{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import gradcheck\n",
    "from IPython.display import clear_output\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class (loads data from csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42600, 7)\n",
      "(5300, 7)\n",
      "(5400, 7)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 100\n",
    "channels = 3\n",
    "classes = 4\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('../data/new_train.csv', header = None)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('../data/new_test.csv', header = None)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('../data/new_val.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 3 : ].values\n",
    "        ind = np.argmax(np.sum(y, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + reqd_len, : channels].values\n",
    "        x = x.astype('float')\n",
    "        x = x.reshape(reqd_len, channels)\n",
    "        assert(x.shape == (reqd_len, channels))\n",
    "        assert(label.shape == (classes, ))\n",
    "        return x, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader definitions (provides data in iterable form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "batch_size = 16\n",
    "train_indices = [(i * reqd_len) for i in range(len(trainset) // reqd_len)]\n",
    "val_indices = [(i * reqd_len) for i in range(len(valset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(testset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)\n",
    "\n",
    "# signal, label = next(iter(trainloader))\n",
    "# print(signal.shape)\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_size(n, f, p = 0, s = 1):\n",
    "    ''' Returns output size for given input size (n), filter size (f), padding (p) and stride (s)\n",
    "    for a convolutional layer\n",
    "    '''\n",
    "    return (((n + 2 * p - f) / s) + 1)\n",
    "\n",
    "output_size(50, 5)\n",
    "output_size(46, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig, lab = next(iter(trainloader))\n",
    "# sig2 = sig\n",
    "# sig = torch.transpose(sig, 1, 2)\n",
    "# sig = sig.reshape(-1, 150)\n",
    "# sig_ = sig.numpy()\n",
    "# sig2_ = sig2.numpy()\n",
    "# plt.plot(sig_[0])\n",
    "# plt.plot(sig2_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 10, 3)\n",
    "        self.pamap = nn.Linear(96 * 10, 12)\n",
    "        self.robogame = nn.Linear(96 * 10, 4)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.pamap.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        nn.init.xavier_uniform_(self.robogame.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    # use flag = True during fine-tuning \n",
    "    def forward(self, signal, flag = False):\n",
    "        signal = torch.transpose(signal, 1, 2)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(-1, 96 * 10)\n",
    "        if flag : \n",
    "            out = self.robogame(out)\n",
    "        else :\n",
    "            out = self.pamap(out)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet().double()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()\n",
    "    \n",
    "Net.load_state_dict(torch.load('../saved_models/model1.pt', map_location = 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, Net.parameters()), lr = 1e-3)\n",
    "# optimizer = optim.SGD(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  26  loss =  1.5333510754403978\n",
      "epoch =  0  step =  20  of total steps  26  loss =  1.0978544836025799\n",
      "epoch :  0  /  100  | TL :  1.237896689509165  | VL :  1.2550600547174648\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  26  loss =  1.0305388172273648\n",
      "epoch =  1  step =  20  of total steps  26  loss =  1.1783458179974768\n",
      "epoch :  1  /  100  | TL :  1.1809112508867095  | VL :  1.2765019480702655\n",
      "epoch =  2  step =  0  of total steps  26  loss =  1.1966728531682653\n",
      "epoch =  2  step =  20  of total steps  26  loss =  1.0839863196911328\n",
      "epoch :  2  /  100  | TL :  1.1478598357213994  | VL :  1.2674307126214537\n",
      "epoch =  3  step =  0  of total steps  26  loss =  1.0906629785970212\n",
      "epoch =  3  step =  20  of total steps  26  loss =  1.0095099075460423\n",
      "epoch :  3  /  100  | TL :  1.1294520491224789  | VL :  1.2345538943513714\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  26  loss =  1.0625042790184276\n",
      "epoch =  4  step =  20  of total steps  26  loss =  1.3775423695616456\n",
      "epoch :  4  /  100  | TL :  1.0963086306203769  | VL :  1.2100708565807017\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  26  loss =  0.9691601727569338\n",
      "epoch =  5  step =  20  of total steps  26  loss =  1.2175533777235232\n",
      "epoch :  5  /  100  | TL :  1.0725001314751788  | VL :  1.17359802821612\n",
      "saving model\n",
      "epoch =  6  step =  0  of total steps  26  loss =  1.095337530810496\n",
      "epoch =  6  step =  20  of total steps  26  loss =  0.9216470545230324\n",
      "epoch :  6  /  100  | TL :  1.0590474618415782  | VL :  1.2684052224888942\n",
      "epoch =  7  step =  0  of total steps  26  loss =  1.254987930323884\n",
      "epoch =  7  step =  20  of total steps  26  loss =  1.0132492210754553\n",
      "epoch :  7  /  100  | TL :  1.034081482556351  | VL :  1.2308957122219013\n",
      "epoch =  8  step =  0  of total steps  26  loss =  0.900222514841544\n",
      "epoch =  8  step =  20  of total steps  26  loss =  0.9716507496830304\n",
      "epoch :  8  /  100  | TL :  1.0130715160222168  | VL :  1.3046733281613305\n",
      "epoch =  9  step =  0  of total steps  26  loss =  1.0581325226940672\n",
      "epoch =  9  step =  20  of total steps  26  loss =  1.1728496161533606\n",
      "epoch :  9  /  100  | TL :  1.0131173885274878  | VL :  1.2452008261037513\n",
      "epoch =  10  step =  0  of total steps  26  loss =  0.9929647789671183\n",
      "epoch =  10  step =  20  of total steps  26  loss =  1.028204650491966\n",
      "epoch :  10  /  100  | TL :  1.0046714697695671  | VL :  1.2786287860996879\n",
      "epoch =  11  step =  0  of total steps  26  loss =  1.0948629113118027\n",
      "epoch =  11  step =  20  of total steps  26  loss =  0.9217632154973724\n",
      "epoch :  11  /  100  | TL :  0.9889586631459875  | VL :  1.3141872531193244\n",
      "epoch =  12  step =  0  of total steps  26  loss =  0.7839729122764645\n",
      "epoch =  12  step =  20  of total steps  26  loss =  0.6119099201977027\n",
      "epoch :  12  /  100  | TL :  0.9802116719853505  | VL :  1.357265572591572\n",
      "epoch =  13  step =  0  of total steps  26  loss =  1.0350119466365642\n",
      "epoch =  13  step =  20  of total steps  26  loss =  0.8863004865990857\n",
      "epoch :  13  /  100  | TL :  0.965333329293389  | VL :  1.3851871217194391\n",
      "epoch =  14  step =  0  of total steps  26  loss =  0.6060256981202051\n",
      "epoch =  14  step =  20  of total steps  26  loss =  0.9884911594662946\n",
      "epoch :  14  /  100  | TL :  0.9667734627071412  | VL :  1.3082967003012191\n",
      "epoch =  15  step =  0  of total steps  26  loss =  0.9740348975406323\n",
      "epoch =  15  step =  20  of total steps  26  loss =  0.7749238070117436\n",
      "epoch :  15  /  100  | TL :  0.9562337173956545  | VL :  1.3357831415780692\n",
      "epoch =  16  step =  0  of total steps  26  loss =  1.0380822434663894\n",
      "epoch =  16  step =  20  of total steps  26  loss =  0.6478576742433348\n",
      "epoch :  16  /  100  | TL :  0.9443120403931744  | VL :  1.4351615557356805\n",
      "epoch =  17  step =  0  of total steps  26  loss =  0.8807807255681631\n",
      "epoch =  17  step =  20  of total steps  26  loss =  1.0477083807784295\n",
      "epoch :  17  /  100  | TL :  0.9387260358043584  | VL :  1.3711752469952534\n",
      "epoch =  18  step =  0  of total steps  26  loss =  1.117956715690356\n",
      "epoch =  18  step =  20  of total steps  26  loss =  0.7994525007708425\n",
      "epoch :  18  /  100  | TL :  0.9323222108633004  | VL :  1.3556805294668859\n",
      "epoch =  19  step =  0  of total steps  26  loss =  0.8584790725470957\n",
      "epoch =  19  step =  20  of total steps  26  loss =  0.6662867942538473\n",
      "epoch :  19  /  100  | TL :  0.9304863972896183  | VL :  1.3822476319997141\n",
      "epoch =  20  step =  0  of total steps  26  loss =  0.9649440329674825\n",
      "epoch =  20  step =  20  of total steps  26  loss =  1.0178075203893069\n",
      "epoch :  20  /  100  | TL :  0.9340210308838217  | VL :  1.4187254595095908\n",
      "epoch =  21  step =  0  of total steps  26  loss =  0.8369501783320555\n",
      "epoch =  21  step =  20  of total steps  26  loss =  1.13622298670939\n",
      "epoch :  21  /  100  | TL :  0.9392487875109208  | VL :  1.4395920752224332\n",
      "epoch =  22  step =  0  of total steps  26  loss =  0.8611321094018799\n",
      "epoch =  22  step =  20  of total steps  26  loss =  0.9648703041059549\n",
      "epoch :  22  /  100  | TL :  0.9126239424424736  | VL :  1.4185867573703959\n",
      "epoch =  23  step =  0  of total steps  26  loss =  0.8287704971611216\n",
      "epoch =  23  step =  20  of total steps  26  loss =  0.902154526906548\n",
      "epoch :  23  /  100  | TL :  0.9097958646550764  | VL :  1.3880180039616226\n",
      "epoch =  24  step =  0  of total steps  26  loss =  0.8818187258229687\n",
      "epoch =  24  step =  20  of total steps  26  loss =  1.1475633574882702\n",
      "epoch :  24  /  100  | TL :  0.9279319369789776  | VL :  1.4007191832105856\n",
      "epoch =  25  step =  0  of total steps  26  loss =  0.9001759336300245\n",
      "epoch =  25  step =  20  of total steps  26  loss =  0.994013923589417\n",
      "epoch :  25  /  100  | TL :  0.9114075774201406  | VL :  1.445911755359779\n",
      "epoch =  26  step =  0  of total steps  26  loss =  1.158311236659906\n",
      "epoch =  26  step =  20  of total steps  26  loss =  1.0152599592643343\n",
      "epoch :  26  /  100  | TL :  0.8978010039931831  | VL :  1.3816831645290846\n",
      "epoch =  27  step =  0  of total steps  26  loss =  0.7772271237041448\n",
      "epoch =  27  step =  20  of total steps  26  loss =  0.7918414770539047\n",
      "epoch :  27  /  100  | TL :  0.8925683912926803  | VL :  1.442279499216509\n",
      "epoch =  28  step =  0  of total steps  26  loss =  0.8875622041403014\n",
      "epoch =  28  step =  20  of total steps  26  loss =  0.7453386599280496\n",
      "epoch :  28  /  100  | TL :  0.8941723286143215  | VL :  1.5171854452932907\n",
      "epoch =  29  step =  0  of total steps  26  loss =  0.942159931689204\n",
      "epoch =  29  step =  20  of total steps  26  loss =  0.8746189769823979\n",
      "epoch :  29  /  100  | TL :  0.8747620021347219  | VL :  1.4570694460373812\n",
      "epoch =  30  step =  0  of total steps  26  loss =  0.9136339211995453\n",
      "epoch =  30  step =  20  of total steps  26  loss =  0.6998356628802007\n",
      "epoch :  30  /  100  | TL :  0.8802414871343476  | VL :  1.4387287676792029\n",
      "epoch =  31  step =  0  of total steps  26  loss =  0.6329967694920389\n",
      "epoch =  31  step =  20  of total steps  26  loss =  1.252743588132091\n",
      "epoch :  31  /  100  | TL :  0.8753455416667134  | VL :  1.504418133031237\n",
      "epoch =  32  step =  0  of total steps  26  loss =  0.9119508652483669\n",
      "epoch =  32  step =  20  of total steps  26  loss =  0.7548681514539638\n",
      "epoch :  32  /  100  | TL :  0.8715996011895452  | VL :  1.4017103674725018\n",
      "epoch =  33  step =  0  of total steps  26  loss =  0.6398078969134042\n",
      "epoch =  33  step =  20  of total steps  26  loss =  0.9196465916263652\n",
      "epoch :  33  /  100  | TL :  0.871275195545555  | VL :  1.458498881199243\n",
      "epoch =  34  step =  0  of total steps  26  loss =  0.5615130069970706\n",
      "epoch =  34  step =  20  of total steps  26  loss =  0.8506470251711362\n",
      "epoch :  34  /  100  | TL :  0.8550366969190966  | VL :  1.373628518564485\n",
      "epoch =  35  step =  0  of total steps  26  loss =  0.6877088716288247\n",
      "epoch =  35  step =  20  of total steps  26  loss =  0.7832940597577899\n",
      "epoch :  35  /  100  | TL :  0.8510210437472043  | VL :  1.428614285851684\n",
      "epoch =  36  step =  0  of total steps  26  loss =  0.7694410758807688\n",
      "epoch =  36  step =  20  of total steps  26  loss =  1.017457504324786\n",
      "epoch :  36  /  100  | TL :  0.8534253532737305  | VL :  1.5048047115004852\n",
      "epoch =  37  step =  0  of total steps  26  loss =  0.7076839963836643\n",
      "epoch =  37  step =  20  of total steps  26  loss =  0.5361114384623529\n",
      "epoch :  37  /  100  | TL :  0.8499946998117491  | VL :  1.3959262705434845\n",
      "epoch =  38  step =  0  of total steps  26  loss =  0.7481214664074568\n",
      "epoch =  38  step =  20  of total steps  26  loss =  0.6235051257546631\n",
      "epoch :  38  /  100  | TL :  0.8296817136316493  | VL :  1.5048917394581205\n",
      "epoch =  39  step =  0  of total steps  26  loss =  0.778190459899835\n",
      "epoch =  39  step =  20  of total steps  26  loss =  0.8884778171362863\n",
      "epoch :  39  /  100  | TL :  0.8468948574375136  | VL :  1.4143233271872937\n",
      "epoch =  40  step =  0  of total steps  26  loss =  1.1144415177784102\n",
      "epoch =  40  step =  20  of total steps  26  loss =  1.1607957352268938\n",
      "epoch :  40  /  100  | TL :  0.8386079875267427  | VL :  1.4512882742015443\n",
      "epoch =  41  step =  0  of total steps  26  loss =  0.8297556277880456\n",
      "epoch =  41  step =  20  of total steps  26  loss =  1.0451012325426947\n",
      "epoch :  41  /  100  | TL :  0.8361323726307142  | VL :  1.4472168950294357\n",
      "epoch =  42  step =  0  of total steps  26  loss =  0.7912021166997036\n",
      "epoch =  42  step =  20  of total steps  26  loss =  0.676264967988215\n",
      "epoch :  42  /  100  | TL :  0.843573294385813  | VL :  1.4250166348032127\n",
      "epoch =  43  step =  0  of total steps  26  loss =  1.0305621997372096\n",
      "epoch =  43  step =  20  of total steps  26  loss =  0.7083858440070918\n",
      "epoch :  43  /  100  | TL :  0.8440085770984003  | VL :  1.5313118731273692\n",
      "epoch =  44  step =  0  of total steps  26  loss =  1.0856586340349363\n",
      "epoch =  44  step =  20  of total steps  26  loss =  0.948281208383298\n",
      "epoch :  44  /  100  | TL :  0.834817643042739  | VL :  1.41050586159323\n",
      "epoch =  45  step =  0  of total steps  26  loss =  0.6384598805244748\n",
      "epoch =  45  step =  20  of total steps  26  loss =  0.8179785369692888\n",
      "epoch :  45  /  100  | TL :  0.8040612623136671  | VL :  1.421522836547305\n",
      "epoch =  46  step =  0  of total steps  26  loss =  0.6451353438114737\n",
      "epoch =  46  step =  20  of total steps  26  loss =  0.9578586088019148\n",
      "epoch :  46  /  100  | TL :  0.8178536663767956  | VL :  1.4850980308475632\n",
      "epoch =  47  step =  0  of total steps  26  loss =  1.0071655447177406\n",
      "epoch =  47  step =  20  of total steps  26  loss =  0.8185400935674872\n",
      "epoch :  47  /  100  | TL :  0.80537005948405  | VL :  1.518571988560576\n",
      "epoch =  48  step =  0  of total steps  26  loss =  0.8496623595116661\n",
      "epoch =  48  step =  20  of total steps  26  loss =  0.8455003898870305\n",
      "epoch :  48  /  100  | TL :  0.8142968640365301  | VL :  1.5156486136937197\n",
      "epoch =  49  step =  0  of total steps  26  loss =  0.7570611447283355\n",
      "epoch =  49  step =  20  of total steps  26  loss =  0.7294534438338374\n",
      "epoch :  49  /  100  | TL :  0.7969693694867749  | VL :  1.5615623848244151\n",
      "epoch =  50  step =  0  of total steps  26  loss =  0.7011096422622832\n",
      "epoch =  50  step =  20  of total steps  26  loss =  1.1077224583516354\n",
      "epoch :  50  /  100  | TL :  0.8130823072098377  | VL :  1.5306404457350293\n",
      "epoch =  51  step =  0  of total steps  26  loss =  0.7026276683623429\n",
      "epoch =  51  step =  20  of total steps  26  loss =  0.7967959088305758\n",
      "epoch :  51  /  100  | TL :  0.7866937279594141  | VL :  1.5165661942029087\n",
      "epoch =  52  step =  0  of total steps  26  loss =  0.8527003514008736\n",
      "epoch =  52  step =  20  of total steps  26  loss =  0.8014898006644524\n",
      "epoch :  52  /  100  | TL :  0.8137868401799869  | VL :  1.522342466337043\n",
      "epoch =  53  step =  0  of total steps  26  loss =  0.9743346317803797\n",
      "epoch =  53  step =  20  of total steps  26  loss =  0.9504968069384547\n",
      "epoch :  53  /  100  | TL :  0.7890892969102243  | VL :  1.4446718212117797\n",
      "epoch =  54  step =  0  of total steps  26  loss =  0.9748380541902303\n",
      "epoch =  54  step =  20  of total steps  26  loss =  0.789735709832329\n",
      "epoch :  54  /  100  | TL :  0.7854952379449939  | VL :  1.4987503440664398\n",
      "epoch =  55  step =  0  of total steps  26  loss =  0.6390758258067204\n",
      "epoch =  55  step =  20  of total steps  26  loss =  0.6525954061343592\n",
      "epoch :  55  /  100  | TL :  0.8045430635707275  | VL :  1.5016260758602318\n",
      "epoch =  56  step =  0  of total steps  26  loss =  0.8764995722013873\n",
      "epoch =  56  step =  20  of total steps  26  loss =  1.0535937321247908\n",
      "epoch :  56  /  100  | TL :  0.7917470578345985  | VL :  1.5161487295342757\n",
      "epoch =  57  step =  0  of total steps  26  loss =  0.8194606553909722\n",
      "epoch =  57  step =  20  of total steps  26  loss =  0.7503104195454628\n",
      "epoch :  57  /  100  | TL :  0.7863440400756896  | VL :  1.5765896793749696\n",
      "epoch =  58  step =  0  of total steps  26  loss =  0.7674490259902261\n",
      "epoch =  58  step =  20  of total steps  26  loss =  1.1866199877012427\n",
      "epoch :  58  /  100  | TL :  0.7735233644121724  | VL :  1.597371000078369\n",
      "epoch =  59  step =  0  of total steps  26  loss =  0.7868381374395698\n",
      "epoch =  59  step =  20  of total steps  26  loss =  0.45301964183848104\n",
      "epoch :  59  /  100  | TL :  0.7818501968348888  | VL :  1.523069778982417\n",
      "epoch =  60  step =  0  of total steps  26  loss =  0.9379428989066713\n",
      "epoch =  60  step =  20  of total steps  26  loss =  0.83785531373453\n",
      "epoch :  60  /  100  | TL :  0.7743780832213552  | VL :  1.4874703515399723\n",
      "epoch =  61  step =  0  of total steps  26  loss =  0.9453962441575392\n",
      "epoch =  61  step =  20  of total steps  26  loss =  0.7306972823617902\n",
      "epoch :  61  /  100  | TL :  0.76765760427576  | VL :  1.5154946469123196\n",
      "epoch =  62  step =  0  of total steps  26  loss =  1.163492817459097\n",
      "epoch =  62  step =  20  of total steps  26  loss =  1.0781012385144795\n",
      "epoch :  62  /  100  | TL :  0.7744071102111422  | VL :  1.5440069777208378\n",
      "epoch =  63  step =  0  of total steps  26  loss =  0.5603933916576691\n",
      "epoch =  63  step =  20  of total steps  26  loss =  0.7019006273224322\n",
      "epoch :  63  /  100  | TL :  0.7613510856473835  | VL :  1.5403131210862522\n",
      "epoch =  64  step =  0  of total steps  26  loss =  0.621071084348725\n",
      "epoch =  64  step =  20  of total steps  26  loss =  0.757593494718072\n",
      "epoch :  64  /  100  | TL :  0.7552618509455022  | VL :  1.5066933782774505\n",
      "epoch =  65  step =  0  of total steps  26  loss =  0.7187300582210375\n",
      "epoch =  65  step =  20  of total steps  26  loss =  1.2573071288489466\n",
      "epoch :  65  /  100  | TL :  0.7626108267703179  | VL :  1.4711644999200715\n",
      "epoch =  66  step =  0  of total steps  26  loss =  0.49796405295083657\n",
      "epoch =  66  step =  20  of total steps  26  loss =  1.0312082900930297\n",
      "epoch :  66  /  100  | TL :  0.7644706410511867  | VL :  1.4514191163033516\n",
      "epoch =  67  step =  0  of total steps  26  loss =  0.6068917507844064\n",
      "epoch =  67  step =  20  of total steps  26  loss =  0.6884730679757043\n",
      "epoch :  67  /  100  | TL :  0.7497589314101686  | VL :  1.5283397181123595\n",
      "epoch =  68  step =  0  of total steps  26  loss =  0.7529408333312089\n",
      "epoch =  68  step =  20  of total steps  26  loss =  0.664502694769776\n",
      "epoch :  68  /  100  | TL :  0.7537498626227055  | VL :  1.5088478147326363\n",
      "epoch =  69  step =  0  of total steps  26  loss =  0.5766742228410339\n",
      "epoch =  69  step =  20  of total steps  26  loss =  0.44427233049234477\n",
      "epoch :  69  /  100  | TL :  0.7370960394856133  | VL :  1.607069197156018\n",
      "epoch =  70  step =  0  of total steps  26  loss =  0.7224092069741657\n",
      "epoch =  70  step =  20  of total steps  26  loss =  0.8417442562308958\n",
      "epoch :  70  /  100  | TL :  0.7530011351395575  | VL :  1.5081029319576835\n",
      "epoch =  71  step =  0  of total steps  26  loss =  0.7183857545700235\n",
      "epoch =  71  step =  20  of total steps  26  loss =  0.8185990518038525\n",
      "epoch :  71  /  100  | TL :  0.7576153653251221  | VL :  1.6088483438233314\n",
      "epoch =  72  step =  0  of total steps  26  loss =  0.8437942323764903\n",
      "epoch =  72  step =  20  of total steps  26  loss =  0.6703098452262365\n",
      "epoch :  72  /  100  | TL :  0.7410759193521173  | VL :  1.5604380581276533\n",
      "epoch =  73  step =  0  of total steps  26  loss =  1.1277296820218674\n",
      "epoch =  73  step =  20  of total steps  26  loss =  0.6149545699535135\n",
      "epoch :  73  /  100  | TL :  0.7365213221406576  | VL :  1.5529417037714657\n",
      "epoch =  74  step =  0  of total steps  26  loss =  0.9385006601641447\n",
      "epoch =  74  step =  20  of total steps  26  loss =  0.7781656311400872\n",
      "epoch :  74  /  100  | TL :  0.7238842270490563  | VL :  1.5946799373999792\n",
      "epoch =  75  step =  0  of total steps  26  loss =  0.8137850363950531\n",
      "epoch =  75  step =  20  of total steps  26  loss =  0.6688858677842155\n",
      "epoch :  75  /  100  | TL :  0.7525123494409873  | VL :  1.7291006342349167\n",
      "epoch =  76  step =  0  of total steps  26  loss =  1.025161352260384\n",
      "epoch =  76  step =  20  of total steps  26  loss =  0.5541745180152977\n",
      "epoch :  76  /  100  | TL :  0.7403045519588882  | VL :  1.7326321953691\n",
      "epoch =  77  step =  0  of total steps  26  loss =  0.8704407676866419\n",
      "epoch =  77  step =  20  of total steps  26  loss =  0.7480081219492345\n",
      "epoch :  77  /  100  | TL :  0.7045621420324408  | VL :  1.5420704135421757\n",
      "epoch =  78  step =  0  of total steps  26  loss =  0.44006196493446836\n",
      "epoch =  78  step =  20  of total steps  26  loss =  1.040028978334364\n",
      "epoch :  78  /  100  | TL :  0.7297238636654797  | VL :  1.6316796454170737\n",
      "epoch =  79  step =  0  of total steps  26  loss =  0.6263393597022225\n",
      "epoch =  79  step =  20  of total steps  26  loss =  0.6190917929735832\n",
      "epoch :  79  /  100  | TL :  0.7291926873019996  | VL :  1.693356238526509\n",
      "epoch =  80  step =  0  of total steps  26  loss =  0.5423197120307782\n",
      "epoch =  80  step =  20  of total steps  26  loss =  0.5893149502334027\n",
      "epoch :  80  /  100  | TL :  0.7024649881006739  | VL :  1.605568224327099\n",
      "epoch =  81  step =  0  of total steps  26  loss =  0.9270535913949779\n",
      "epoch =  81  step =  20  of total steps  26  loss =  0.8908045192108645\n",
      "epoch :  81  /  100  | TL :  0.7051897727170093  | VL :  1.581785042305217\n",
      "epoch =  82  step =  0  of total steps  26  loss =  0.8225200855891994\n",
      "epoch =  82  step =  20  of total steps  26  loss =  0.8464840742694354\n",
      "epoch :  82  /  100  | TL :  0.7003949729840867  | VL :  1.5633116326309338\n",
      "epoch =  83  step =  0  of total steps  26  loss =  0.5907398928671658\n",
      "epoch =  83  step =  20  of total steps  26  loss =  0.8595304084888705\n",
      "epoch :  83  /  100  | TL :  0.7103954424095963  | VL :  1.5579637308185486\n",
      "epoch =  84  step =  0  of total steps  26  loss =  0.5362051151721798\n",
      "epoch =  84  step =  20  of total steps  26  loss =  0.9889550306639585\n",
      "epoch :  84  /  100  | TL :  0.6925049469310692  | VL :  1.4806162663905515\n",
      "epoch =  85  step =  0  of total steps  26  loss =  0.5699606614340057\n",
      "epoch =  85  step =  20  of total steps  26  loss =  1.2736353412880876\n",
      "epoch :  85  /  100  | TL :  0.6872335526663372  | VL :  1.6245076326619676\n",
      "epoch =  86  step =  0  of total steps  26  loss =  0.6112608909807239\n",
      "epoch =  86  step =  20  of total steps  26  loss =  1.2455425187576934\n",
      "epoch :  86  /  100  | TL :  0.6977327066613512  | VL :  1.6569753203119548\n",
      "epoch =  87  step =  0  of total steps  26  loss =  0.6148228871162827\n",
      "epoch =  87  step =  20  of total steps  26  loss =  0.7376125962870136\n",
      "epoch :  87  /  100  | TL :  0.7005963799107443  | VL :  1.6014636629929395\n",
      "epoch =  88  step =  0  of total steps  26  loss =  1.047127047838435\n",
      "epoch =  88  step =  20  of total steps  26  loss =  0.7670313029580007\n",
      "epoch :  88  /  100  | TL :  0.7087977548666078  | VL :  1.5609532732196456\n",
      "epoch =  89  step =  0  of total steps  26  loss =  0.7694305893601767\n",
      "epoch =  89  step =  20  of total steps  26  loss =  0.5066775180147993\n",
      "epoch :  89  /  100  | TL :  0.7015705110540842  | VL :  1.7232990366064838\n",
      "epoch =  90  step =  0  of total steps  26  loss =  0.1998962004161365\n",
      "epoch =  90  step =  20  of total steps  26  loss =  0.7819775643075171\n",
      "epoch :  90  /  100  | TL :  0.6630379194961786  | VL :  1.7960741923645414\n",
      "epoch =  91  step =  0  of total steps  26  loss =  0.6170566181420056\n",
      "epoch =  91  step =  20  of total steps  26  loss =  0.8675851211901507\n",
      "epoch :  91  /  100  | TL :  0.6802769236333196  | VL :  1.7905713145927349\n",
      "epoch =  92  step =  0  of total steps  26  loss =  0.7074532510162654\n",
      "epoch =  92  step =  20  of total steps  26  loss =  0.9230741378182813\n",
      "epoch :  92  /  100  | TL :  0.6802293500893366  | VL :  1.5952573791425237\n",
      "epoch =  93  step =  0  of total steps  26  loss =  0.8021299955501622\n",
      "epoch =  93  step =  20  of total steps  26  loss =  0.5301929793167586\n",
      "epoch :  93  /  100  | TL :  0.6643280812435252  | VL :  1.5846960585300043\n",
      "epoch =  94  step =  0  of total steps  26  loss =  0.6541710349104563\n",
      "epoch =  94  step =  20  of total steps  26  loss =  0.38051786470344423\n",
      "epoch :  94  /  100  | TL :  0.6675253274514742  | VL :  1.7516452004804905\n",
      "epoch =  95  step =  0  of total steps  26  loss =  0.5900430279916973\n",
      "epoch =  95  step =  20  of total steps  26  loss =  0.4544022472245196\n",
      "epoch :  95  /  100  | TL :  0.6725880835334702  | VL :  1.683330514724844\n",
      "epoch =  96  step =  0  of total steps  26  loss =  0.580294038834656\n",
      "epoch =  96  step =  20  of total steps  26  loss =  0.5926516375168568\n",
      "epoch :  96  /  100  | TL :  0.6636630324844555  | VL :  1.7943212211350037\n",
      "epoch =  97  step =  0  of total steps  26  loss =  0.4712468983751081\n",
      "epoch =  97  step =  20  of total steps  26  loss =  0.5038034013893518\n",
      "epoch :  97  /  100  | TL :  0.6546707200174944  | VL :  1.6950154101068409\n",
      "epoch =  98  step =  0  of total steps  26  loss =  0.8350809288880988\n",
      "epoch =  98  step =  20  of total steps  26  loss =  0.7222573546443067\n",
      "epoch :  98  /  100  | TL :  0.651322759046425  | VL :  1.680840644224627\n",
      "epoch =  99  step =  0  of total steps  26  loss =  0.5389204647689751\n",
      "epoch =  99  step =  20  of total steps  26  loss =  0.7359795861120495\n",
      "epoch :  99  /  100  | TL :  0.6543529155225201  | VL :  1.5347702210141856\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "total_step = len(trainset) // (train_batch_size * reqd_len)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().double()\n",
    "            images.requires_grad = True\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).double()\n",
    "            images.requires_grad = True\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net.forward(images, flag = True)\n",
    "        \n",
    "        loss = F.cross_entropy(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "#             print('Gradient Check : ', gradcheck(Net, (images, )))\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(testloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().double()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).double()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net.forward(images, flag = True)\n",
    "            loss = F.cross_entropy(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '../saved_models/model2_finetuning.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f978261e1d0>,\n",
       " <matplotlib.lines.Line2D at 0x7f978261e320>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(100)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.5673076923077 / 54.166666666666664 / 39.58333333333333\n",
      "59.375 / 54.166666666666664 / 45.83333333333333\n"
     ]
    }
   ],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).double()\n",
    "        labels = Variable(labels).double()\n",
    "        \n",
    "        if torch.cuda.is_available() : \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = Net.forward(images, flag = True)\n",
    "        outputs = F.log_softmax(outputs, dim = 1)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.cpu().numpy()\n",
    "        pred_ind = pred_ind.data.cpu().numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.eval()\n",
    "\n",
    "print(_get_accuracy(trainloader, Net) * 100, '/', _get_accuracy(valloader, Net) * 100, '/', _get_accuracy(testloader, Net) * 100)\n",
    "\n",
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('../saved_models/model2_finetuning.pt'))\n",
    "testing_Net.eval().double()\n",
    "print(_get_accuracy(trainloader, testing_Net) * 100, '/', _get_accuracy(valloader, testing_Net) * 100, '/', _get_accuracy(testloader, testing_Net) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directly training NNs on raw data doesn't work well (network overfits most of the time). So, we can try to use some pre-processing to the data before training (like running mean, running std deviation, running rms, etc.)\n",
    "\n",
    "### PyTorch implementation of `running_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(signal, window_size = 10):\n",
    "    ''' Returns running mean of 3D signal (batch_size, length, channels)\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].mean(dim = 0)\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = signal[i][j]\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_mean` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f012cd56898>,\n",
       " <matplotlib.lines.Line2D at 0x7f012cd569e8>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "# print(signal.shape)\n",
    "# print(signal[2].shape)\n",
    "# print(signal[2].mean(dim = 0).shape)\n",
    "# print(signal[2][ : 10].mean(dim = 0).shape)\n",
    "# print(signal[1][2].shape)\n",
    "mean = running_mean(signal, window_size = 5)\n",
    "print(mean.shape)\n",
    "sig_ = signal[0].transpose(0, 1)\n",
    "mean_ = mean[0].transpose(0, 1)\n",
    "t = range(50)\n",
    "plt.plot(t, sig_[1].data.numpy(), 'r', t, mean_[1].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_mean` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 10, 3)\n",
    "        self.fc1 = nn.Linear(46 * 10, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.pamap = nn.Linear(64, 12)\n",
    "        self.robogame = nn.Linear(64, 4)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.pamap.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        nn.init.xavier_uniform_(self.robogame.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "        self.conv1.requires_grad = False\n",
    "        self.conv2.requires_grad = False\n",
    "#         self.conv3.requires_grad = False\n",
    "        self.fc1.requires_grad = False\n",
    "        \n",
    "    # use flag = True during fine-tuning \n",
    "    def forward(self, signal, flag = False):\n",
    "        signal = torch.transpose(signal, 1, 2)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(-1, 46 * 10)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        if flag : \n",
    "            out = F.log_softmax(self.robogame(out), dim = 1)\n",
    "        else :\n",
    "            out = F.log_softmax(self.pamap(out), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet().double()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()\n",
    "    \n",
    "Net.load_state_dict(torch.load('../saved_models/model5.pt', map_location = 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  24  loss =  40.38579961256982\n",
      "epoch =  0  step =  20  of total steps  24  loss =  11.082769917554113\n",
      "epoch =  0  step =  40  of total steps  24  loss =  4.386315553257795\n",
      "epoch =  0  step =  60  of total steps  24  loss =  4.5303314611552725\n",
      "epoch :  0  /  20  | TL :  10.175358823116795  | VL :  4.0957429852096086\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  24  loss =  2.2734264813851945\n",
      "epoch =  1  step =  20  of total steps  24  loss =  2.560068265577454\n",
      "epoch =  1  step =  40  of total steps  24  loss =  5.460454538465867\n",
      "epoch =  1  step =  60  of total steps  24  loss =  1.640364041251571\n",
      "epoch :  1  /  20  | TL :  2.9486955296092665  | VL :  2.7871905952074583\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  24  loss =  1.641685817389175\n",
      "epoch =  2  step =  20  of total steps  24  loss =  3.171220095012442\n",
      "epoch =  2  step =  40  of total steps  24  loss =  1.6949074627107763\n",
      "epoch =  2  step =  60  of total steps  24  loss =  1.8898738992152464\n",
      "epoch :  2  /  20  | TL :  2.084889712451881  | VL :  2.4027770530013237\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  24  loss =  1.4595966628378245\n",
      "epoch =  3  step =  20  of total steps  24  loss =  2.4750518567044053\n",
      "epoch =  3  step =  40  of total steps  24  loss =  2.137516267740264\n",
      "epoch =  3  step =  60  of total steps  24  loss =  2.3187881308674734\n",
      "epoch :  3  /  20  | TL :  1.7356064331755165  | VL :  2.1142892410331964\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  24  loss =  1.6469333825553476\n",
      "epoch =  4  step =  20  of total steps  24  loss =  1.7054418616286844\n",
      "epoch =  4  step =  40  of total steps  24  loss =  1.680567356252085\n",
      "epoch =  4  step =  60  of total steps  24  loss =  1.1955434742146107\n",
      "epoch :  4  /  20  | TL :  1.5106702881230147  | VL :  1.8413889423247118\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  24  loss =  1.6567471908044213\n",
      "epoch =  5  step =  20  of total steps  24  loss =  1.1158275720626312\n",
      "epoch =  5  step =  40  of total steps  24  loss =  1.3887438090585573\n",
      "epoch =  5  step =  60  of total steps  24  loss =  1.6431585381859621\n",
      "epoch :  5  /  20  | TL :  1.4164035088683855  | VL :  1.9293270089783572\n",
      "epoch =  6  step =  0  of total steps  24  loss =  1.3425372535509923\n",
      "epoch =  6  step =  20  of total steps  24  loss =  1.4961099284460522\n",
      "epoch =  6  step =  40  of total steps  24  loss =  1.1020033698049267\n",
      "epoch =  6  step =  60  of total steps  24  loss =  1.3348990156401497\n",
      "epoch :  6  /  20  | TL :  1.2936357763085276  | VL :  1.7418578478453988\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  24  loss =  1.3058005726811195\n",
      "epoch =  7  step =  20  of total steps  24  loss =  0.616661984528921\n",
      "epoch =  7  step =  40  of total steps  24  loss =  1.5246193723732377\n",
      "epoch =  7  step =  60  of total steps  24  loss =  1.3087683923065438\n",
      "epoch :  7  /  20  | TL :  1.23130672360364  | VL :  1.7806504189870072\n",
      "epoch =  8  step =  0  of total steps  24  loss =  1.0595622124255193\n",
      "epoch =  8  step =  20  of total steps  24  loss =  0.8244724459552348\n",
      "epoch =  8  step =  40  of total steps  24  loss =  1.2716404859532482\n",
      "epoch =  8  step =  60  of total steps  24  loss =  1.35941177883245\n",
      "epoch :  8  /  20  | TL :  1.1733878136739955  | VL :  1.7815597692379488\n",
      "epoch =  9  step =  0  of total steps  24  loss =  0.6887240460282981\n",
      "epoch =  9  step =  20  of total steps  24  loss =  0.973961218744841\n",
      "epoch =  9  step =  40  of total steps  24  loss =  1.4255489516416542\n",
      "epoch =  9  step =  60  of total steps  24  loss =  1.1443442155609076\n",
      "epoch :  9  /  20  | TL :  1.117689054620426  | VL :  1.6661637498917556\n",
      "saving model\n",
      "epoch =  10  step =  0  of total steps  24  loss =  0.7839298908251182\n",
      "epoch =  10  step =  20  of total steps  24  loss =  0.9679741299347808\n",
      "epoch =  10  step =  40  of total steps  24  loss =  0.9276047358300996\n",
      "epoch =  10  step =  60  of total steps  24  loss =  1.1721941772427138\n",
      "epoch :  10  /  20  | TL :  1.0607881621244362  | VL :  1.601590938054959\n",
      "saving model\n",
      "epoch =  11  step =  0  of total steps  24  loss =  0.6463626573536144\n",
      "epoch =  11  step =  20  of total steps  24  loss =  0.8277497976352012\n",
      "epoch =  11  step =  40  of total steps  24  loss =  0.9156837544496328\n",
      "epoch =  11  step =  60  of total steps  24  loss =  1.1899139247512696\n",
      "epoch :  11  /  20  | TL :  1.057769295621444  | VL :  1.6298130616088453\n",
      "epoch =  12  step =  0  of total steps  24  loss =  1.3212486670868682\n",
      "epoch =  12  step =  20  of total steps  24  loss =  0.9030060783244769\n",
      "epoch =  12  step =  40  of total steps  24  loss =  0.8964618203607567\n",
      "epoch =  12  step =  60  of total steps  24  loss =  0.8695932946620523\n",
      "epoch :  12  /  20  | TL :  1.0203534034702704  | VL :  1.7186065388074427\n",
      "epoch =  13  step =  0  of total steps  24  loss =  1.1647714604996913\n",
      "epoch =  13  step =  20  of total steps  24  loss =  1.075135839006023\n",
      "epoch =  13  step =  40  of total steps  24  loss =  0.8746860503573091\n",
      "epoch =  13  step =  60  of total steps  24  loss =  1.1479204623967647\n",
      "epoch :  13  /  20  | TL :  0.9976711162872127  | VL :  1.5587375006983104\n",
      "saving model\n",
      "epoch =  14  step =  0  of total steps  24  loss =  0.8207604890081892\n",
      "epoch =  14  step =  20  of total steps  24  loss =  1.22972897482687\n",
      "epoch =  14  step =  40  of total steps  24  loss =  1.1278041835223638\n",
      "epoch =  14  step =  60  of total steps  24  loss =  1.0143420806214558\n",
      "epoch :  14  /  20  | TL :  0.9724252978077235  | VL :  1.6327743622838176\n",
      "epoch =  15  step =  0  of total steps  24  loss =  0.7892789742268272\n",
      "epoch =  15  step =  20  of total steps  24  loss =  0.8423424020568351\n",
      "epoch =  15  step =  40  of total steps  24  loss =  0.7394852895029351\n",
      "epoch =  15  step =  60  of total steps  24  loss =  0.883641773506376\n",
      "epoch :  15  /  20  | TL :  0.9422222487683921  | VL :  1.597082277885344\n",
      "epoch =  16  step =  0  of total steps  24  loss =  0.8503904834336841\n",
      "epoch =  16  step =  20  of total steps  24  loss =  0.9735615029177268\n",
      "epoch =  16  step =  40  of total steps  24  loss =  0.8196834386577747\n",
      "epoch =  16  step =  60  of total steps  24  loss =  0.546660836343205\n",
      "epoch :  16  /  20  | TL :  0.9235061924872765  | VL :  1.5499680574419743\n",
      "saving model\n",
      "epoch =  17  step =  0  of total steps  24  loss =  0.7302748087140275\n",
      "epoch =  17  step =  20  of total steps  24  loss =  1.1527202390715954\n",
      "epoch =  17  step =  40  of total steps  24  loss =  0.7135103272455835\n",
      "epoch =  17  step =  60  of total steps  24  loss =  0.5736566384414842\n",
      "epoch :  17  /  20  | TL :  0.9190719707803809  | VL :  1.5093811847293013\n",
      "saving model\n",
      "epoch =  18  step =  0  of total steps  24  loss =  1.0273000489604207\n",
      "epoch =  18  step =  20  of total steps  24  loss =  0.687969291221481\n",
      "epoch =  18  step =  40  of total steps  24  loss =  1.358016132038631\n",
      "epoch =  18  step =  60  of total steps  24  loss =  0.8169610734240705\n",
      "epoch :  18  /  20  | TL :  0.9096920452183789  | VL :  1.7122805414019098\n",
      "epoch =  19  step =  0  of total steps  24  loss =  1.1895884760480273\n",
      "epoch =  19  step =  20  of total steps  24  loss =  0.9457142649131994\n",
      "epoch =  19  step =  40  of total steps  24  loss =  0.924966634852499\n",
      "epoch =  19  step =  60  of total steps  24  loss =  0.8396435323227607\n",
      "epoch :  19  /  20  | TL :  0.903707897331913  | VL :  1.673891073086247\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().double()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).double()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().double()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).double()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '../saved_models/model5_finetuning.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f012ccc0358>,\n",
       " <matplotlib.lines.Line2D at 0x7f012ccc04a8>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(20)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).double()\n",
    "        labels = Variable(labels).double()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429794520547946\n",
      "0.4861111111111111\n",
      "0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader, Net))\n",
    "print(_get_accuracy(testloader, Net))\n",
    "print(_get_accuracy(valloader, Net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6738013698630136\n",
      "0.4722222222222222\n",
      "0.4305555555555556\n"
     ]
    }
   ],
   "source": [
    "testing_Net = ConvNet().double()\n",
    "testing_Net.load_state_dict(torch.load('../saved_models/model5_finetuning.pt'))\n",
    "testing_Net.eval()\n",
    "print(_get_accuracy(trainloader, testing_Net))\n",
    "print(_get_accuracy(testloader, testing_Net))\n",
    "print(_get_accuracy(valloader, testing_Net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even using `running_mean` processed data, the network again overfits. Even increasing window size didn't help (decreasing won't help as it will be closer to raw data then). Increasing too much is also not helpful as the plot will get more and more flat. So, we need to try out other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch implementation of running standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_std_dev(signal, window_size = 10):\n",
    "    ''' Returns running standard deviation of 3D signal (batch_size, length, channels)\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].std(dim = 0)\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = np.abs(signal[i][j])\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_std_dev` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0135a2fa58>,\n",
       " <matplotlib.lines.Line2D at 0x7f0135a2fba8>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "mean = running_std_dev(signal, window_size = 5)\n",
    "print(mean.shape)\n",
    "sig_ = signal[0].transpose(0, 1)\n",
    "mean_ = mean[0].transpose(0, 1)\n",
    "t = range(50)\n",
    "plt.plot(t, sig_[0].data.numpy(), 'r', t, mean_[0].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_std_dev` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 5, 3)\n",
    "        self.fc1 = nn.Linear(46 * 5, 5)\n",
    "        self.mp = nn.MaxPool1d(2, 2)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features = 5)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features = 5)\n",
    "        self.bnfc = nn.BatchNorm1d(num_features = 5)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal_ = running_std_dev(signal, window_size = 10)\n",
    "        signal_ = signal_.view(-1, 3, 50)\n",
    "        out = F.relu(self.conv1(signal_))\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.bn2(out)\n",
    "        out = out.view(-1, 46 * 5)\n",
    "        out = F.log_softmax(self.bnfc(self.fc1(out)), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  24  loss =  1.5915772914886475\n",
      "epoch =  0  step =  20  of total steps  24  loss =  1.5109798908233643\n",
      "epoch =  0  step =  40  of total steps  24  loss =  1.474916696548462\n",
      "epoch =  0  step =  60  of total steps  24  loss =  1.7542158365249634\n",
      "epoch :  0  /  30  | TL :  1.6536096938668865  | VL :  1.5527667999267578\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  24  loss =  1.5564055442810059\n",
      "epoch =  1  step =  20  of total steps  24  loss =  1.458630919456482\n",
      "epoch =  1  step =  40  of total steps  24  loss =  1.3727484941482544\n",
      "epoch =  1  step =  60  of total steps  24  loss =  1.277813196182251\n",
      "epoch :  1  /  30  | TL :  1.4873102919696128  | VL :  1.4842694997787476\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  24  loss =  1.3420875072479248\n",
      "epoch =  2  step =  20  of total steps  24  loss =  1.5141997337341309\n",
      "epoch =  2  step =  40  of total steps  24  loss =  1.4671512842178345\n",
      "epoch =  2  step =  60  of total steps  24  loss =  1.388037085533142\n",
      "epoch :  2  /  30  | TL :  1.4383495833775768  | VL :  1.4263825416564941\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  24  loss =  1.365372896194458\n",
      "epoch =  3  step =  20  of total steps  24  loss =  1.408215045928955\n",
      "epoch =  3  step =  40  of total steps  24  loss =  1.558132290840149\n",
      "epoch =  3  step =  60  of total steps  24  loss =  1.3750078678131104\n",
      "epoch :  3  /  30  | TL :  1.4069606555651313  | VL :  1.4214377403259277\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  24  loss =  1.5007541179656982\n",
      "epoch =  4  step =  20  of total steps  24  loss =  1.1930480003356934\n",
      "epoch =  4  step =  40  of total steps  24  loss =  1.3849663734436035\n",
      "epoch =  4  step =  60  of total steps  24  loss =  1.120690941810608\n",
      "epoch :  4  /  30  | TL :  1.3657008719770876  | VL :  1.371471881866455\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  24  loss =  1.4087554216384888\n",
      "epoch =  5  step =  20  of total steps  24  loss =  1.3455548286437988\n",
      "epoch =  5  step =  40  of total steps  24  loss =  1.3961673974990845\n",
      "epoch =  5  step =  60  of total steps  24  loss =  1.121755838394165\n",
      "epoch :  5  /  30  | TL :  1.3440023072778362  | VL :  1.3309619426727295\n",
      "saving model\n",
      "epoch =  6  step =  0  of total steps  24  loss =  1.4399425983428955\n",
      "epoch =  6  step =  20  of total steps  24  loss =  1.0823360681533813\n",
      "epoch =  6  step =  40  of total steps  24  loss =  1.3000653982162476\n",
      "epoch =  6  step =  60  of total steps  24  loss =  1.5991154909133911\n",
      "epoch :  6  /  30  | TL :  1.3107717216831365  | VL :  1.30765700340271\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  24  loss =  1.282135248184204\n",
      "epoch =  7  step =  20  of total steps  24  loss =  1.3511239290237427\n",
      "epoch =  7  step =  40  of total steps  24  loss =  1.0557453632354736\n",
      "epoch =  7  step =  60  of total steps  24  loss =  1.5855082273483276\n",
      "epoch :  7  /  30  | TL :  1.2851432080138219  | VL :  1.3126702308654785\n",
      "epoch =  8  step =  0  of total steps  24  loss =  1.2972432374954224\n",
      "epoch =  8  step =  20  of total steps  24  loss =  1.5268574953079224\n",
      "epoch =  8  step =  40  of total steps  24  loss =  0.9553670287132263\n",
      "epoch =  8  step =  60  of total steps  24  loss =  1.161264419555664\n",
      "epoch :  8  /  30  | TL :  1.2642034422861386  | VL :  1.3216208219528198\n",
      "epoch =  9  step =  0  of total steps  24  loss =  1.5361160039901733\n",
      "epoch =  9  step =  20  of total steps  24  loss =  1.1575207710266113\n",
      "epoch =  9  step =  40  of total steps  24  loss =  1.1924257278442383\n",
      "epoch =  9  step =  60  of total steps  24  loss =  1.0472818613052368\n",
      "epoch :  9  /  30  | TL :  1.2581690909111336  | VL :  1.296156406402588\n",
      "saving model\n",
      "epoch =  10  step =  0  of total steps  24  loss =  1.4648655652999878\n",
      "epoch =  10  step =  20  of total steps  24  loss =  1.449369192123413\n",
      "epoch =  10  step =  40  of total steps  24  loss =  1.0382721424102783\n",
      "epoch =  10  step =  60  of total steps  24  loss =  1.2700061798095703\n",
      "epoch :  10  /  30  | TL :  1.2365038901159209  | VL :  1.2643380165100098\n",
      "saving model\n",
      "epoch =  11  step =  0  of total steps  24  loss =  1.2757078409194946\n",
      "epoch =  11  step =  20  of total steps  24  loss =  1.2455470561981201\n",
      "epoch =  11  step =  40  of total steps  24  loss =  1.1325781345367432\n",
      "epoch =  11  step =  60  of total steps  24  loss =  1.3849530220031738\n",
      "epoch :  11  /  30  | TL :  1.2093324057043415  | VL :  1.3011257648468018\n",
      "epoch =  12  step =  0  of total steps  24  loss =  1.3356448411941528\n",
      "epoch =  12  step =  20  of total steps  24  loss =  1.173122525215149\n",
      "epoch =  12  step =  40  of total steps  24  loss =  1.0693538188934326\n",
      "epoch =  12  step =  60  of total steps  24  loss =  1.1765739917755127\n",
      "epoch :  12  /  30  | TL :  1.2051251791927913  | VL :  1.2863506078720093\n",
      "epoch =  13  step =  0  of total steps  24  loss =  0.9185419082641602\n",
      "epoch =  13  step =  20  of total steps  24  loss =  1.1788575649261475\n",
      "epoch =  13  step =  40  of total steps  24  loss =  1.0805847644805908\n",
      "epoch =  13  step =  60  of total steps  24  loss =  1.1558542251586914\n",
      "epoch :  13  /  30  | TL :  1.1838056110355952  | VL :  1.2896466255187988\n",
      "epoch =  14  step =  0  of total steps  24  loss =  1.0677951574325562\n",
      "epoch =  14  step =  20  of total steps  24  loss =  1.24543297290802\n",
      "epoch =  14  step =  40  of total steps  24  loss =  1.3538049459457397\n",
      "epoch =  14  step =  60  of total steps  24  loss =  1.076460361480713\n",
      "epoch :  14  /  30  | TL :  1.1747662498526377  | VL :  1.262938380241394\n",
      "saving model\n",
      "epoch =  15  step =  0  of total steps  24  loss =  1.300122618675232\n",
      "epoch =  15  step =  20  of total steps  24  loss =  1.270992636680603\n",
      "epoch =  15  step =  40  of total steps  24  loss =  1.3661311864852905\n",
      "epoch =  15  step =  60  of total steps  24  loss =  1.1055549383163452\n",
      "epoch :  15  /  30  | TL :  1.173721730709076  | VL :  1.2685959339141846\n",
      "epoch =  16  step =  0  of total steps  24  loss =  1.0054668188095093\n",
      "epoch =  16  step =  20  of total steps  24  loss =  0.9830688238143921\n",
      "epoch =  16  step =  40  of total steps  24  loss =  1.1810587644577026\n",
      "epoch =  16  step =  60  of total steps  24  loss =  1.389623999595642\n",
      "epoch :  16  /  30  | TL :  1.16385477046444  | VL :  1.2561317682266235\n",
      "saving model\n",
      "epoch =  17  step =  0  of total steps  24  loss =  1.3564980030059814\n",
      "epoch =  17  step =  20  of total steps  24  loss =  1.1083053350448608\n",
      "epoch =  17  step =  40  of total steps  24  loss =  1.2584996223449707\n",
      "epoch =  17  step =  60  of total steps  24  loss =  1.1147863864898682\n",
      "epoch :  17  /  30  | TL :  1.1411574646218183  | VL :  1.2523555755615234\n",
      "saving model\n",
      "epoch =  18  step =  0  of total steps  24  loss =  1.023354411125183\n",
      "epoch =  18  step =  20  of total steps  24  loss =  0.8993639349937439\n",
      "epoch =  18  step =  40  of total steps  24  loss =  1.4132812023162842\n",
      "epoch =  18  step =  60  of total steps  24  loss =  0.8489101529121399\n",
      "epoch :  18  /  30  | TL :  1.1374710422672638  | VL :  1.2577648162841797\n",
      "epoch =  19  step =  0  of total steps  24  loss =  1.2338194847106934\n",
      "epoch =  19  step =  20  of total steps  24  loss =  1.0799100399017334\n",
      "epoch =  19  step =  40  of total steps  24  loss =  1.451222538948059\n",
      "epoch =  19  step =  60  of total steps  24  loss =  1.2180944681167603\n",
      "epoch :  19  /  30  | TL :  1.13540703139893  | VL :  1.2481663227081299\n",
      "saving model\n",
      "epoch =  20  step =  0  of total steps  24  loss =  1.1720162630081177\n",
      "epoch =  20  step =  20  of total steps  24  loss =  1.0338292121887207\n",
      "epoch =  20  step =  40  of total steps  24  loss =  1.1189615726470947\n",
      "epoch =  20  step =  60  of total steps  24  loss =  1.273023009300232\n",
      "epoch :  20  /  30  | TL :  1.132810398323895  | VL :  1.2598633766174316\n",
      "epoch =  21  step =  0  of total steps  24  loss =  1.0840789079666138\n",
      "epoch =  21  step =  20  of total steps  24  loss =  1.1232646703720093\n",
      "epoch =  21  step =  40  of total steps  24  loss =  1.3584263324737549\n",
      "epoch =  21  step =  60  of total steps  24  loss =  1.2384157180786133\n",
      "epoch :  21  /  30  | TL :  1.130017149121794  | VL :  1.2476024627685547\n",
      "saving model\n",
      "epoch =  22  step =  0  of total steps  24  loss =  1.0938506126403809\n",
      "epoch =  22  step =  20  of total steps  24  loss =  1.1870313882827759\n",
      "epoch =  22  step =  40  of total steps  24  loss =  1.3916808366775513\n",
      "epoch =  22  step =  60  of total steps  24  loss =  1.1255205869674683\n",
      "epoch :  22  /  30  | TL :  1.119125005317061  | VL :  1.2653919458389282\n",
      "epoch =  23  step =  0  of total steps  24  loss =  1.1669145822525024\n",
      "epoch =  23  step =  20  of total steps  24  loss =  1.1095833778381348\n",
      "epoch =  23  step =  40  of total steps  24  loss =  1.1835598945617676\n",
      "epoch =  23  step =  60  of total steps  24  loss =  1.2113662958145142\n",
      "epoch :  23  /  30  | TL :  1.118927776813507  | VL :  1.2656968832015991\n",
      "epoch =  24  step =  0  of total steps  24  loss =  1.150303602218628\n",
      "epoch =  24  step =  20  of total steps  24  loss =  1.2837120294570923\n",
      "epoch =  24  step =  40  of total steps  24  loss =  0.9228520393371582\n",
      "epoch =  24  step =  60  of total steps  24  loss =  1.0768330097198486\n",
      "epoch :  24  /  30  | TL :  1.1125250622017744  | VL :  1.314347267150879\n",
      "epoch =  25  step =  0  of total steps  24  loss =  0.9356022477149963\n",
      "epoch =  25  step =  20  of total steps  24  loss =  0.8457363843917847\n",
      "epoch =  25  step =  40  of total steps  24  loss =  0.9789284467697144\n",
      "epoch =  25  step =  60  of total steps  24  loss =  1.1486220359802246\n",
      "epoch :  25  /  30  | TL :  1.1042957754984295  | VL :  1.2577146291732788\n",
      "epoch =  26  step =  0  of total steps  24  loss =  0.8912360072135925\n",
      "epoch =  26  step =  20  of total steps  24  loss =  0.9030160307884216\n",
      "epoch =  26  step =  40  of total steps  24  loss =  1.6674878597259521\n",
      "epoch =  26  step =  60  of total steps  24  loss =  0.9227238893508911\n",
      "epoch :  26  /  30  | TL :  1.106340471195848  | VL :  1.2593603134155273\n",
      "epoch =  27  step =  0  of total steps  24  loss =  1.2544090747833252\n",
      "epoch =  27  step =  20  of total steps  24  loss =  0.7962004542350769\n",
      "epoch =  27  step =  40  of total steps  24  loss =  1.028196096420288\n",
      "epoch =  27  step =  60  of total steps  24  loss =  1.4845099449157715\n",
      "epoch :  27  /  30  | TL :  1.09473007019252  | VL :  1.2836909294128418\n",
      "epoch =  28  step =  0  of total steps  24  loss =  1.4272736310958862\n",
      "epoch =  28  step =  20  of total steps  24  loss =  0.9168794751167297\n",
      "epoch =  28  step =  40  of total steps  24  loss =  0.8348355293273926\n",
      "epoch =  28  step =  60  of total steps  24  loss =  1.0307475328445435\n",
      "epoch :  28  /  30  | TL :  1.097880589635405  | VL :  1.2698009014129639\n",
      "epoch =  29  step =  0  of total steps  24  loss =  1.32150399684906\n",
      "epoch =  29  step =  20  of total steps  24  loss =  1.1018472909927368\n",
      "epoch =  29  step =  40  of total steps  24  loss =  1.0353072881698608\n",
      "epoch =  29  step =  60  of total steps  24  loss =  1.522422432899475\n",
      "epoch :  29  /  30  | TL :  1.0906353356087044  | VL :  1.2615635395050049\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '1conv_softmax.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0135c5ee80>,\n",
       " <matplotlib.lines.Line2D at 0x7f0135c5efd0>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(30)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.81849315068494 / 47.91666666666667 / 48.61111111111111\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader, Net) * 100, '/', _get_accuracy(valloader, Net) * 100, '/', _get_accuracy(testloader, Net) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.59246575342466 / 53.47222222222222 / 52.77777777777778\n"
     ]
    }
   ],
   "source": [
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('1conv_softmax.pt'))\n",
    "testing_Net.eval()\n",
    "print(_get_accuracy(trainloader, testing_Net) * 100, '/', _get_accuracy(valloader, testing_Net) * 100, '/', _get_accuracy(testloader, testing_Net) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even using running standard deviation of raw data doesn't help reduce overfitting significantly. So, next we try using running RMS of raw data.\n",
    "\n",
    "### PyTorch implementation of `running_rms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_rms(signal, window_size = 10):\n",
    "    ''' Returns running rms of 3D signal (batch_size, length, channels)\n",
    "    Note : torch.norm just gives vector 2-norm, so we need to divide it by\n",
    "    sqrt(window_size) to make it the RMS value\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    n = np.sqrt(window_size)\n",
    "    div = torch.tensor(np.array([n, n, n])).float()\n",
    "    if torch.cuda.is_available() : \n",
    "        div = div.cuda()\n",
    "    \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].norm(dim = 0) / div\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = signal[i][j]\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_rms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected backend CPU and dtype Double but got backend CPU and dtype Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-97bcda305a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_rms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msig_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-f81c4c7abaca>\u001b[0m in \u001b[0;36mrunning_rms\u001b[0;34m(signal, window_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected backend CPU and dtype Double but got backend CPU and dtype Float"
     ]
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "if torch.cuda.is_available() :\n",
    "    signal = signal.cuda().float()\n",
    "rms = running_rms(signal, window_size = 10)\n",
    "print(rms.shape)\n",
    "sig_ = signal[0].transpose(0, 1).cpu()\n",
    "mean_ = rms[0].transpose(0, 1).cpu()\n",
    "t = range(50)\n",
    "plt.plot(t, sig_[1].data.numpy(), 'r', t, mean_[1].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_rms` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 5, 3)\n",
    "        self.fc1 = nn.Linear(46 * 5, 5)\n",
    "#         self.mp = nn.MaxPool1d(2, 2)\n",
    "#         self.dropout = nn.Dropout(p = 0.5)\n",
    "#         self.bn1 = nn.BatchNorm1d(num_features = 5)\n",
    "#         self.bn2 = nn.BatchNorm1d(num_features = 5)\n",
    "#         self.bnfc = nn.BatchNorm1d(num_features = 5)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal_ = running_rms(signal, window_size = 10)\n",
    "        signal_ = signal_.view(-1, 3, 50)\n",
    "        out = F.relu(self.conv1(signal_))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out.view(-1, 46 * 5)\n",
    "        out = F.log_softmax(self.fc1(out), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  24  loss =  1.8811068534851074\n",
      "epoch =  0  step =  20  of total steps  24  loss =  1.3653590679168701\n",
      "epoch =  0  step =  40  of total steps  24  loss =  1.2853695154190063\n",
      "epoch =  0  step =  60  of total steps  24  loss =  1.291702389717102\n",
      "epoch :  0  /  30  | TL :  1.3621268599000695  | VL :  1.3164602518081665\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  24  loss =  1.2448471784591675\n",
      "epoch =  1  step =  20  of total steps  24  loss =  1.0377711057662964\n",
      "epoch =  1  step =  40  of total steps  24  loss =  1.0086761713027954\n",
      "epoch =  1  step =  60  of total steps  24  loss =  1.180564522743225\n",
      "epoch :  1  /  30  | TL :  1.2508377130717447  | VL :  1.3296135663986206\n",
      "epoch =  2  step =  0  of total steps  24  loss =  1.1189979314804077\n",
      "epoch =  2  step =  20  of total steps  24  loss =  1.2224631309509277\n",
      "epoch =  2  step =  40  of total steps  24  loss =  1.1607489585876465\n",
      "epoch =  2  step =  60  of total steps  24  loss =  1.1938399076461792\n",
      "epoch :  2  /  30  | TL :  1.2393064768347022  | VL :  1.3060611486434937\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  24  loss =  1.3021384477615356\n",
      "epoch =  3  step =  20  of total steps  24  loss =  1.0817525386810303\n",
      "epoch =  3  step =  40  of total steps  24  loss =  1.2776519060134888\n",
      "epoch =  3  step =  60  of total steps  24  loss =  1.546712875366211\n",
      "epoch :  3  /  30  | TL :  1.2372265988833284  | VL :  1.301056981086731\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  24  loss =  1.532987117767334\n",
      "epoch =  4  step =  20  of total steps  24  loss =  1.1698825359344482\n",
      "epoch =  4  step =  40  of total steps  24  loss =  1.30800461769104\n",
      "epoch =  4  step =  60  of total steps  24  loss =  1.0630090236663818\n",
      "epoch :  4  /  30  | TL :  1.2289143237349105  | VL :  1.302204966545105\n",
      "epoch =  5  step =  0  of total steps  24  loss =  1.2924392223358154\n",
      "epoch =  5  step =  20  of total steps  24  loss =  1.6495826244354248\n",
      "epoch =  5  step =  40  of total steps  24  loss =  1.4081907272338867\n",
      "epoch =  5  step =  60  of total steps  24  loss =  1.017055869102478\n",
      "epoch :  5  /  30  | TL :  1.2346076810196653  | VL :  1.3025054931640625\n",
      "epoch =  6  step =  0  of total steps  24  loss =  1.2474825382232666\n",
      "epoch =  6  step =  20  of total steps  24  loss =  1.3606036901474\n",
      "epoch =  6  step =  40  of total steps  24  loss =  1.1784090995788574\n",
      "epoch =  6  step =  60  of total steps  24  loss =  1.2484744787216187\n",
      "epoch :  6  /  30  | TL :  1.219812417683536  | VL :  1.2974063158035278\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  24  loss =  1.1820281744003296\n",
      "epoch =  7  step =  20  of total steps  24  loss =  1.241288661956787\n",
      "epoch =  7  step =  40  of total steps  24  loss =  1.4275249242782593\n",
      "epoch =  7  step =  60  of total steps  24  loss =  1.2391878366470337\n",
      "epoch :  7  /  30  | TL :  1.2275948687775495  | VL :  1.289915919303894\n",
      "saving model\n",
      "epoch =  8  step =  0  of total steps  24  loss =  1.4555037021636963\n",
      "epoch =  8  step =  20  of total steps  24  loss =  1.2025268077850342\n",
      "epoch =  8  step =  40  of total steps  24  loss =  1.2675487995147705\n",
      "epoch =  8  step =  60  of total steps  24  loss =  1.2545719146728516\n",
      "epoch :  8  /  30  | TL :  1.2197730794344863  | VL :  1.2958641052246094\n",
      "epoch =  9  step =  0  of total steps  24  loss =  1.1848511695861816\n",
      "epoch =  9  step =  20  of total steps  24  loss =  1.05252206325531\n",
      "epoch =  9  step =  40  of total steps  24  loss =  1.082357406616211\n",
      "epoch =  9  step =  60  of total steps  24  loss =  1.1562994718551636\n",
      "epoch :  9  /  30  | TL :  1.2205718968012562  | VL :  1.2908395528793335\n",
      "epoch =  10  step =  0  of total steps  24  loss =  1.2513833045959473\n",
      "epoch =  10  step =  20  of total steps  24  loss =  1.293017029762268\n",
      "epoch =  10  step =  40  of total steps  24  loss =  1.0824171304702759\n",
      "epoch =  10  step =  60  of total steps  24  loss =  1.2718755006790161\n",
      "epoch :  10  /  30  | TL :  1.216893639466534  | VL :  1.3025002479553223\n",
      "epoch =  11  step =  0  of total steps  24  loss =  1.1819859743118286\n",
      "epoch =  11  step =  20  of total steps  24  loss =  1.2223892211914062\n",
      "epoch =  11  step =  40  of total steps  24  loss =  0.9674538373947144\n",
      "epoch =  11  step =  60  of total steps  24  loss =  1.4180184602737427\n",
      "epoch :  11  /  30  | TL :  1.2137230520379054  | VL :  1.2875325679779053\n",
      "saving model\n",
      "epoch =  12  step =  0  of total steps  24  loss =  1.0180778503417969\n",
      "epoch =  12  step =  20  of total steps  24  loss =  1.232564091682434\n",
      "epoch =  12  step =  40  of total steps  24  loss =  1.1419188976287842\n",
      "epoch =  12  step =  60  of total steps  24  loss =  1.365647554397583\n",
      "epoch :  12  /  30  | TL :  1.2164667501841506  | VL :  1.292335033416748\n",
      "epoch =  13  step =  0  of total steps  24  loss =  1.1962147951126099\n",
      "epoch =  13  step =  20  of total steps  24  loss =  1.2276442050933838\n",
      "epoch =  13  step =  40  of total steps  24  loss =  1.3981281518936157\n",
      "epoch =  13  step =  60  of total steps  24  loss =  1.1903408765792847\n",
      "epoch :  13  /  30  | TL :  1.2139642524392638  | VL :  1.29463529586792\n",
      "epoch =  14  step =  0  of total steps  24  loss =  1.1561352014541626\n",
      "epoch =  14  step =  20  of total steps  24  loss =  1.2134164571762085\n",
      "epoch =  14  step =  40  of total steps  24  loss =  1.145789384841919\n",
      "epoch =  14  step =  60  of total steps  24  loss =  1.2947076559066772\n",
      "epoch :  14  /  30  | TL :  1.210951222948832  | VL :  1.3021929264068604\n",
      "epoch =  15  step =  0  of total steps  24  loss =  1.118507742881775\n",
      "epoch =  15  step =  20  of total steps  24  loss =  0.9740551710128784\n",
      "epoch =  15  step =  40  of total steps  24  loss =  1.240596890449524\n",
      "epoch =  15  step =  60  of total steps  24  loss =  1.222632884979248\n",
      "epoch :  15  /  30  | TL :  1.211065943110479  | VL :  1.301877498626709\n",
      "epoch =  16  step =  0  of total steps  24  loss =  0.9485311508178711\n",
      "epoch =  16  step =  20  of total steps  24  loss =  1.2361562252044678\n",
      "epoch =  16  step =  40  of total steps  24  loss =  1.2679914236068726\n",
      "epoch =  16  step =  60  of total steps  24  loss =  1.2756195068359375\n",
      "epoch :  16  /  30  | TL :  1.2083104391620583  | VL :  1.2752752304077148\n",
      "saving model\n",
      "epoch =  17  step =  0  of total steps  24  loss =  1.366483449935913\n",
      "epoch =  17  step =  20  of total steps  24  loss =  1.118767499923706\n",
      "epoch =  17  step =  40  of total steps  24  loss =  1.4251952171325684\n",
      "epoch =  17  step =  60  of total steps  24  loss =  1.199074387550354\n",
      "epoch :  17  /  30  | TL :  1.2085544026061281  | VL :  1.291746973991394\n",
      "epoch =  18  step =  0  of total steps  24  loss =  1.32235848903656\n",
      "epoch =  18  step =  20  of total steps  24  loss =  1.3394056558609009\n",
      "epoch =  18  step =  40  of total steps  24  loss =  1.1178864240646362\n",
      "epoch =  18  step =  60  of total steps  24  loss =  1.2698698043823242\n",
      "epoch :  18  /  30  | TL :  1.2111185707458079  | VL :  1.2884950637817383\n",
      "epoch =  19  step =  0  of total steps  24  loss =  1.285465121269226\n",
      "epoch =  19  step =  20  of total steps  24  loss =  1.075966238975525\n",
      "epoch =  19  step =  40  of total steps  24  loss =  1.3953883647918701\n",
      "epoch =  19  step =  60  of total steps  24  loss =  1.3944604396820068\n",
      "epoch :  19  /  30  | TL :  1.206787540488047  | VL :  1.2658805847167969\n",
      "saving model\n",
      "epoch =  20  step =  0  of total steps  24  loss =  1.3673038482666016\n",
      "epoch =  20  step =  20  of total steps  24  loss =  1.4407153129577637\n",
      "epoch =  20  step =  40  of total steps  24  loss =  0.9142886400222778\n",
      "epoch =  20  step =  60  of total steps  24  loss =  1.0346355438232422\n",
      "epoch :  20  /  30  | TL :  1.2091668207351476  | VL :  1.296800136566162\n",
      "epoch =  21  step =  0  of total steps  24  loss =  1.12722647190094\n",
      "epoch =  21  step =  20  of total steps  24  loss =  1.309962272644043\n",
      "epoch =  21  step =  40  of total steps  24  loss =  1.048552393913269\n",
      "epoch =  21  step =  60  of total steps  24  loss =  1.4039450883865356\n",
      "epoch :  21  /  30  | TL :  1.2020688195751137  | VL :  1.294471025466919\n",
      "epoch =  22  step =  0  of total steps  24  loss =  1.223084568977356\n",
      "epoch =  22  step =  20  of total steps  24  loss =  1.4052660465240479\n",
      "epoch =  22  step =  40  of total steps  24  loss =  1.2221784591674805\n",
      "epoch =  22  step =  60  of total steps  24  loss =  1.170488715171814\n",
      "epoch :  22  /  30  | TL :  1.2048019391216644  | VL :  1.2658984661102295\n",
      "epoch =  23  step =  0  of total steps  24  loss =  1.30437171459198\n",
      "epoch =  23  step =  20  of total steps  24  loss =  1.1575068235397339\n",
      "epoch =  23  step =  40  of total steps  24  loss =  1.118457317352295\n",
      "epoch =  23  step =  60  of total steps  24  loss =  1.249645471572876\n",
      "epoch :  23  /  30  | TL :  1.2043895892900964  | VL :  1.2968378067016602\n",
      "epoch =  24  step =  0  of total steps  24  loss =  1.1930707693099976\n",
      "epoch =  24  step =  20  of total steps  24  loss =  1.2849507331848145\n",
      "epoch =  24  step =  40  of total steps  24  loss =  1.4297460317611694\n",
      "epoch =  24  step =  60  of total steps  24  loss =  1.4166173934936523\n",
      "epoch :  24  /  30  | TL :  1.2044420968996334  | VL :  1.2831717729568481\n",
      "epoch =  25  step =  0  of total steps  24  loss =  1.5505131483078003\n",
      "epoch =  25  step =  20  of total steps  24  loss =  1.1154916286468506\n",
      "epoch =  25  step =  40  of total steps  24  loss =  1.3296321630477905\n",
      "epoch =  25  step =  60  of total steps  24  loss =  1.117674708366394\n",
      "epoch :  25  /  30  | TL :  1.2002378318407765  | VL :  1.286512017250061\n",
      "epoch =  26  step =  0  of total steps  24  loss =  1.082871675491333\n",
      "epoch =  26  step =  20  of total steps  24  loss =  1.0742998123168945\n",
      "epoch =  26  step =  40  of total steps  24  loss =  1.3187546730041504\n",
      "epoch =  26  step =  60  of total steps  24  loss =  1.2550493478775024\n",
      "epoch :  26  /  30  | TL :  1.20274107341897  | VL :  1.2927815914154053\n",
      "epoch =  27  step =  0  of total steps  24  loss =  1.1299846172332764\n",
      "epoch =  27  step =  20  of total steps  24  loss =  1.1077907085418701\n",
      "epoch =  27  step =  40  of total steps  24  loss =  0.93753981590271\n",
      "epoch =  27  step =  60  of total steps  24  loss =  1.264987826347351\n",
      "epoch :  27  /  30  | TL :  1.200698932556257  | VL :  1.2815316915512085\n",
      "epoch =  28  step =  0  of total steps  24  loss =  1.385637640953064\n",
      "epoch =  28  step =  20  of total steps  24  loss =  1.2711786031723022\n",
      "epoch =  28  step =  40  of total steps  24  loss =  1.269797444343567\n",
      "epoch =  28  step =  60  of total steps  24  loss =  1.189910888671875\n",
      "epoch :  28  /  30  | TL :  1.1992432515915126  | VL :  1.2752134799957275\n",
      "epoch =  29  step =  0  of total steps  24  loss =  1.288767695426941\n",
      "epoch =  29  step =  20  of total steps  24  loss =  1.16928231716156\n",
      "epoch =  29  step =  40  of total steps  24  loss =  1.0412744283676147\n",
      "epoch =  29  step =  60  of total steps  24  loss =  1.248137354850769\n",
      "epoch :  29  /  30  | TL :  1.1998709236105827  | VL :  1.2694483995437622\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '1conv_softmax.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f012e066dd8>,\n",
       " <matplotlib.lines.Line2D at 0x7f012dffdd68>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(30)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.171232876712324 / 44.44444444444444 / 45.13888888888889\n",
      "48.88698630136986 / 45.13888888888889 / 43.75\n"
     ]
    }
   ],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "        \n",
    "        if torch.cuda.is_available() : \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.cpu().numpy()\n",
    "        pred_ind = pred_ind.data.cpu().numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.eval()\n",
    "\n",
    "print(_get_accuracy(trainloader, Net) * 100, '/', _get_accuracy(valloader, Net) * 100, '/', _get_accuracy(testloader, Net) * 100)\n",
    "\n",
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('1conv_softmax.pt'))\n",
    "testing_Net.eval()\n",
    "print(_get_accuracy(trainloader, testing_Net) * 100, '/', _get_accuracy(valloader, testing_Net) * 100, '/', _get_accuracy(testloader, testing_Net) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
