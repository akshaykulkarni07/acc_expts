{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class (loads data from csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58750, 7)\n",
      "(7300, 7)\n",
      "(7400, 7)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 50\n",
    "channels = 3\n",
    "classes = 4\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('../data/new_train.csv', header = None)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('../data/new_test.csv', header = None)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('../data/new_val.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 3 : ].values\n",
    "        ind = np.argmax(np.sum(y, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + reqd_len, : channels].values\n",
    "        x = x.astype('float')\n",
    "        x = x.reshape(reqd_len, channels)\n",
    "        assert(x.shape == (reqd_len, channels))\n",
    "        assert(label.shape == (classes, ))\n",
    "        return x, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader definitions (provides data in iterable form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "batch_size = 8\n",
    "train_indices = [(i * reqd_len) for i in range(len(trainset) // reqd_len)]\n",
    "val_indices = [(i * reqd_len) for i in range(len(valset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(testset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)\n",
    "\n",
    "# signal, label = next(iter(trainloader))\n",
    "# print(signal.shape)\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_size(n, f, p = 0, s = 1):\n",
    "    ''' Returns output size for given input size (n), filter size (f), padding (p) and stride (s)\n",
    "    for a convolutional layer\n",
    "    '''\n",
    "    return (((n + 2 * p - f) / s) + 1)\n",
    "\n",
    "output_size(50, 5)\n",
    "output_size(46, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig, lab = next(iter(trainloader))\n",
    "# sig2 = sig\n",
    "# sig = torch.transpose(sig, 1, 2)\n",
    "# sig = sig.reshape(-1, 150)\n",
    "# sig_ = sig.numpy()\n",
    "# sig2_ = sig2.numpy()\n",
    "# plt.plot(sig_[0])\n",
    "# plt.plot(sig2_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 10, 5)\n",
    "        self.conv2 = nn.Conv1d(10, 15, 5)\n",
    "#         self.conv3 = nn.Conv1d(15, 20, 3)\n",
    "        self.fc1 = nn.Linear(42 * 15, 4)\n",
    "#         self.fc2 = nn.Linear(128, 64)\n",
    "#         self.fc3 = nn.Linear(64, 4)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal = torch.transpose(signal, 1, 2)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(-1, 42 * 15)\n",
    "        out = F.log_softmax(self.fc1(out), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  48  loss =  1.7725774049758911\n",
      "epoch =  0  step =  20  of total steps  48  loss =  1.3923002481460571\n",
      "epoch =  0  step =  40  of total steps  48  loss =  1.635724425315857\n",
      "epoch =  0  step =  60  of total steps  48  loss =  1.5383427143096924\n",
      "epoch =  0  step =  80  of total steps  48  loss =  1.3559269905090332\n",
      "epoch =  0  step =  100  of total steps  48  loss =  1.1754403114318848\n",
      "epoch =  0  step =  120  of total steps  48  loss =  1.2991706132888794\n",
      "epoch =  0  step =  140  of total steps  48  loss =  1.1665079593658447\n",
      "epoch :  0  /  100  | TL :  1.2690941438283005  | VL :  1.283699870109558\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  48  loss =  1.4013595581054688\n",
      "epoch =  1  step =  20  of total steps  48  loss =  0.9226192235946655\n",
      "epoch =  1  step =  40  of total steps  48  loss =  1.5486972332000732\n",
      "epoch =  1  step =  60  of total steps  48  loss =  1.394718050956726\n",
      "epoch =  1  step =  80  of total steps  48  loss =  1.1064189672470093\n",
      "epoch =  1  step =  100  of total steps  48  loss =  1.0682196617126465\n",
      "epoch =  1  step =  120  of total steps  48  loss =  0.9503055810928345\n",
      "epoch =  1  step =  140  of total steps  48  loss =  0.9648985862731934\n",
      "epoch :  1  /  100  | TL :  1.2421146149504674  | VL :  1.3436403274536133\n",
      "epoch =  2  step =  0  of total steps  48  loss =  1.2099988460540771\n",
      "epoch =  2  step =  20  of total steps  48  loss =  1.1542742252349854\n",
      "epoch =  2  step =  40  of total steps  48  loss =  1.2015776634216309\n",
      "epoch =  2  step =  60  of total steps  48  loss =  1.1339952945709229\n",
      "epoch =  2  step =  80  of total steps  48  loss =  0.9373726844787598\n",
      "epoch =  2  step =  100  of total steps  48  loss =  1.3139883279800415\n",
      "epoch =  2  step =  120  of total steps  48  loss =  1.0414652824401855\n",
      "epoch =  2  step =  140  of total steps  48  loss =  1.2716212272644043\n",
      "epoch :  2  /  100  | TL :  1.2431844354492345  | VL :  1.276363730430603\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  48  loss =  1.145534873008728\n",
      "epoch =  3  step =  20  of total steps  48  loss =  1.3833513259887695\n",
      "epoch =  3  step =  40  of total steps  48  loss =  1.0340378284454346\n",
      "epoch =  3  step =  60  of total steps  48  loss =  0.9807270169258118\n",
      "epoch =  3  step =  80  of total steps  48  loss =  1.3799842596054077\n",
      "epoch =  3  step =  100  of total steps  48  loss =  1.1107081174850464\n",
      "epoch =  3  step =  120  of total steps  48  loss =  1.2010643482208252\n",
      "epoch =  3  step =  140  of total steps  48  loss =  1.54420006275177\n",
      "epoch :  3  /  100  | TL :  1.229112783931706  | VL :  1.2844704389572144\n",
      "epoch =  4  step =  0  of total steps  48  loss =  1.4943450689315796\n",
      "epoch =  4  step =  20  of total steps  48  loss =  1.026977300643921\n",
      "epoch =  4  step =  40  of total steps  48  loss =  1.1126134395599365\n",
      "epoch =  4  step =  60  of total steps  48  loss =  1.3806265592575073\n",
      "epoch =  4  step =  80  of total steps  48  loss =  0.8409245014190674\n",
      "epoch =  4  step =  100  of total steps  48  loss =  1.4145344495773315\n",
      "epoch =  4  step =  120  of total steps  48  loss =  1.3938634395599365\n",
      "epoch =  4  step =  140  of total steps  48  loss =  1.1202552318572998\n",
      "epoch :  4  /  100  | TL :  1.2295263589245  | VL :  1.279199242591858\n",
      "epoch =  5  step =  0  of total steps  48  loss =  1.4046962261199951\n",
      "epoch =  5  step =  20  of total steps  48  loss =  1.1113457679748535\n",
      "epoch =  5  step =  40  of total steps  48  loss =  1.3960118293762207\n",
      "epoch =  5  step =  60  of total steps  48  loss =  1.074278473854065\n",
      "epoch =  5  step =  80  of total steps  48  loss =  0.9556664228439331\n",
      "epoch =  5  step =  100  of total steps  48  loss =  0.9921889901161194\n",
      "epoch =  5  step =  120  of total steps  48  loss =  1.4471471309661865\n",
      "epoch =  5  step =  140  of total steps  48  loss =  1.5284911394119263\n",
      "epoch :  5  /  100  | TL :  1.2151573369764301  | VL :  1.2836155891418457\n",
      "epoch =  6  step =  0  of total steps  48  loss =  1.3488917350769043\n",
      "epoch =  6  step =  20  of total steps  48  loss =  1.2928944826126099\n",
      "epoch =  6  step =  40  of total steps  48  loss =  0.8981760144233704\n",
      "epoch =  6  step =  60  of total steps  48  loss =  0.9493052363395691\n",
      "epoch =  6  step =  80  of total steps  48  loss =  1.3819501399993896\n",
      "epoch =  6  step =  100  of total steps  48  loss =  1.3611388206481934\n",
      "epoch =  6  step =  120  of total steps  48  loss =  1.150803804397583\n",
      "epoch =  6  step =  140  of total steps  48  loss =  1.1975069046020508\n",
      "epoch :  6  /  100  | TL :  1.2007535018333018  | VL :  1.288369059562683\n",
      "epoch =  7  step =  0  of total steps  48  loss =  1.0633714199066162\n",
      "epoch =  7  step =  20  of total steps  48  loss =  0.9840644598007202\n",
      "epoch =  7  step =  40  of total steps  48  loss =  1.2709898948669434\n",
      "epoch =  7  step =  60  of total steps  48  loss =  1.1289373636245728\n",
      "epoch =  7  step =  80  of total steps  48  loss =  1.1468743085861206\n",
      "epoch =  7  step =  100  of total steps  48  loss =  1.3681318759918213\n",
      "epoch =  7  step =  120  of total steps  48  loss =  1.1496437788009644\n",
      "epoch =  7  step =  140  of total steps  48  loss =  1.1360018253326416\n",
      "epoch :  7  /  100  | TL :  1.1971757673237422  | VL :  1.3254157304763794\n",
      "epoch =  8  step =  0  of total steps  48  loss =  1.206364393234253\n",
      "epoch =  8  step =  20  of total steps  48  loss =  1.0653212070465088\n",
      "epoch =  8  step =  40  of total steps  48  loss =  1.0186065435409546\n",
      "epoch =  8  step =  60  of total steps  48  loss =  1.1094391345977783\n",
      "epoch =  8  step =  80  of total steps  48  loss =  1.3466012477874756\n",
      "epoch =  8  step =  100  of total steps  48  loss =  1.3343414068222046\n",
      "epoch =  8  step =  120  of total steps  48  loss =  1.1405866146087646\n",
      "epoch =  8  step =  140  of total steps  48  loss =  1.1728906631469727\n",
      "epoch :  8  /  100  | TL :  1.200184069267691  | VL :  1.2723621129989624\n",
      "saving model\n",
      "epoch =  9  step =  0  of total steps  48  loss =  1.1691471338272095\n",
      "epoch =  9  step =  20  of total steps  48  loss =  1.115243673324585\n",
      "epoch =  9  step =  40  of total steps  48  loss =  1.3591787815093994\n",
      "epoch =  9  step =  60  of total steps  48  loss =  1.1020739078521729\n",
      "epoch =  9  step =  80  of total steps  48  loss =  1.3679180145263672\n",
      "epoch =  9  step =  100  of total steps  48  loss =  1.6079916954040527\n",
      "epoch =  9  step =  120  of total steps  48  loss =  1.254388689994812\n",
      "epoch =  9  step =  140  of total steps  48  loss =  0.9350273013114929\n",
      "epoch :  9  /  100  | TL :  1.1902591520792818  | VL :  1.2489895820617676\n",
      "saving model\n",
      "epoch =  10  step =  0  of total steps  48  loss =  0.8829638957977295\n",
      "epoch =  10  step =  20  of total steps  48  loss =  0.8351183533668518\n",
      "epoch =  10  step =  40  of total steps  48  loss =  1.086691975593567\n",
      "epoch =  10  step =  60  of total steps  48  loss =  1.4697695970535278\n",
      "epoch =  10  step =  80  of total steps  48  loss =  0.9869961738586426\n",
      "epoch =  10  step =  100  of total steps  48  loss =  1.2365670204162598\n",
      "epoch =  10  step =  120  of total steps  48  loss =  1.3962914943695068\n",
      "epoch =  10  step =  140  of total steps  48  loss =  1.2587907314300537\n",
      "epoch :  10  /  100  | TL :  1.173406621772949  | VL :  1.2419427633285522\n",
      "saving model\n",
      "epoch =  11  step =  0  of total steps  48  loss =  0.8147100210189819\n",
      "epoch =  11  step =  20  of total steps  48  loss =  0.9746502637863159\n",
      "epoch =  11  step =  40  of total steps  48  loss =  1.0484271049499512\n",
      "epoch =  11  step =  60  of total steps  48  loss =  1.3717052936553955\n",
      "epoch =  11  step =  80  of total steps  48  loss =  1.0164680480957031\n",
      "epoch =  11  step =  100  of total steps  48  loss =  1.1872291564941406\n",
      "epoch =  11  step =  120  of total steps  48  loss =  0.9004585146903992\n",
      "epoch =  11  step =  140  of total steps  48  loss =  1.113981008529663\n",
      "epoch :  11  /  100  | TL :  1.1705659370716304  | VL :  1.2432880401611328\n",
      "epoch =  12  step =  0  of total steps  48  loss =  1.1657075881958008\n",
      "epoch =  12  step =  20  of total steps  48  loss =  1.2200422286987305\n",
      "epoch =  12  step =  40  of total steps  48  loss =  0.8816020488739014\n",
      "epoch =  12  step =  60  of total steps  48  loss =  1.1300246715545654\n",
      "epoch =  12  step =  80  of total steps  48  loss =  1.226270318031311\n",
      "epoch =  12  step =  100  of total steps  48  loss =  0.9258760809898376\n",
      "epoch =  12  step =  120  of total steps  48  loss =  0.9899379014968872\n",
      "epoch =  12  step =  140  of total steps  48  loss =  1.2395892143249512\n",
      "epoch :  12  /  100  | TL :  1.1788695238224447  | VL :  1.234437346458435\n",
      "saving model\n",
      "epoch =  13  step =  0  of total steps  48  loss =  1.0825960636138916\n",
      "epoch =  13  step =  20  of total steps  48  loss =  0.9119174480438232\n",
      "epoch =  13  step =  40  of total steps  48  loss =  1.1547117233276367\n",
      "epoch =  13  step =  60  of total steps  48  loss =  1.0953991413116455\n",
      "epoch =  13  step =  80  of total steps  48  loss =  1.39523446559906\n",
      "epoch =  13  step =  100  of total steps  48  loss =  1.2235054969787598\n",
      "epoch =  13  step =  120  of total steps  48  loss =  1.481978416442871\n",
      "epoch =  13  step =  140  of total steps  48  loss =  1.264437198638916\n",
      "epoch :  13  /  100  | TL :  1.1533914657488262  | VL :  1.2460461854934692\n",
      "epoch =  14  step =  0  of total steps  48  loss =  0.9555590152740479\n",
      "epoch =  14  step =  20  of total steps  48  loss =  0.8423308730125427\n",
      "epoch =  14  step =  40  of total steps  48  loss =  0.9880854487419128\n",
      "epoch =  14  step =  60  of total steps  48  loss =  1.1818608045578003\n",
      "epoch =  14  step =  80  of total steps  48  loss =  1.092095136642456\n",
      "epoch =  14  step =  100  of total steps  48  loss =  0.9737542271614075\n",
      "epoch =  14  step =  120  of total steps  48  loss =  1.0849761962890625\n",
      "epoch =  14  step =  140  of total steps  48  loss =  0.8997703790664673\n",
      "epoch :  14  /  100  | TL :  1.1598168484968683  | VL :  1.225450038909912\n",
      "saving model\n",
      "epoch =  15  step =  0  of total steps  48  loss =  1.2601237297058105\n",
      "epoch =  15  step =  20  of total steps  48  loss =  1.2202818393707275\n",
      "epoch =  15  step =  40  of total steps  48  loss =  0.8800754547119141\n",
      "epoch =  15  step =  60  of total steps  48  loss =  1.2474111318588257\n",
      "epoch =  15  step =  80  of total steps  48  loss =  1.0734624862670898\n",
      "epoch =  15  step =  100  of total steps  48  loss =  1.1927266120910645\n",
      "epoch =  15  step =  120  of total steps  48  loss =  1.064927339553833\n",
      "epoch =  15  step =  140  of total steps  48  loss =  0.8364570736885071\n",
      "epoch :  15  /  100  | TL :  1.1419404994135034  | VL :  1.2489724159240723\n",
      "epoch =  16  step =  0  of total steps  48  loss =  1.27948796749115\n",
      "epoch =  16  step =  20  of total steps  48  loss =  1.214474081993103\n",
      "epoch =  16  step =  40  of total steps  48  loss =  1.3054921627044678\n",
      "epoch =  16  step =  60  of total steps  48  loss =  1.3075311183929443\n",
      "epoch =  16  step =  80  of total steps  48  loss =  1.4160841703414917\n",
      "epoch =  16  step =  100  of total steps  48  loss =  0.7614970803260803\n",
      "epoch =  16  step =  120  of total steps  48  loss =  1.2017854452133179\n",
      "epoch =  16  step =  140  of total steps  48  loss =  0.941247284412384\n",
      "epoch :  16  /  100  | TL :  1.146208501841924  | VL :  1.2484906911849976\n",
      "epoch =  17  step =  0  of total steps  48  loss =  1.1242650747299194\n",
      "epoch =  17  step =  20  of total steps  48  loss =  0.8836699724197388\n",
      "epoch =  17  step =  40  of total steps  48  loss =  0.9816327095031738\n",
      "epoch =  17  step =  60  of total steps  48  loss =  1.3374475240707397\n",
      "epoch =  17  step =  80  of total steps  48  loss =  0.9747371673583984\n",
      "epoch =  17  step =  100  of total steps  48  loss =  1.1418613195419312\n",
      "epoch =  17  step =  120  of total steps  48  loss =  1.178894281387329\n",
      "epoch =  17  step =  140  of total steps  48  loss =  1.4290156364440918\n",
      "epoch :  17  /  100  | TL :  1.142656880698792  | VL :  1.2295786142349243\n",
      "epoch =  18  step =  0  of total steps  48  loss =  1.2162463665008545\n",
      "epoch =  18  step =  20  of total steps  48  loss =  0.8855687379837036\n",
      "epoch =  18  step =  40  of total steps  48  loss =  1.1139880418777466\n",
      "epoch =  18  step =  60  of total steps  48  loss =  1.0315673351287842\n",
      "epoch =  18  step =  80  of total steps  48  loss =  0.9961408376693726\n",
      "epoch =  18  step =  100  of total steps  48  loss =  1.471584439277649\n",
      "epoch =  18  step =  120  of total steps  48  loss =  1.202354073524475\n",
      "epoch =  18  step =  140  of total steps  48  loss =  1.470212459564209\n",
      "epoch :  18  /  100  | TL :  1.1390365864316079  | VL :  1.2553209066390991\n",
      "epoch =  19  step =  0  of total steps  48  loss =  1.297515630722046\n",
      "epoch =  19  step =  20  of total steps  48  loss =  1.3014482259750366\n",
      "epoch =  19  step =  40  of total steps  48  loss =  1.4104092121124268\n",
      "epoch =  19  step =  60  of total steps  48  loss =  0.7166787385940552\n",
      "epoch =  19  step =  80  of total steps  48  loss =  0.996662974357605\n",
      "epoch =  19  step =  100  of total steps  48  loss =  1.3636165857315063\n",
      "epoch =  19  step =  120  of total steps  48  loss =  1.1394171714782715\n",
      "epoch =  19  step =  140  of total steps  48  loss =  1.1462512016296387\n",
      "epoch :  19  /  100  | TL :  1.1332697533581355  | VL :  1.2392525672912598\n",
      "epoch =  20  step =  0  of total steps  48  loss =  1.2501697540283203\n",
      "epoch =  20  step =  20  of total steps  48  loss =  0.7718766331672668\n",
      "epoch =  20  step =  40  of total steps  48  loss =  1.636778712272644\n",
      "epoch =  20  step =  60  of total steps  48  loss =  1.2422358989715576\n",
      "epoch =  20  step =  80  of total steps  48  loss =  1.0508065223693848\n",
      "epoch =  20  step =  100  of total steps  48  loss =  1.2191532850265503\n",
      "epoch =  20  step =  120  of total steps  48  loss =  1.202944040298462\n",
      "epoch =  20  step =  140  of total steps  48  loss =  1.0657296180725098\n",
      "epoch :  20  /  100  | TL :  1.126517358708055  | VL :  1.2634936571121216\n",
      "epoch =  21  step =  0  of total steps  48  loss =  0.9902205467224121\n",
      "epoch =  21  step =  20  of total steps  48  loss =  1.0152034759521484\n",
      "epoch =  21  step =  40  of total steps  48  loss =  0.8770396113395691\n",
      "epoch =  21  step =  60  of total steps  48  loss =  0.7738152742385864\n",
      "epoch =  21  step =  80  of total steps  48  loss =  0.9751035571098328\n",
      "epoch =  21  step =  100  of total steps  48  loss =  1.111497163772583\n",
      "epoch =  21  step =  120  of total steps  48  loss =  1.3437082767486572\n",
      "epoch =  21  step =  140  of total steps  48  loss =  1.068450927734375\n",
      "epoch :  21  /  100  | TL :  1.1208850716891354  | VL :  1.2319788932800293\n",
      "epoch =  22  step =  0  of total steps  48  loss =  1.3267072439193726\n",
      "epoch =  22  step =  20  of total steps  48  loss =  1.0871167182922363\n",
      "epoch =  22  step =  40  of total steps  48  loss =  0.7318866848945618\n",
      "epoch =  22  step =  60  of total steps  48  loss =  0.8704920411109924\n",
      "epoch =  22  step =  80  of total steps  48  loss =  0.8404108881950378\n",
      "epoch =  22  step =  100  of total steps  48  loss =  1.353532075881958\n",
      "epoch =  22  step =  120  of total steps  48  loss =  0.9340207576751709\n",
      "epoch =  22  step =  140  of total steps  48  loss =  0.9149386882781982\n",
      "epoch :  22  /  100  | TL :  1.1170750856399536  | VL :  1.2332510948181152\n",
      "epoch =  23  step =  0  of total steps  48  loss =  1.3219722509384155\n",
      "epoch =  23  step =  20  of total steps  48  loss =  0.8134429454803467\n",
      "epoch =  23  step =  40  of total steps  48  loss =  1.0683366060256958\n",
      "epoch =  23  step =  60  of total steps  48  loss =  1.4330734014511108\n",
      "epoch =  23  step =  80  of total steps  48  loss =  1.2792880535125732\n",
      "epoch =  23  step =  100  of total steps  48  loss =  0.925046443939209\n",
      "epoch =  23  step =  120  of total steps  48  loss =  0.7733291387557983\n",
      "epoch =  23  step =  140  of total steps  48  loss =  1.1455960273742676\n",
      "epoch :  23  /  100  | TL :  1.1152055332921955  | VL :  1.259135365486145\n",
      "epoch =  24  step =  0  of total steps  48  loss =  0.9945987462997437\n",
      "epoch =  24  step =  20  of total steps  48  loss =  0.7094071507453918\n",
      "epoch =  24  step =  40  of total steps  48  loss =  1.3283984661102295\n",
      "epoch =  24  step =  60  of total steps  48  loss =  1.432629108428955\n",
      "epoch =  24  step =  80  of total steps  48  loss =  1.2748873233795166\n",
      "epoch =  24  step =  100  of total steps  48  loss =  1.0608454942703247\n",
      "epoch =  24  step =  120  of total steps  48  loss =  1.3460217714309692\n",
      "epoch =  24  step =  140  of total steps  48  loss =  0.8607863187789917\n",
      "epoch :  24  /  100  | TL :  1.1097093338835728  | VL :  1.247199535369873\n",
      "epoch =  25  step =  0  of total steps  48  loss =  1.178244709968567\n",
      "epoch =  25  step =  20  of total steps  48  loss =  1.341448187828064\n",
      "epoch =  25  step =  40  of total steps  48  loss =  1.0806148052215576\n",
      "epoch =  25  step =  60  of total steps  48  loss =  1.1976754665374756\n",
      "epoch =  25  step =  80  of total steps  48  loss =  1.1722476482391357\n",
      "epoch =  25  step =  100  of total steps  48  loss =  0.7261988520622253\n",
      "epoch =  25  step =  120  of total steps  48  loss =  1.2629016637802124\n",
      "epoch =  25  step =  140  of total steps  48  loss =  1.0233889818191528\n",
      "epoch :  25  /  100  | TL :  1.0996245725514138  | VL :  1.2603282928466797\n",
      "epoch =  26  step =  0  of total steps  48  loss =  0.9156569242477417\n",
      "epoch =  26  step =  20  of total steps  48  loss =  1.2809841632843018\n",
      "epoch =  26  step =  40  of total steps  48  loss =  0.7689666748046875\n",
      "epoch =  26  step =  60  of total steps  48  loss =  0.7953876256942749\n",
      "epoch =  26  step =  80  of total steps  48  loss =  1.289551019668579\n",
      "epoch =  26  step =  100  of total steps  48  loss =  0.9562743306159973\n",
      "epoch =  26  step =  120  of total steps  48  loss =  1.010526180267334\n",
      "epoch =  26  step =  140  of total steps  48  loss =  0.8092415928840637\n",
      "epoch :  26  /  100  | TL :  1.0998111979602134  | VL :  1.2672209739685059\n",
      "epoch =  27  step =  0  of total steps  48  loss =  0.9817711710929871\n",
      "epoch =  27  step =  20  of total steps  48  loss =  1.5902291536331177\n",
      "epoch =  27  step =  40  of total steps  48  loss =  0.9398549199104309\n",
      "epoch =  27  step =  60  of total steps  48  loss =  0.9678078889846802\n",
      "epoch =  27  step =  80  of total steps  48  loss =  1.4364237785339355\n",
      "epoch =  27  step =  100  of total steps  48  loss =  1.05461585521698\n",
      "epoch =  27  step =  120  of total steps  48  loss =  1.1361522674560547\n",
      "epoch =  27  step =  140  of total steps  48  loss =  0.7088710069656372\n",
      "epoch :  27  /  100  | TL :  1.0928796382799542  | VL :  1.2578712701797485\n",
      "epoch =  28  step =  0  of total steps  48  loss =  0.7258084416389465\n",
      "epoch =  28  step =  20  of total steps  48  loss =  0.9189532995223999\n",
      "epoch =  28  step =  40  of total steps  48  loss =  1.1276583671569824\n",
      "epoch =  28  step =  60  of total steps  48  loss =  1.0122674703598022\n",
      "epoch =  28  step =  80  of total steps  48  loss =  1.695798397064209\n",
      "epoch =  28  step =  100  of total steps  48  loss =  0.8827935457229614\n",
      "epoch =  28  step =  120  of total steps  48  loss =  0.992131233215332\n",
      "epoch =  28  step =  140  of total steps  48  loss =  1.6738414764404297\n",
      "epoch :  28  /  100  | TL :  1.0835176963512212  | VL :  1.3032582998275757\n",
      "epoch =  29  step =  0  of total steps  48  loss =  0.8853535056114197\n",
      "epoch =  29  step =  20  of total steps  48  loss =  1.2285306453704834\n",
      "epoch =  29  step =  40  of total steps  48  loss =  1.0410761833190918\n",
      "epoch =  29  step =  60  of total steps  48  loss =  1.246969223022461\n",
      "epoch =  29  step =  80  of total steps  48  loss =  0.9203634858131409\n",
      "epoch =  29  step =  100  of total steps  48  loss =  0.6375660300254822\n",
      "epoch =  29  step =  120  of total steps  48  loss =  1.1082042455673218\n",
      "epoch =  29  step =  140  of total steps  48  loss =  0.8546656966209412\n",
      "epoch :  29  /  100  | TL :  1.091477440236366  | VL :  1.2663683891296387\n",
      "epoch =  30  step =  0  of total steps  48  loss =  0.8702709078788757\n",
      "epoch =  30  step =  20  of total steps  48  loss =  1.4743504524230957\n",
      "epoch =  30  step =  40  of total steps  48  loss =  1.5105693340301514\n",
      "epoch =  30  step =  60  of total steps  48  loss =  0.6003597378730774\n",
      "epoch =  30  step =  80  of total steps  48  loss =  1.0102319717407227\n",
      "epoch =  30  step =  100  of total steps  48  loss =  0.9933209419250488\n",
      "epoch =  30  step =  120  of total steps  48  loss =  0.9851073026657104\n",
      "epoch =  30  step =  140  of total steps  48  loss =  0.849926233291626\n",
      "epoch :  30  /  100  | TL :  1.0907196182094208  | VL :  1.276907205581665\n",
      "epoch =  31  step =  0  of total steps  48  loss =  1.327226161956787\n",
      "epoch =  31  step =  20  of total steps  48  loss =  1.0845273733139038\n",
      "epoch =  31  step =  40  of total steps  48  loss =  0.84325110912323\n",
      "epoch =  31  step =  60  of total steps  48  loss =  0.9075976610183716\n",
      "epoch =  31  step =  80  of total steps  48  loss =  1.2944025993347168\n",
      "epoch =  31  step =  100  of total steps  48  loss =  0.9657061696052551\n",
      "epoch =  31  step =  120  of total steps  48  loss =  1.321489691734314\n",
      "epoch =  31  step =  140  of total steps  48  loss =  0.7800518274307251\n",
      "epoch :  31  /  100  | TL :  1.0712664037534636  | VL :  1.2675318717956543\n",
      "epoch =  32  step =  0  of total steps  48  loss =  0.9758874177932739\n",
      "epoch =  32  step =  20  of total steps  48  loss =  1.2338874340057373\n",
      "epoch =  32  step =  40  of total steps  48  loss =  0.8790864944458008\n",
      "epoch =  32  step =  60  of total steps  48  loss =  1.0037509202957153\n",
      "epoch =  32  step =  80  of total steps  48  loss =  1.092149257659912\n",
      "epoch =  32  step =  100  of total steps  48  loss =  0.621047854423523\n",
      "epoch =  32  step =  120  of total steps  48  loss =  0.5257754921913147\n",
      "epoch =  32  step =  140  of total steps  48  loss =  0.9440812468528748\n",
      "epoch :  32  /  100  | TL :  1.070499986818392  | VL :  1.2669005393981934\n",
      "epoch =  33  step =  0  of total steps  48  loss =  0.9826706647872925\n",
      "epoch =  33  step =  20  of total steps  48  loss =  1.1289377212524414\n",
      "epoch =  33  step =  40  of total steps  48  loss =  1.0320988893508911\n",
      "epoch =  33  step =  60  of total steps  48  loss =  1.241734266281128\n",
      "epoch =  33  step =  80  of total steps  48  loss =  0.7013660073280334\n",
      "epoch =  33  step =  100  of total steps  48  loss =  1.2743852138519287\n",
      "epoch =  33  step =  120  of total steps  48  loss =  0.731532871723175\n",
      "epoch =  33  step =  140  of total steps  48  loss =  1.153193712234497\n",
      "epoch :  33  /  100  | TL :  1.067893119095123  | VL :  1.2574118375778198\n",
      "epoch =  34  step =  0  of total steps  48  loss =  1.137435793876648\n",
      "epoch =  34  step =  20  of total steps  48  loss =  0.8482005000114441\n",
      "epoch =  34  step =  40  of total steps  48  loss =  1.3195762634277344\n",
      "epoch =  34  step =  60  of total steps  48  loss =  1.379579782485962\n",
      "epoch =  34  step =  80  of total steps  48  loss =  1.2724257707595825\n",
      "epoch =  34  step =  100  of total steps  48  loss =  1.0341932773590088\n",
      "epoch =  34  step =  120  of total steps  48  loss =  0.7786599397659302\n",
      "epoch =  34  step =  140  of total steps  48  loss =  1.0286448001861572\n",
      "epoch :  34  /  100  | TL :  1.0599109171188041  | VL :  1.2881280183792114\n",
      "epoch =  35  step =  0  of total steps  48  loss =  0.8712667226791382\n",
      "epoch =  35  step =  20  of total steps  48  loss =  0.9374638199806213\n",
      "epoch =  35  step =  40  of total steps  48  loss =  1.168603539466858\n",
      "epoch =  35  step =  60  of total steps  48  loss =  0.9848056435585022\n",
      "epoch =  35  step =  80  of total steps  48  loss =  0.9790537357330322\n",
      "epoch =  35  step =  100  of total steps  48  loss =  1.1109145879745483\n",
      "epoch =  35  step =  120  of total steps  48  loss =  0.5359655022621155\n",
      "epoch =  35  step =  140  of total steps  48  loss =  0.6635477542877197\n",
      "epoch :  35  /  100  | TL :  1.0594134855352035  | VL :  1.2723745107650757\n",
      "epoch =  36  step =  0  of total steps  48  loss =  1.474290132522583\n",
      "epoch =  36  step =  20  of total steps  48  loss =  1.147686243057251\n",
      "epoch =  36  step =  40  of total steps  48  loss =  1.0691947937011719\n",
      "epoch =  36  step =  60  of total steps  48  loss =  1.309840202331543\n",
      "epoch =  36  step =  80  of total steps  48  loss =  0.8713973760604858\n",
      "epoch =  36  step =  100  of total steps  48  loss =  1.247084379196167\n",
      "epoch =  36  step =  120  of total steps  48  loss =  1.0790681838989258\n",
      "epoch =  36  step =  140  of total steps  48  loss =  0.9991728663444519\n",
      "epoch :  36  /  100  | TL :  1.0513346366686365  | VL :  1.274376392364502\n",
      "epoch =  37  step =  0  of total steps  48  loss =  0.8998923301696777\n",
      "epoch =  37  step =  20  of total steps  48  loss =  1.1975257396697998\n",
      "epoch =  37  step =  40  of total steps  48  loss =  0.9888954162597656\n",
      "epoch =  37  step =  60  of total steps  48  loss =  0.8587646484375\n",
      "epoch =  37  step =  80  of total steps  48  loss =  0.7273651957511902\n",
      "epoch =  37  step =  100  of total steps  48  loss =  1.006618857383728\n",
      "epoch =  37  step =  120  of total steps  48  loss =  1.1303646564483643\n",
      "epoch =  37  step =  140  of total steps  48  loss =  0.6307870149612427\n",
      "epoch :  37  /  100  | TL :  1.0448271313758746  | VL :  1.2609370946884155\n",
      "epoch =  38  step =  0  of total steps  48  loss =  0.8754177093505859\n",
      "epoch =  38  step =  20  of total steps  48  loss =  0.6326447129249573\n",
      "epoch =  38  step =  40  of total steps  48  loss =  1.0716503858566284\n",
      "epoch =  38  step =  60  of total steps  48  loss =  0.840617299079895\n",
      "epoch =  38  step =  80  of total steps  48  loss =  1.0280765295028687\n",
      "epoch =  38  step =  100  of total steps  48  loss =  1.3144395351409912\n",
      "epoch =  38  step =  120  of total steps  48  loss =  0.7172173261642456\n",
      "epoch =  38  step =  140  of total steps  48  loss =  1.5096142292022705\n",
      "epoch :  38  /  100  | TL :  1.0452437864182746  | VL :  1.2666292190551758\n",
      "epoch =  39  step =  0  of total steps  48  loss =  1.024799108505249\n",
      "epoch =  39  step =  20  of total steps  48  loss =  1.0129456520080566\n",
      "epoch =  39  step =  40  of total steps  48  loss =  0.8533029556274414\n",
      "epoch =  39  step =  60  of total steps  48  loss =  1.2252802848815918\n",
      "epoch =  39  step =  80  of total steps  48  loss =  0.8546967506408691\n",
      "epoch =  39  step =  100  of total steps  48  loss =  0.6710441708564758\n",
      "epoch =  39  step =  120  of total steps  48  loss =  1.217391014099121\n",
      "epoch =  39  step =  140  of total steps  48  loss =  1.5337249040603638\n",
      "epoch :  39  /  100  | TL :  1.0441419739429265  | VL :  1.2755247354507446\n",
      "epoch =  40  step =  0  of total steps  48  loss =  1.1618980169296265\n",
      "epoch =  40  step =  20  of total steps  48  loss =  1.3801435232162476\n",
      "epoch =  40  step =  40  of total steps  48  loss =  0.9553791284561157\n",
      "epoch =  40  step =  60  of total steps  48  loss =  0.7934456467628479\n",
      "epoch =  40  step =  80  of total steps  48  loss =  1.171305537223816\n",
      "epoch =  40  step =  100  of total steps  48  loss =  0.9945356845855713\n",
      "epoch =  40  step =  120  of total steps  48  loss =  1.160759687423706\n",
      "epoch =  40  step =  140  of total steps  48  loss =  0.7278594970703125\n",
      "epoch :  40  /  100  | TL :  1.0380135052008173  | VL :  1.26816725730896\n",
      "epoch =  41  step =  0  of total steps  48  loss =  0.9885011911392212\n",
      "epoch =  41  step =  20  of total steps  48  loss =  1.151193618774414\n",
      "epoch =  41  step =  40  of total steps  48  loss =  1.1601980924606323\n",
      "epoch =  41  step =  60  of total steps  48  loss =  0.7030205726623535\n",
      "epoch =  41  step =  80  of total steps  48  loss =  0.9190002679824829\n",
      "epoch =  41  step =  100  of total steps  48  loss =  1.1507452726364136\n",
      "epoch =  41  step =  120  of total steps  48  loss =  1.1460868120193481\n",
      "epoch =  41  step =  140  of total steps  48  loss =  1.1466221809387207\n",
      "epoch :  41  /  100  | TL :  1.0289646170727194  | VL :  1.2555755376815796\n",
      "epoch =  42  step =  0  of total steps  48  loss =  0.8258485198020935\n",
      "epoch =  42  step =  20  of total steps  48  loss =  1.3417694568634033\n",
      "epoch =  42  step =  40  of total steps  48  loss =  1.1092805862426758\n",
      "epoch =  42  step =  60  of total steps  48  loss =  0.9483156204223633\n",
      "epoch =  42  step =  80  of total steps  48  loss =  0.8001888394355774\n",
      "epoch =  42  step =  100  of total steps  48  loss =  1.1658140420913696\n",
      "epoch =  42  step =  120  of total steps  48  loss =  0.8557916879653931\n",
      "epoch =  42  step =  140  of total steps  48  loss =  1.1011275053024292\n",
      "epoch :  42  /  100  | TL :  1.02431397099201  | VL :  1.2827377319335938\n",
      "epoch =  43  step =  0  of total steps  48  loss =  1.0208598375320435\n",
      "epoch =  43  step =  20  of total steps  48  loss =  0.8924435377120972\n",
      "epoch =  43  step =  40  of total steps  48  loss =  0.9034834504127502\n",
      "epoch =  43  step =  60  of total steps  48  loss =  1.4372248649597168\n",
      "epoch =  43  step =  80  of total steps  48  loss =  0.689164400100708\n",
      "epoch =  43  step =  100  of total steps  48  loss =  1.094534993171692\n",
      "epoch =  43  step =  120  of total steps  48  loss =  0.912306547164917\n",
      "epoch =  43  step =  140  of total steps  48  loss =  1.0946049690246582\n",
      "epoch :  43  /  100  | TL :  1.0225568254516548  | VL :  1.2466506958007812\n",
      "epoch =  44  step =  0  of total steps  48  loss =  0.6662085652351379\n",
      "epoch =  44  step =  20  of total steps  48  loss =  0.9656389951705933\n",
      "epoch =  44  step =  40  of total steps  48  loss =  1.0936143398284912\n",
      "epoch =  44  step =  60  of total steps  48  loss =  0.7947933077812195\n",
      "epoch =  44  step =  80  of total steps  48  loss =  0.547522246837616\n",
      "epoch =  44  step =  100  of total steps  48  loss =  1.3153774738311768\n",
      "epoch =  44  step =  120  of total steps  48  loss =  0.8207551836967468\n",
      "epoch =  44  step =  140  of total steps  48  loss =  0.5489610433578491\n",
      "epoch :  44  /  100  | TL :  1.0132647948722318  | VL :  1.3210558891296387\n",
      "epoch =  45  step =  0  of total steps  48  loss =  0.4241032600402832\n",
      "epoch =  45  step =  20  of total steps  48  loss =  1.1241916418075562\n",
      "epoch =  45  step =  40  of total steps  48  loss =  1.2813137769699097\n",
      "epoch =  45  step =  60  of total steps  48  loss =  1.2275029420852661\n",
      "epoch =  45  step =  80  of total steps  48  loss =  0.9778175354003906\n",
      "epoch =  45  step =  100  of total steps  48  loss =  0.7911796569824219\n",
      "epoch =  45  step =  120  of total steps  48  loss =  0.509311854839325\n",
      "epoch =  45  step =  140  of total steps  48  loss =  0.8873063921928406\n",
      "epoch :  45  /  100  | TL :  1.0264456376229247  | VL :  1.303934931755066\n",
      "epoch =  46  step =  0  of total steps  48  loss =  1.0424290895462036\n",
      "epoch =  46  step =  20  of total steps  48  loss =  1.1581834554672241\n",
      "epoch =  46  step =  40  of total steps  48  loss =  0.797671914100647\n",
      "epoch =  46  step =  60  of total steps  48  loss =  0.7655525207519531\n",
      "epoch =  46  step =  80  of total steps  48  loss =  1.0696384906768799\n",
      "epoch =  46  step =  100  of total steps  48  loss =  1.187049150466919\n",
      "epoch =  46  step =  120  of total steps  48  loss =  1.2177486419677734\n",
      "epoch =  46  step =  140  of total steps  48  loss =  1.3795084953308105\n",
      "epoch :  46  /  100  | TL :  1.0164845647060707  | VL :  1.2740193605422974\n",
      "epoch =  47  step =  0  of total steps  48  loss =  0.8202476501464844\n",
      "epoch =  47  step =  20  of total steps  48  loss =  0.7125836610794067\n",
      "epoch =  47  step =  40  of total steps  48  loss =  1.275915503501892\n",
      "epoch =  47  step =  60  of total steps  48  loss =  0.5635114908218384\n",
      "epoch =  47  step =  80  of total steps  48  loss =  0.7912501096725464\n",
      "epoch =  47  step =  100  of total steps  48  loss =  1.1652092933654785\n",
      "epoch =  47  step =  120  of total steps  48  loss =  1.0162945985794067\n",
      "epoch =  47  step =  140  of total steps  48  loss =  1.0637133121490479\n",
      "epoch :  47  /  100  | TL :  1.009780545961367  | VL :  1.2931935787200928\n",
      "epoch =  48  step =  0  of total steps  48  loss =  1.1145002841949463\n",
      "epoch =  48  step =  20  of total steps  48  loss =  0.9453198313713074\n",
      "epoch =  48  step =  40  of total steps  48  loss =  1.1664385795593262\n",
      "epoch =  48  step =  60  of total steps  48  loss =  1.0902531147003174\n",
      "epoch =  48  step =  80  of total steps  48  loss =  0.8479175567626953\n",
      "epoch =  48  step =  100  of total steps  48  loss =  0.47806304693222046\n",
      "epoch =  48  step =  120  of total steps  48  loss =  1.0986928939819336\n",
      "epoch =  48  step =  140  of total steps  48  loss =  1.0140328407287598\n",
      "epoch :  48  /  100  | TL :  1.0119785454175243  | VL :  1.3095563650131226\n",
      "epoch =  49  step =  0  of total steps  48  loss =  0.9690996408462524\n",
      "epoch =  49  step =  20  of total steps  48  loss =  1.2583402395248413\n",
      "epoch =  49  step =  40  of total steps  48  loss =  1.0327595472335815\n",
      "epoch =  49  step =  60  of total steps  48  loss =  1.1665210723876953\n",
      "epoch =  49  step =  80  of total steps  48  loss =  0.8039011359214783\n",
      "epoch =  49  step =  100  of total steps  48  loss =  0.5206596851348877\n",
      "epoch =  49  step =  120  of total steps  48  loss =  0.9361023902893066\n",
      "epoch =  49  step =  140  of total steps  48  loss =  1.2446449995040894\n",
      "epoch :  49  /  100  | TL :  0.9942787779520635  | VL :  1.2942794561386108\n",
      "epoch =  50  step =  0  of total steps  48  loss =  0.980078935623169\n",
      "epoch =  50  step =  20  of total steps  48  loss =  1.0618592500686646\n",
      "epoch =  50  step =  40  of total steps  48  loss =  0.9886064529418945\n",
      "epoch =  50  step =  60  of total steps  48  loss =  0.8014221787452698\n",
      "epoch =  50  step =  80  of total steps  48  loss =  0.5212046504020691\n",
      "epoch =  50  step =  100  of total steps  48  loss =  1.0963844060897827\n",
      "epoch =  50  step =  120  of total steps  48  loss =  0.6599129438400269\n",
      "epoch =  50  step =  140  of total steps  48  loss =  0.9181491136550903\n",
      "epoch :  50  /  100  | TL :  0.9979355545484856  | VL :  1.3091845512390137\n",
      "epoch =  51  step =  0  of total steps  48  loss =  1.0169161558151245\n",
      "epoch =  51  step =  20  of total steps  48  loss =  1.0582067966461182\n",
      "epoch =  51  step =  40  of total steps  48  loss =  0.9667118191719055\n",
      "epoch =  51  step =  60  of total steps  48  loss =  1.0654168128967285\n",
      "epoch =  51  step =  80  of total steps  48  loss =  1.1255525350570679\n",
      "epoch =  51  step =  100  of total steps  48  loss =  1.0682748556137085\n",
      "epoch =  51  step =  120  of total steps  48  loss =  1.326253890991211\n",
      "epoch =  51  step =  140  of total steps  48  loss =  0.9592539072036743\n",
      "epoch :  51  /  100  | TL :  0.9942922134921975  | VL :  1.3240594863891602\n",
      "epoch =  52  step =  0  of total steps  48  loss =  0.8648650646209717\n",
      "epoch =  52  step =  20  of total steps  48  loss =  0.5898959636688232\n",
      "epoch =  52  step =  40  of total steps  48  loss =  1.062744379043579\n",
      "epoch =  52  step =  60  of total steps  48  loss =  0.5129507780075073\n",
      "epoch =  52  step =  80  of total steps  48  loss =  1.0652036666870117\n",
      "epoch =  52  step =  100  of total steps  48  loss =  1.2750458717346191\n",
      "epoch =  52  step =  120  of total steps  48  loss =  1.3618112802505493\n",
      "epoch =  52  step =  140  of total steps  48  loss =  0.8566579222679138\n",
      "epoch :  52  /  100  | TL :  0.9896518749325243  | VL :  1.2975291013717651\n",
      "epoch =  53  step =  0  of total steps  48  loss =  0.8452790379524231\n",
      "epoch =  53  step =  20  of total steps  48  loss =  1.4748893976211548\n",
      "epoch =  53  step =  40  of total steps  48  loss =  0.9424751400947571\n",
      "epoch =  53  step =  60  of total steps  48  loss =  1.1503982543945312\n",
      "epoch =  53  step =  80  of total steps  48  loss =  0.9209546446800232\n",
      "epoch =  53  step =  100  of total steps  48  loss =  0.7772603034973145\n",
      "epoch =  53  step =  120  of total steps  48  loss =  0.9168277978897095\n",
      "epoch =  53  step =  140  of total steps  48  loss =  0.7261002063751221\n",
      "epoch :  53  /  100  | TL :  0.983324528761106  | VL :  1.325609564781189\n",
      "epoch =  54  step =  0  of total steps  48  loss =  0.6892215609550476\n",
      "epoch =  54  step =  20  of total steps  48  loss =  0.5727756023406982\n",
      "epoch =  54  step =  40  of total steps  48  loss =  1.0412888526916504\n",
      "epoch =  54  step =  60  of total steps  48  loss =  1.185681700706482\n",
      "epoch =  54  step =  80  of total steps  48  loss =  0.930016040802002\n",
      "epoch =  54  step =  100  of total steps  48  loss =  1.4093371629714966\n",
      "epoch =  54  step =  120  of total steps  48  loss =  0.9404767155647278\n",
      "epoch =  54  step =  140  of total steps  48  loss =  1.5400607585906982\n",
      "epoch :  54  /  100  | TL :  0.976443396855707  | VL :  1.3558602333068848\n",
      "epoch =  55  step =  0  of total steps  48  loss =  0.553867757320404\n",
      "epoch =  55  step =  20  of total steps  48  loss =  0.6184340119361877\n",
      "epoch =  55  step =  40  of total steps  48  loss =  1.1662297248840332\n",
      "epoch =  55  step =  60  of total steps  48  loss =  1.182083249092102\n",
      "epoch =  55  step =  80  of total steps  48  loss =  1.1348638534545898\n",
      "epoch =  55  step =  100  of total steps  48  loss =  0.9434614181518555\n",
      "epoch =  55  step =  120  of total steps  48  loss =  1.0324406623840332\n",
      "epoch =  55  step =  140  of total steps  48  loss =  1.440816879272461\n",
      "epoch :  55  /  100  | TL :  0.9776721070074055  | VL :  1.3555446863174438\n",
      "epoch =  56  step =  0  of total steps  48  loss =  0.8847543597221375\n",
      "epoch =  56  step =  20  of total steps  48  loss =  1.2978594303131104\n",
      "epoch =  56  step =  40  of total steps  48  loss =  0.9535760283470154\n",
      "epoch =  56  step =  60  of total steps  48  loss =  0.8016371130943298\n",
      "epoch =  56  step =  80  of total steps  48  loss =  0.9025925993919373\n",
      "epoch =  56  step =  100  of total steps  48  loss =  0.7460843324661255\n",
      "epoch =  56  step =  120  of total steps  48  loss =  0.7611982822418213\n",
      "epoch =  56  step =  140  of total steps  48  loss =  0.9987260103225708\n",
      "epoch :  56  /  100  | TL :  0.9741971715264124  | VL :  1.3390209674835205\n",
      "epoch =  57  step =  0  of total steps  48  loss =  1.3904165029525757\n",
      "epoch =  57  step =  20  of total steps  48  loss =  0.8906376957893372\n",
      "epoch =  57  step =  40  of total steps  48  loss =  1.3818633556365967\n",
      "epoch =  57  step =  60  of total steps  48  loss =  0.834372341632843\n",
      "epoch =  57  step =  80  of total steps  48  loss =  0.5484004616737366\n",
      "epoch =  57  step =  100  of total steps  48  loss =  0.9022529125213623\n",
      "epoch =  57  step =  120  of total steps  48  loss =  0.9917817115783691\n",
      "epoch =  57  step =  140  of total steps  48  loss =  0.8157660961151123\n",
      "epoch :  57  /  100  | TL :  0.9667333885006708  | VL :  1.2877497673034668\n",
      "epoch =  58  step =  0  of total steps  48  loss =  1.1155935525894165\n",
      "epoch =  58  step =  20  of total steps  48  loss =  0.8997533321380615\n",
      "epoch =  58  step =  40  of total steps  48  loss =  0.9673900604248047\n",
      "epoch =  58  step =  60  of total steps  48  loss =  0.7747566103935242\n",
      "epoch =  58  step =  80  of total steps  48  loss =  0.9890512824058533\n",
      "epoch =  58  step =  100  of total steps  48  loss =  1.064023733139038\n",
      "epoch =  58  step =  120  of total steps  48  loss =  0.9137754440307617\n",
      "epoch =  58  step =  140  of total steps  48  loss =  1.1061211824417114\n",
      "epoch :  58  /  100  | TL :  0.9694110840967257  | VL :  1.3423023223876953\n",
      "epoch =  59  step =  0  of total steps  48  loss =  0.40777525305747986\n",
      "epoch =  59  step =  20  of total steps  48  loss =  1.0540995597839355\n",
      "epoch =  59  step =  40  of total steps  48  loss =  1.0264440774917603\n",
      "epoch =  59  step =  60  of total steps  48  loss =  1.2093061208724976\n",
      "epoch =  59  step =  80  of total steps  48  loss =  0.6682254672050476\n",
      "epoch =  59  step =  100  of total steps  48  loss =  0.9980475306510925\n",
      "epoch =  59  step =  120  of total steps  48  loss =  1.0462301969528198\n",
      "epoch =  59  step =  140  of total steps  48  loss =  0.4572749435901642\n",
      "epoch :  59  /  100  | TL :  0.9671525844972427  | VL :  1.3499417304992676\n",
      "epoch =  60  step =  0  of total steps  48  loss =  1.3682459592819214\n",
      "epoch =  60  step =  20  of total steps  48  loss =  1.0319151878356934\n",
      "epoch =  60  step =  40  of total steps  48  loss =  0.8445402383804321\n",
      "epoch =  60  step =  60  of total steps  48  loss =  0.778986394405365\n",
      "epoch =  60  step =  80  of total steps  48  loss =  0.614037036895752\n",
      "epoch =  60  step =  100  of total steps  48  loss =  1.160020351409912\n",
      "epoch =  60  step =  120  of total steps  48  loss =  0.992326021194458\n",
      "epoch =  60  step =  140  of total steps  48  loss =  0.6094124913215637\n",
      "epoch :  60  /  100  | TL :  0.9630042222672945  | VL :  1.3211216926574707\n",
      "epoch =  61  step =  0  of total steps  48  loss =  0.6608529686927795\n",
      "epoch =  61  step =  20  of total steps  48  loss =  0.7762991189956665\n",
      "epoch =  61  step =  40  of total steps  48  loss =  1.2802318334579468\n",
      "epoch =  61  step =  60  of total steps  48  loss =  0.7084853649139404\n",
      "epoch =  61  step =  80  of total steps  48  loss =  1.0181769132614136\n",
      "epoch =  61  step =  100  of total steps  48  loss =  1.2878094911575317\n",
      "epoch =  61  step =  120  of total steps  48  loss =  0.613808274269104\n",
      "epoch =  61  step =  140  of total steps  48  loss =  0.9561700820922852\n",
      "epoch :  61  /  100  | TL :  0.958254800879792  | VL :  1.3522201776504517\n",
      "epoch =  62  step =  0  of total steps  48  loss =  0.8094788193702698\n",
      "epoch =  62  step =  20  of total steps  48  loss =  0.710074782371521\n",
      "epoch =  62  step =  40  of total steps  48  loss =  0.8176498413085938\n",
      "epoch =  62  step =  60  of total steps  48  loss =  1.3244736194610596\n",
      "epoch =  62  step =  80  of total steps  48  loss =  1.2466398477554321\n",
      "epoch =  62  step =  100  of total steps  48  loss =  0.7702367305755615\n",
      "epoch =  62  step =  120  of total steps  48  loss =  1.2098923921585083\n",
      "epoch =  62  step =  140  of total steps  48  loss =  1.0932703018188477\n",
      "epoch :  62  /  100  | TL :  0.9533425314377432  | VL :  1.331909418106079\n",
      "epoch =  63  step =  0  of total steps  48  loss =  0.8382174372673035\n",
      "epoch =  63  step =  20  of total steps  48  loss =  0.6058049201965332\n",
      "epoch =  63  step =  40  of total steps  48  loss =  0.8826783299446106\n",
      "epoch =  63  step =  60  of total steps  48  loss =  1.2643128633499146\n",
      "epoch =  63  step =  80  of total steps  48  loss =  0.9685385823249817\n",
      "epoch =  63  step =  100  of total steps  48  loss =  0.9437038898468018\n",
      "epoch =  63  step =  120  of total steps  48  loss =  1.3491109609603882\n",
      "epoch =  63  step =  140  of total steps  48  loss =  0.9287992119789124\n",
      "epoch :  63  /  100  | TL :  0.9480339839850387  | VL :  1.3689589500427246\n",
      "epoch =  64  step =  0  of total steps  48  loss =  0.7340972423553467\n",
      "epoch =  64  step =  20  of total steps  48  loss =  1.191037893295288\n",
      "epoch =  64  step =  40  of total steps  48  loss =  1.0176000595092773\n",
      "epoch =  64  step =  60  of total steps  48  loss =  1.0258084535598755\n",
      "epoch =  64  step =  80  of total steps  48  loss =  1.299262285232544\n",
      "epoch =  64  step =  100  of total steps  48  loss =  0.9522191286087036\n",
      "epoch =  64  step =  120  of total steps  48  loss =  0.8740724921226501\n",
      "epoch =  64  step =  140  of total steps  48  loss =  0.6129761934280396\n",
      "epoch :  64  /  100  | TL :  0.9520814296317427  | VL :  1.3424690961837769\n",
      "epoch =  65  step =  0  of total steps  48  loss =  1.1917808055877686\n",
      "epoch =  65  step =  20  of total steps  48  loss =  0.7321786284446716\n",
      "epoch =  65  step =  40  of total steps  48  loss =  0.9176537990570068\n",
      "epoch =  65  step =  60  of total steps  48  loss =  1.6406434774398804\n",
      "epoch =  65  step =  80  of total steps  48  loss =  0.825060248374939\n",
      "epoch =  65  step =  100  of total steps  48  loss =  1.559396743774414\n",
      "epoch =  65  step =  120  of total steps  48  loss =  1.092157244682312\n",
      "epoch =  65  step =  140  of total steps  48  loss =  0.8239396810531616\n",
      "epoch :  65  /  100  | TL :  0.9396405242485543  | VL :  1.3455054759979248\n",
      "epoch =  66  step =  0  of total steps  48  loss =  1.13071870803833\n",
      "epoch =  66  step =  20  of total steps  48  loss =  0.5774219036102295\n",
      "epoch =  66  step =  40  of total steps  48  loss =  1.123953938484192\n",
      "epoch =  66  step =  60  of total steps  48  loss =  1.3130013942718506\n",
      "epoch =  66  step =  80  of total steps  48  loss =  1.0829358100891113\n",
      "epoch =  66  step =  100  of total steps  48  loss =  0.9718538522720337\n",
      "epoch =  66  step =  120  of total steps  48  loss =  1.0002963542938232\n",
      "epoch =  66  step =  140  of total steps  48  loss =  1.083254337310791\n",
      "epoch :  66  /  100  | TL :  0.9346371983012108  | VL :  1.3415685892105103\n",
      "epoch =  67  step =  0  of total steps  48  loss =  1.474636197090149\n",
      "epoch =  67  step =  20  of total steps  48  loss =  1.1037027835845947\n",
      "epoch =  67  step =  40  of total steps  48  loss =  1.1595940589904785\n",
      "epoch =  67  step =  60  of total steps  48  loss =  0.648308515548706\n",
      "epoch =  67  step =  80  of total steps  48  loss =  0.580152690410614\n",
      "epoch =  67  step =  100  of total steps  48  loss =  1.172728180885315\n",
      "epoch =  67  step =  120  of total steps  48  loss =  0.7856199145317078\n",
      "epoch =  67  step =  140  of total steps  48  loss =  0.9784274101257324\n",
      "epoch :  67  /  100  | TL :  0.933259370800567  | VL :  1.3601946830749512\n",
      "epoch =  68  step =  0  of total steps  48  loss =  1.2887942790985107\n",
      "epoch =  68  step =  20  of total steps  48  loss =  0.8219659328460693\n",
      "epoch =  68  step =  40  of total steps  48  loss =  0.6902370452880859\n",
      "epoch =  68  step =  60  of total steps  48  loss =  1.3997927904129028\n",
      "epoch =  68  step =  80  of total steps  48  loss =  1.113133192062378\n",
      "epoch =  68  step =  100  of total steps  48  loss =  0.6390380859375\n",
      "epoch =  68  step =  120  of total steps  48  loss =  0.8630886077880859\n",
      "epoch =  68  step =  140  of total steps  48  loss =  0.6116766333580017\n",
      "epoch :  68  /  100  | TL :  0.9261621477669233  | VL :  1.348441481590271\n",
      "epoch =  69  step =  0  of total steps  48  loss =  0.8529837131500244\n",
      "epoch =  69  step =  20  of total steps  48  loss =  0.4935096204280853\n",
      "epoch =  69  step =  40  of total steps  48  loss =  1.2135066986083984\n",
      "epoch =  69  step =  60  of total steps  48  loss =  0.845609188079834\n",
      "epoch =  69  step =  80  of total steps  48  loss =  0.7885115146636963\n",
      "epoch =  69  step =  100  of total steps  48  loss =  0.672084629535675\n",
      "epoch =  69  step =  120  of total steps  48  loss =  1.1959974765777588\n",
      "epoch =  69  step =  140  of total steps  48  loss =  1.149622917175293\n",
      "epoch :  69  /  100  | TL :  0.9272900544209023  | VL :  1.3506317138671875\n",
      "epoch =  70  step =  0  of total steps  48  loss =  0.9223629236221313\n",
      "epoch =  70  step =  20  of total steps  48  loss =  0.7355360388755798\n",
      "epoch =  70  step =  40  of total steps  48  loss =  0.9952679872512817\n",
      "epoch =  70  step =  60  of total steps  48  loss =  0.6124045848846436\n",
      "epoch =  70  step =  80  of total steps  48  loss =  0.656846284866333\n",
      "epoch =  70  step =  100  of total steps  48  loss =  0.8391038775444031\n",
      "epoch =  70  step =  120  of total steps  48  loss =  0.6709195375442505\n",
      "epoch =  70  step =  140  of total steps  48  loss =  0.7976540923118591\n",
      "epoch :  70  /  100  | TL :  0.919632441989363  | VL :  1.410220980644226\n",
      "epoch =  71  step =  0  of total steps  48  loss =  1.243727684020996\n",
      "epoch =  71  step =  20  of total steps  48  loss =  0.8498834371566772\n",
      "epoch =  71  step =  40  of total steps  48  loss =  0.7659652829170227\n",
      "epoch =  71  step =  60  of total steps  48  loss =  0.819478452205658\n",
      "epoch =  71  step =  80  of total steps  48  loss =  1.1194114685058594\n",
      "epoch =  71  step =  100  of total steps  48  loss =  1.1132359504699707\n",
      "epoch =  71  step =  120  of total steps  48  loss =  0.9981257319450378\n",
      "epoch =  71  step =  140  of total steps  48  loss =  0.7214111089706421\n",
      "epoch :  71  /  100  | TL :  0.9232296780364154  | VL :  1.3372975587844849\n",
      "epoch =  72  step =  0  of total steps  48  loss =  0.879965603351593\n",
      "epoch =  72  step =  20  of total steps  48  loss =  0.44130221009254456\n",
      "epoch =  72  step =  40  of total steps  48  loss =  1.1841709613800049\n",
      "epoch =  72  step =  60  of total steps  48  loss =  1.2186343669891357\n",
      "epoch =  72  step =  80  of total steps  48  loss =  0.8742605447769165\n",
      "epoch =  72  step =  100  of total steps  48  loss =  1.2447296380996704\n",
      "epoch =  72  step =  120  of total steps  48  loss =  1.1500823497772217\n",
      "epoch =  72  step =  140  of total steps  48  loss =  1.5370445251464844\n",
      "epoch :  72  /  100  | TL :  0.927663289724964  | VL :  1.39686918258667\n",
      "epoch =  73  step =  0  of total steps  48  loss =  0.8019951581954956\n",
      "epoch =  73  step =  20  of total steps  48  loss =  0.764551043510437\n",
      "epoch =  73  step =  40  of total steps  48  loss =  1.2435343265533447\n",
      "epoch =  73  step =  60  of total steps  48  loss =  0.7408063411712646\n",
      "epoch =  73  step =  80  of total steps  48  loss =  1.0153813362121582\n",
      "epoch =  73  step =  100  of total steps  48  loss =  1.1608130931854248\n",
      "epoch =  73  step =  120  of total steps  48  loss =  0.7199329137802124\n",
      "epoch =  73  step =  140  of total steps  48  loss =  0.8529031872749329\n",
      "epoch :  73  /  100  | TL :  0.9152239722340074  | VL :  1.3921332359313965\n",
      "epoch =  74  step =  0  of total steps  48  loss =  0.7765002846717834\n",
      "epoch =  74  step =  20  of total steps  48  loss =  1.2169140577316284\n",
      "epoch =  74  step =  40  of total steps  48  loss =  0.937043309211731\n",
      "epoch =  74  step =  60  of total steps  48  loss =  1.271641731262207\n",
      "epoch =  74  step =  80  of total steps  48  loss =  0.7910248041152954\n",
      "epoch =  74  step =  100  of total steps  48  loss =  0.942249596118927\n",
      "epoch =  74  step =  120  of total steps  48  loss =  0.9272974133491516\n",
      "epoch =  74  step =  140  of total steps  48  loss =  0.7271414399147034\n",
      "epoch :  74  /  100  | TL :  0.910789992098939  | VL :  1.3655643463134766\n",
      "epoch =  75  step =  0  of total steps  48  loss =  0.7691360116004944\n",
      "epoch =  75  step =  20  of total steps  48  loss =  0.42621880769729614\n",
      "epoch =  75  step =  40  of total steps  48  loss =  1.2173011302947998\n",
      "epoch =  75  step =  60  of total steps  48  loss =  0.488261878490448\n",
      "epoch =  75  step =  80  of total steps  48  loss =  0.6436132788658142\n",
      "epoch =  75  step =  100  of total steps  48  loss =  0.6394291520118713\n",
      "epoch =  75  step =  120  of total steps  48  loss =  1.0907145738601685\n",
      "epoch =  75  step =  140  of total steps  48  loss =  1.1240673065185547\n",
      "epoch :  75  /  100  | TL :  0.9179353518028782  | VL :  1.4012084007263184\n",
      "epoch =  76  step =  0  of total steps  48  loss =  1.0266966819763184\n",
      "epoch =  76  step =  20  of total steps  48  loss =  1.4323275089263916\n",
      "epoch =  76  step =  40  of total steps  48  loss =  0.5414561033248901\n",
      "epoch =  76  step =  60  of total steps  48  loss =  0.8140060305595398\n",
      "epoch =  76  step =  80  of total steps  48  loss =  0.9724940657615662\n",
      "epoch =  76  step =  100  of total steps  48  loss =  0.739342987537384\n",
      "epoch =  76  step =  120  of total steps  48  loss =  0.9439811706542969\n",
      "epoch =  76  step =  140  of total steps  48  loss =  1.1035271883010864\n",
      "epoch :  76  /  100  | TL :  0.8971809644813407  | VL :  1.3921051025390625\n",
      "epoch =  77  step =  0  of total steps  48  loss =  0.9168250560760498\n",
      "epoch =  77  step =  20  of total steps  48  loss =  0.9762646555900574\n",
      "epoch =  77  step =  40  of total steps  48  loss =  1.356857419013977\n",
      "epoch =  77  step =  60  of total steps  48  loss =  0.5424437522888184\n",
      "epoch =  77  step =  80  of total steps  48  loss =  0.44555750489234924\n",
      "epoch =  77  step =  100  of total steps  48  loss =  0.9951031804084778\n",
      "epoch =  77  step =  120  of total steps  48  loss =  0.6421930193901062\n",
      "epoch =  77  step =  140  of total steps  48  loss =  0.9904965162277222\n",
      "epoch :  77  /  100  | TL :  0.9025923405608086  | VL :  1.4004807472229004\n",
      "epoch =  78  step =  0  of total steps  48  loss =  0.6455988883972168\n",
      "epoch =  78  step =  20  of total steps  48  loss =  1.186805009841919\n",
      "epoch =  78  step =  40  of total steps  48  loss =  1.0517269372940063\n",
      "epoch =  78  step =  60  of total steps  48  loss =  0.877602219581604\n",
      "epoch =  78  step =  80  of total steps  48  loss =  0.9248517751693726\n",
      "epoch =  78  step =  100  of total steps  48  loss =  0.6316578388214111\n",
      "epoch =  78  step =  120  of total steps  48  loss =  0.36973902583122253\n",
      "epoch =  78  step =  140  of total steps  48  loss =  1.360485315322876\n",
      "epoch :  78  /  100  | TL :  0.893790655348399  | VL :  1.404839277267456\n",
      "epoch =  79  step =  0  of total steps  48  loss =  1.1814777851104736\n",
      "epoch =  79  step =  20  of total steps  48  loss =  0.5141177773475647\n",
      "epoch =  79  step =  40  of total steps  48  loss =  0.7061482071876526\n",
      "epoch =  79  step =  60  of total steps  48  loss =  0.9284734725952148\n",
      "epoch =  79  step =  80  of total steps  48  loss =  0.7004145383834839\n",
      "epoch =  79  step =  100  of total steps  48  loss =  0.7401238083839417\n",
      "epoch =  79  step =  120  of total steps  48  loss =  0.8188433647155762\n",
      "epoch =  79  step =  140  of total steps  48  loss =  1.113409399986267\n",
      "epoch :  79  /  100  | TL :  0.8855339625518616  | VL :  1.4708843231201172\n",
      "epoch =  80  step =  0  of total steps  48  loss =  1.0652490854263306\n",
      "epoch =  80  step =  20  of total steps  48  loss =  1.086908221244812\n",
      "epoch =  80  step =  40  of total steps  48  loss =  0.7731471061706543\n",
      "epoch =  80  step =  60  of total steps  48  loss =  0.8879250884056091\n",
      "epoch =  80  step =  80  of total steps  48  loss =  0.9216982126235962\n",
      "epoch =  80  step =  100  of total steps  48  loss =  1.2234249114990234\n",
      "epoch =  80  step =  120  of total steps  48  loss =  1.0915497541427612\n",
      "epoch =  80  step =  140  of total steps  48  loss =  1.2216784954071045\n",
      "epoch :  80  /  100  | TL :  0.892431424905176  | VL :  1.4497666358947754\n",
      "epoch =  81  step =  0  of total steps  48  loss =  1.3190269470214844\n",
      "epoch =  81  step =  20  of total steps  48  loss =  0.7020235657691956\n",
      "epoch =  81  step =  40  of total steps  48  loss =  0.8244233727455139\n",
      "epoch =  81  step =  60  of total steps  48  loss =  0.6423611640930176\n",
      "epoch =  81  step =  80  of total steps  48  loss =  1.4566171169281006\n",
      "epoch =  81  step =  100  of total steps  48  loss =  0.8517124056816101\n",
      "epoch =  81  step =  120  of total steps  48  loss =  0.67774498462677\n",
      "epoch =  81  step =  140  of total steps  48  loss =  0.6278791427612305\n",
      "epoch :  81  /  100  | TL :  0.8875956600659514  | VL :  1.4013164043426514\n",
      "epoch =  82  step =  0  of total steps  48  loss =  1.0255203247070312\n",
      "epoch =  82  step =  20  of total steps  48  loss =  0.6472097039222717\n",
      "epoch =  82  step =  40  of total steps  48  loss =  1.1473009586334229\n",
      "epoch =  82  step =  60  of total steps  48  loss =  1.1911678314208984\n",
      "epoch =  82  step =  80  of total steps  48  loss =  1.4288804531097412\n",
      "epoch =  82  step =  100  of total steps  48  loss =  1.1118489503860474\n",
      "epoch =  82  step =  120  of total steps  48  loss =  0.7283467650413513\n",
      "epoch =  82  step =  140  of total steps  48  loss =  1.1266459226608276\n",
      "epoch :  82  /  100  | TL :  0.8838988140429536  | VL :  1.3876643180847168\n",
      "epoch =  83  step =  0  of total steps  48  loss =  1.0076719522476196\n",
      "epoch =  83  step =  20  of total steps  48  loss =  0.7247059345245361\n",
      "epoch =  83  step =  40  of total steps  48  loss =  0.6294688582420349\n",
      "epoch =  83  step =  60  of total steps  48  loss =  1.2518011331558228\n",
      "epoch =  83  step =  80  of total steps  48  loss =  0.7876226305961609\n",
      "epoch =  83  step =  100  of total steps  48  loss =  1.2121429443359375\n",
      "epoch =  83  step =  120  of total steps  48  loss =  0.8603749871253967\n",
      "epoch =  83  step =  140  of total steps  48  loss =  0.5415336489677429\n",
      "epoch :  83  /  100  | TL :  0.8749885359039046  | VL :  1.3986210823059082\n",
      "epoch =  84  step =  0  of total steps  48  loss =  1.1048721075057983\n",
      "epoch =  84  step =  20  of total steps  48  loss =  0.7727254033088684\n",
      "epoch =  84  step =  40  of total steps  48  loss =  0.5959150791168213\n",
      "epoch =  84  step =  60  of total steps  48  loss =  0.9510476589202881\n",
      "epoch =  84  step =  80  of total steps  48  loss =  1.049340009689331\n",
      "epoch =  84  step =  100  of total steps  48  loss =  0.3264210820198059\n",
      "epoch =  84  step =  120  of total steps  48  loss =  1.4090889692306519\n",
      "epoch =  84  step =  140  of total steps  48  loss =  0.8283461928367615\n",
      "epoch :  84  /  100  | TL :  0.8793607864477863  | VL :  1.40645432472229\n",
      "epoch =  85  step =  0  of total steps  48  loss =  0.899004340171814\n",
      "epoch =  85  step =  20  of total steps  48  loss =  0.7245602011680603\n",
      "epoch =  85  step =  40  of total steps  48  loss =  0.5731841921806335\n",
      "epoch =  85  step =  60  of total steps  48  loss =  0.9533190131187439\n",
      "epoch =  85  step =  80  of total steps  48  loss =  1.0577726364135742\n",
      "epoch =  85  step =  100  of total steps  48  loss =  1.6335335969924927\n",
      "epoch =  85  step =  120  of total steps  48  loss =  0.8841701149940491\n",
      "epoch =  85  step =  140  of total steps  48  loss =  0.9322153925895691\n",
      "epoch :  85  /  100  | TL :  0.8782575293763043  | VL :  1.4454874992370605\n",
      "epoch =  86  step =  0  of total steps  48  loss =  1.1125478744506836\n",
      "epoch =  86  step =  20  of total steps  48  loss =  0.3647451102733612\n",
      "epoch =  86  step =  40  of total steps  48  loss =  0.5137678980827332\n",
      "epoch =  86  step =  60  of total steps  48  loss =  0.6103785037994385\n",
      "epoch =  86  step =  80  of total steps  48  loss =  0.7917826771736145\n",
      "epoch =  86  step =  100  of total steps  48  loss =  1.230324387550354\n",
      "epoch =  86  step =  120  of total steps  48  loss =  0.8096948266029358\n",
      "epoch =  86  step =  140  of total steps  48  loss =  0.662771999835968\n",
      "epoch :  86  /  100  | TL :  0.8622738630191921  | VL :  1.4090322256088257\n",
      "epoch =  87  step =  0  of total steps  48  loss =  0.6974336504936218\n",
      "epoch =  87  step =  20  of total steps  48  loss =  1.1020963191986084\n",
      "epoch =  87  step =  40  of total steps  48  loss =  0.32752907276153564\n",
      "epoch =  87  step =  60  of total steps  48  loss =  0.8393599987030029\n",
      "epoch =  87  step =  80  of total steps  48  loss =  0.929004430770874\n",
      "epoch =  87  step =  100  of total steps  48  loss =  0.5784471035003662\n",
      "epoch =  87  step =  120  of total steps  48  loss =  0.5586370825767517\n",
      "epoch =  87  step =  140  of total steps  48  loss =  1.006453275680542\n",
      "epoch :  87  /  100  | TL :  0.8696282934652616  | VL :  1.5114315748214722\n",
      "epoch =  88  step =  0  of total steps  48  loss =  0.8446290493011475\n",
      "epoch =  88  step =  20  of total steps  48  loss =  1.581719160079956\n",
      "epoch =  88  step =  40  of total steps  48  loss =  0.941923975944519\n",
      "epoch =  88  step =  60  of total steps  48  loss =  0.8047665357589722\n",
      "epoch =  88  step =  80  of total steps  48  loss =  0.8333665132522583\n",
      "epoch =  88  step =  100  of total steps  48  loss =  0.841384768486023\n",
      "epoch =  88  step =  120  of total steps  48  loss =  0.6888712644577026\n",
      "epoch =  88  step =  140  of total steps  48  loss =  0.6442733407020569\n",
      "epoch :  88  /  100  | TL :  0.8652971545106745  | VL :  1.4938997030258179\n",
      "epoch =  89  step =  0  of total steps  48  loss =  0.7676408886909485\n",
      "epoch =  89  step =  20  of total steps  48  loss =  1.2453830242156982\n",
      "epoch =  89  step =  40  of total steps  48  loss =  1.0378731489181519\n",
      "epoch =  89  step =  60  of total steps  48  loss =  0.7790451645851135\n",
      "epoch =  89  step =  80  of total steps  48  loss =  1.1371057033538818\n",
      "epoch =  89  step =  100  of total steps  48  loss =  1.0170336961746216\n",
      "epoch =  89  step =  120  of total steps  48  loss =  0.828705370426178\n",
      "epoch =  89  step =  140  of total steps  48  loss =  0.8837813138961792\n",
      "epoch :  89  /  100  | TL :  0.8558412808669756  | VL :  1.4957475662231445\n",
      "epoch =  90  step =  0  of total steps  48  loss =  0.8872508406639099\n",
      "epoch =  90  step =  20  of total steps  48  loss =  0.644279956817627\n",
      "epoch =  90  step =  40  of total steps  48  loss =  0.6202036142349243\n",
      "epoch =  90  step =  60  of total steps  48  loss =  1.1545499563217163\n",
      "epoch =  90  step =  80  of total steps  48  loss =  0.8817110657691956\n",
      "epoch =  90  step =  100  of total steps  48  loss =  0.5296720266342163\n",
      "epoch =  90  step =  120  of total steps  48  loss =  0.7328216433525085\n",
      "epoch =  90  step =  140  of total steps  48  loss =  0.5720447301864624\n",
      "epoch :  90  /  100  | TL :  0.8555801968051963  | VL :  1.438300609588623\n",
      "epoch =  91  step =  0  of total steps  48  loss =  0.538532018661499\n",
      "epoch =  91  step =  20  of total steps  48  loss =  0.9686122536659241\n",
      "epoch =  91  step =  40  of total steps  48  loss =  0.8948896527290344\n",
      "epoch =  91  step =  60  of total steps  48  loss =  1.167724609375\n",
      "epoch =  91  step =  80  of total steps  48  loss =  1.0206910371780396\n",
      "epoch =  91  step =  100  of total steps  48  loss =  0.8186644315719604\n",
      "epoch =  91  step =  120  of total steps  48  loss =  0.7537679672241211\n",
      "epoch =  91  step =  140  of total steps  48  loss =  0.6896138191223145\n",
      "epoch :  91  /  100  | TL :  0.8521020592075504  | VL :  1.4469977617263794\n",
      "epoch =  92  step =  0  of total steps  48  loss =  0.7016944885253906\n",
      "epoch =  92  step =  20  of total steps  48  loss =  0.9302628636360168\n",
      "epoch =  92  step =  40  of total steps  48  loss =  0.9077075719833374\n",
      "epoch =  92  step =  60  of total steps  48  loss =  0.6238993406295776\n",
      "epoch =  92  step =  80  of total steps  48  loss =  0.9115725755691528\n",
      "epoch =  92  step =  100  of total steps  48  loss =  0.4008980691432953\n",
      "epoch =  92  step =  120  of total steps  48  loss =  1.015684723854065\n",
      "epoch =  92  step =  140  of total steps  48  loss =  0.7379207611083984\n",
      "epoch :  92  /  100  | TL :  0.8629627893232319  | VL :  1.4322772026062012\n",
      "epoch =  93  step =  0  of total steps  48  loss =  0.4259926378726959\n",
      "epoch =  93  step =  20  of total steps  48  loss =  0.5443283915519714\n",
      "epoch =  93  step =  40  of total steps  48  loss =  0.34494414925575256\n",
      "epoch =  93  step =  60  of total steps  48  loss =  0.5723710656166077\n",
      "epoch =  93  step =  80  of total steps  48  loss =  0.5685078501701355\n",
      "epoch =  93  step =  100  of total steps  48  loss =  0.5272184610366821\n",
      "epoch =  93  step =  120  of total steps  48  loss =  0.3444826602935791\n",
      "epoch =  93  step =  140  of total steps  48  loss =  0.9699886441230774\n",
      "epoch :  93  /  100  | TL :  0.8548146286239363  | VL :  1.496286392211914\n",
      "epoch =  94  step =  0  of total steps  48  loss =  0.6976682543754578\n",
      "epoch =  94  step =  20  of total steps  48  loss =  1.1302162408828735\n",
      "epoch =  94  step =  40  of total steps  48  loss =  0.669916033744812\n",
      "epoch =  94  step =  60  of total steps  48  loss =  1.1625878810882568\n",
      "epoch =  94  step =  80  of total steps  48  loss =  1.0244276523590088\n",
      "epoch =  94  step =  100  of total steps  48  loss =  0.7602337598800659\n",
      "epoch =  94  step =  120  of total steps  48  loss =  1.096509575843811\n",
      "epoch =  94  step =  140  of total steps  48  loss =  0.8649057149887085\n",
      "epoch :  94  /  100  | TL :  0.8488562447975759  | VL :  1.5218417644500732\n",
      "epoch =  95  step =  0  of total steps  48  loss =  0.5473011136054993\n",
      "epoch =  95  step =  20  of total steps  48  loss =  0.5689799785614014\n",
      "epoch =  95  step =  40  of total steps  48  loss =  0.6967347860336304\n",
      "epoch =  95  step =  60  of total steps  48  loss =  0.937805712223053\n",
      "epoch =  95  step =  80  of total steps  48  loss =  0.6387380361557007\n",
      "epoch =  95  step =  100  of total steps  48  loss =  0.880568265914917\n",
      "epoch =  95  step =  120  of total steps  48  loss =  0.9748641848564148\n",
      "epoch =  95  step =  140  of total steps  48  loss =  0.40354955196380615\n",
      "epoch :  95  /  100  | TL :  0.8512149691989978  | VL :  1.5161672830581665\n",
      "epoch =  96  step =  0  of total steps  48  loss =  1.4284203052520752\n",
      "epoch =  96  step =  20  of total steps  48  loss =  0.5641747713088989\n",
      "epoch =  96  step =  40  of total steps  48  loss =  0.833550214767456\n",
      "epoch =  96  step =  60  of total steps  48  loss =  0.7024878263473511\n",
      "epoch =  96  step =  80  of total steps  48  loss =  0.7165382504463196\n",
      "epoch =  96  step =  100  of total steps  48  loss =  0.9478029608726501\n",
      "epoch =  96  step =  120  of total steps  48  loss =  0.43259403109550476\n",
      "epoch =  96  step =  140  of total steps  48  loss =  0.29706478118896484\n",
      "epoch :  96  /  100  | TL :  0.8439864571372123  | VL :  1.4616961479187012\n",
      "epoch =  97  step =  0  of total steps  48  loss =  1.6866884231567383\n",
      "epoch =  97  step =  20  of total steps  48  loss =  1.0454885959625244\n",
      "epoch =  97  step =  40  of total steps  48  loss =  0.7964600920677185\n",
      "epoch =  97  step =  60  of total steps  48  loss =  0.816790759563446\n",
      "epoch =  97  step =  80  of total steps  48  loss =  0.4806085526943207\n",
      "epoch =  97  step =  100  of total steps  48  loss =  0.9783124327659607\n",
      "epoch =  97  step =  120  of total steps  48  loss =  0.6604746580123901\n",
      "epoch =  97  step =  140  of total steps  48  loss =  0.70838463306427\n",
      "epoch :  97  /  100  | TL :  0.8321856317454821  | VL :  1.48030424118042\n",
      "epoch =  98  step =  0  of total steps  48  loss =  0.8178266882896423\n",
      "epoch =  98  step =  20  of total steps  48  loss =  1.0721111297607422\n",
      "epoch =  98  step =  40  of total steps  48  loss =  1.0330122709274292\n",
      "epoch =  98  step =  60  of total steps  48  loss =  1.1768698692321777\n",
      "epoch =  98  step =  80  of total steps  48  loss =  0.9061975479125977\n",
      "epoch =  98  step =  100  of total steps  48  loss =  0.8353883028030396\n",
      "epoch =  98  step =  120  of total steps  48  loss =  1.3923386335372925\n",
      "epoch =  98  step =  140  of total steps  48  loss =  0.8919932842254639\n",
      "epoch :  98  /  100  | TL :  0.8397258758953173  | VL :  1.528507947921753\n",
      "epoch =  99  step =  0  of total steps  48  loss =  0.7490993142127991\n",
      "epoch =  99  step =  20  of total steps  48  loss =  0.6922174096107483\n",
      "epoch =  99  step =  40  of total steps  48  loss =  0.5771328806877136\n",
      "epoch =  99  step =  60  of total steps  48  loss =  1.231707215309143\n",
      "epoch =  99  step =  80  of total steps  48  loss =  1.0854688882827759\n",
      "epoch =  99  step =  100  of total steps  48  loss =  0.7529648542404175\n",
      "epoch =  99  step =  120  of total steps  48  loss =  0.8408483266830444\n",
      "epoch =  99  step =  140  of total steps  48  loss =  0.5894274711608887\n",
      "epoch :  99  /  100  | TL :  0.8314421085053927  | VL :  1.5155826807022095\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '../saved_models/new_fc_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9d4e559128>,\n",
       " <matplotlib.lines.Line2D at 0x7f9d4e559278>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(100)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv1d(3, 10, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(10, 15, kernel_size=(5,), stride=(1,))\n",
       "  (fc1): Linear(in_features=630, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_accuracy(dataloader):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net.cpu()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7157534246575342\n",
      "0.4375\n",
      "0.4513888888888889\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader))\n",
    "print(_get_accuracy(testloader))\n",
    "print(_get_accuracy(valloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directly training NNs on raw data doesn't work well (network overfits most of the time). So, we can try to use some pre-processing to the data before training (like running mean, running std deviation, running rms, etc.)\n",
    "\n",
    "### PyTorch implementation of `running_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(signal, window_size = 10):\n",
    "    ''' Returns running mean of 3D signal (batch_size, length, channels)\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].mean(dim = 0)\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = signal[i][j]\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_mean` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 150, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2bb62ed7f0>,\n",
       " <matplotlib.lines.Line2D at 0x7f2bb62ed940>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "# print(signal.shape)\n",
    "# print(signal[2].shape)\n",
    "# print(signal[2].mean(dim = 0).shape)\n",
    "# print(signal[2][ : 10].mean(dim = 0).shape)\n",
    "# print(signal[1][2].shape)\n",
    "mean = running_mean(signal, window_size = 5)\n",
    "print(mean.shape)\n",
    "sig_ = signal[0].transpose(0, 1)\n",
    "mean_ = mean[0].transpose(0, 1)\n",
    "t = range(150)\n",
    "plt.plot(t, sig_[1].data.numpy(), 'r', t, mean_[1].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_mean` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.fc1 = nn.Linear(148 * 5, 5)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal_ = running_mean(signal, window_size = 5)\n",
    "        signal_ = signal_.view(-1, 3, 150)\n",
    "        out = F.relu(self.conv1(signal_))\n",
    "        out = out.view(-1, 148 * 5)\n",
    "        out = F.log_softmax(self.fc1(out), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  106  loss =  1.5382548570632935\n",
      "epoch =  0  step =  20  of total steps  106  loss =  2.0540518760681152\n",
      "epoch =  0  step =  40  of total steps  106  loss =  1.498380422592163\n",
      "epoch =  0  step =  60  of total steps  106  loss =  1.5275654792785645\n",
      "epoch =  0  step =  80  of total steps  106  loss =  1.9702608585357666\n",
      "epoch =  0  step =  100  of total steps  106  loss =  1.3912906646728516\n",
      "epoch :  0  /  20  | TL :  1.5100063715340957  | VL :  1.523334264755249\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  106  loss =  1.4645376205444336\n",
      "epoch =  1  step =  20  of total steps  106  loss =  1.71355402469635\n",
      "epoch =  1  step =  40  of total steps  106  loss =  1.6008198261260986\n",
      "epoch =  1  step =  60  of total steps  106  loss =  1.5929672718048096\n",
      "epoch =  1  step =  80  of total steps  106  loss =  1.2262083292007446\n",
      "epoch =  1  step =  100  of total steps  106  loss =  1.345224380493164\n",
      "epoch :  1  /  20  | TL :  1.4471513145374801  | VL :  1.5233323574066162\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  106  loss =  1.2329537868499756\n",
      "epoch =  2  step =  20  of total steps  106  loss =  1.5427677631378174\n",
      "epoch =  2  step =  40  of total steps  106  loss =  1.309971570968628\n",
      "epoch =  2  step =  60  of total steps  106  loss =  1.1091303825378418\n",
      "epoch =  2  step =  80  of total steps  106  loss =  1.4347128868103027\n",
      "epoch =  2  step =  100  of total steps  106  loss =  1.2824145555496216\n",
      "epoch :  2  /  20  | TL :  1.3997872904786524  | VL :  1.4941520690917969\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  106  loss =  1.215334177017212\n",
      "epoch =  3  step =  20  of total steps  106  loss =  1.4007498025894165\n",
      "epoch =  3  step =  40  of total steps  106  loss =  1.1808557510375977\n",
      "epoch =  3  step =  60  of total steps  106  loss =  1.4348599910736084\n",
      "epoch =  3  step =  80  of total steps  106  loss =  0.9146389961242676\n",
      "epoch =  3  step =  100  of total steps  106  loss =  1.1072851419448853\n",
      "epoch :  3  /  20  | TL :  1.3645890124563902  | VL :  1.5043957233428955\n",
      "epoch =  4  step =  0  of total steps  106  loss =  1.3918367624282837\n",
      "epoch =  4  step =  20  of total steps  106  loss =  1.2513656616210938\n",
      "epoch =  4  step =  40  of total steps  106  loss =  1.3268520832061768\n",
      "epoch =  4  step =  60  of total steps  106  loss =  1.3507840633392334\n",
      "epoch =  4  step =  80  of total steps  106  loss =  1.0180280208587646\n",
      "epoch =  4  step =  100  of total steps  106  loss =  1.471154808998108\n",
      "epoch :  4  /  20  | TL :  1.3351238977234319  | VL :  1.5054574012756348\n",
      "epoch =  5  step =  0  of total steps  106  loss =  1.5063996315002441\n",
      "epoch =  5  step =  20  of total steps  106  loss =  1.4793708324432373\n",
      "epoch =  5  step =  40  of total steps  106  loss =  1.102637767791748\n",
      "epoch =  5  step =  60  of total steps  106  loss =  1.332414984703064\n",
      "epoch =  5  step =  80  of total steps  106  loss =  1.406476378440857\n",
      "epoch =  5  step =  100  of total steps  106  loss =  1.571319580078125\n",
      "epoch :  5  /  20  | TL :  1.3172203521683532  | VL :  1.5095329284667969\n",
      "epoch =  6  step =  0  of total steps  106  loss =  1.332930326461792\n",
      "epoch =  6  step =  20  of total steps  106  loss =  0.817150354385376\n",
      "epoch =  6  step =  40  of total steps  106  loss =  1.310502290725708\n",
      "epoch =  6  step =  60  of total steps  106  loss =  1.1230974197387695\n",
      "epoch =  6  step =  80  of total steps  106  loss =  1.1358942985534668\n",
      "epoch =  6  step =  100  of total steps  106  loss =  1.3676239252090454\n",
      "epoch :  6  /  20  | TL :  1.2952421543733128  | VL :  1.4997284412384033\n",
      "epoch =  7  step =  0  of total steps  106  loss =  1.0675426721572876\n",
      "epoch =  7  step =  20  of total steps  106  loss =  1.2712823152542114\n",
      "epoch =  7  step =  40  of total steps  106  loss =  1.7227050065994263\n",
      "epoch =  7  step =  60  of total steps  106  loss =  1.0448471307754517\n",
      "epoch =  7  step =  80  of total steps  106  loss =  1.1519811153411865\n",
      "epoch =  7  step =  100  of total steps  106  loss =  1.1787474155426025\n",
      "epoch :  7  /  20  | TL :  1.273292603357783  | VL :  1.5667688846588135\n",
      "epoch =  8  step =  0  of total steps  106  loss =  1.2947014570236206\n",
      "epoch =  8  step =  20  of total steps  106  loss =  1.331595540046692\n",
      "epoch =  8  step =  40  of total steps  106  loss =  1.7344235181808472\n",
      "epoch =  8  step =  60  of total steps  106  loss =  1.3282109498977661\n",
      "epoch =  8  step =  80  of total steps  106  loss =  1.2067127227783203\n",
      "epoch =  8  step =  100  of total steps  106  loss =  1.3777050971984863\n",
      "epoch :  8  /  20  | TL :  1.269154667292001  | VL :  1.500510573387146\n",
      "epoch =  9  step =  0  of total steps  106  loss =  1.0341464281082153\n",
      "epoch =  9  step =  20  of total steps  106  loss =  1.2561731338500977\n",
      "epoch =  9  step =  40  of total steps  106  loss =  1.4082974195480347\n",
      "epoch =  9  step =  60  of total steps  106  loss =  1.775622844696045\n",
      "epoch =  9  step =  80  of total steps  106  loss =  1.4095345735549927\n",
      "epoch =  9  step =  100  of total steps  106  loss =  1.4117883443832397\n",
      "epoch :  9  /  20  | TL :  1.2502197820060659  | VL :  1.521846055984497\n",
      "epoch =  10  step =  0  of total steps  106  loss =  1.3411352634429932\n",
      "epoch =  10  step =  20  of total steps  106  loss =  1.3837403059005737\n",
      "epoch =  10  step =  40  of total steps  106  loss =  1.4673622846603394\n",
      "epoch =  10  step =  60  of total steps  106  loss =  1.316107988357544\n",
      "epoch =  10  step =  80  of total steps  106  loss =  1.3640894889831543\n",
      "epoch =  10  step =  100  of total steps  106  loss =  1.402716040611267\n",
      "epoch :  10  /  20  | TL :  1.235899564230217  | VL :  1.5154902935028076\n",
      "epoch =  11  step =  0  of total steps  106  loss =  1.0129417181015015\n",
      "epoch =  11  step =  20  of total steps  106  loss =  1.25785231590271\n",
      "epoch =  11  step =  40  of total steps  106  loss =  0.9417282938957214\n",
      "epoch =  11  step =  60  of total steps  106  loss =  1.315420389175415\n",
      "epoch =  11  step =  80  of total steps  106  loss =  1.248000144958496\n",
      "epoch =  11  step =  100  of total steps  106  loss =  1.468817114830017\n",
      "epoch :  11  /  20  | TL :  1.219864546128039  | VL :  1.5269287824630737\n",
      "epoch =  12  step =  0  of total steps  106  loss =  1.072914481163025\n",
      "epoch =  12  step =  20  of total steps  106  loss =  1.6469968557357788\n",
      "epoch =  12  step =  40  of total steps  106  loss =  1.0702228546142578\n",
      "epoch =  12  step =  60  of total steps  106  loss =  1.042405366897583\n",
      "epoch =  12  step =  80  of total steps  106  loss =  0.9300298690795898\n",
      "epoch =  12  step =  100  of total steps  106  loss =  1.050620436668396\n",
      "epoch :  12  /  20  | TL :  1.2084756386729907  | VL :  1.4961720705032349\n",
      "epoch =  13  step =  0  of total steps  106  loss =  1.303767204284668\n",
      "epoch =  13  step =  20  of total steps  106  loss =  0.9433697462081909\n",
      "epoch =  13  step =  40  of total steps  106  loss =  1.1909596920013428\n",
      "epoch =  13  step =  60  of total steps  106  loss =  1.5063748359680176\n",
      "epoch =  13  step =  80  of total steps  106  loss =  1.2780739068984985\n",
      "epoch =  13  step =  100  of total steps  106  loss =  1.1332906484603882\n",
      "epoch :  13  /  20  | TL :  1.2014180815444802  | VL :  1.4984209537506104\n",
      "epoch =  14  step =  0  of total steps  106  loss =  1.1174927949905396\n",
      "epoch =  14  step =  20  of total steps  106  loss =  0.9627321362495422\n",
      "epoch =  14  step =  40  of total steps  106  loss =  1.3179023265838623\n",
      "epoch =  14  step =  60  of total steps  106  loss =  1.2450432777404785\n",
      "epoch =  14  step =  80  of total steps  106  loss =  1.3552604913711548\n",
      "epoch =  14  step =  100  of total steps  106  loss =  1.171013355255127\n",
      "epoch :  14  /  20  | TL :  1.1881286906746198  | VL :  1.524522304534912\n",
      "epoch =  15  step =  0  of total steps  106  loss =  0.9147519469261169\n",
      "epoch =  15  step =  20  of total steps  106  loss =  0.9139739274978638\n",
      "epoch =  15  step =  40  of total steps  106  loss =  1.1085238456726074\n",
      "epoch =  15  step =  60  of total steps  106  loss =  1.386927843093872\n",
      "epoch =  15  step =  80  of total steps  106  loss =  1.2659802436828613\n",
      "epoch =  15  step =  100  of total steps  106  loss =  1.0846874713897705\n",
      "epoch :  15  /  20  | TL :  1.177204598795693  | VL :  1.5302832126617432\n",
      "epoch =  16  step =  0  of total steps  106  loss =  0.8912366628646851\n",
      "epoch =  16  step =  20  of total steps  106  loss =  1.073879361152649\n",
      "epoch =  16  step =  40  of total steps  106  loss =  1.0021015405654907\n",
      "epoch =  16  step =  60  of total steps  106  loss =  1.016965389251709\n",
      "epoch =  16  step =  80  of total steps  106  loss =  1.375260829925537\n",
      "epoch =  16  step =  100  of total steps  106  loss =  1.3518165349960327\n",
      "epoch :  16  /  20  | TL :  1.1653421852948531  | VL :  1.5525832176208496\n",
      "epoch =  17  step =  0  of total steps  106  loss =  1.200771450996399\n",
      "epoch =  17  step =  20  of total steps  106  loss =  1.238407015800476\n",
      "epoch =  17  step =  40  of total steps  106  loss =  1.2281763553619385\n",
      "epoch =  17  step =  60  of total steps  106  loss =  0.7023838758468628\n",
      "epoch =  17  step =  80  of total steps  106  loss =  1.1319007873535156\n",
      "epoch =  17  step =  100  of total steps  106  loss =  1.0166105031967163\n",
      "epoch :  17  /  20  | TL :  1.1602540685320801  | VL :  1.5532773733139038\n",
      "epoch =  18  step =  0  of total steps  106  loss =  1.5999433994293213\n",
      "epoch =  18  step =  20  of total steps  106  loss =  1.074840784072876\n",
      "epoch =  18  step =  40  of total steps  106  loss =  0.8017275333404541\n",
      "epoch =  18  step =  60  of total steps  106  loss =  1.3507561683654785\n",
      "epoch =  18  step =  80  of total steps  106  loss =  1.2545119524002075\n",
      "epoch =  18  step =  100  of total steps  106  loss =  0.9698358178138733\n",
      "epoch :  18  /  20  | TL :  1.1591409208639614  | VL :  1.5474454164505005\n",
      "epoch =  19  step =  0  of total steps  106  loss =  1.2971397638320923\n",
      "epoch =  19  step =  20  of total steps  106  loss =  0.6850504279136658\n",
      "epoch =  19  step =  40  of total steps  106  loss =  0.9271788001060486\n",
      "epoch =  19  step =  60  of total steps  106  loss =  1.5501484870910645\n",
      "epoch =  19  step =  80  of total steps  106  loss =  1.1575143337249756\n",
      "epoch =  19  step =  100  of total steps  106  loss =  1.3864907026290894\n",
      "epoch :  19  /  20  | TL :  1.141646274418201  | VL :  1.5801435708999634\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '1conv_softmax.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2bb5a01400>,\n",
       " <matplotlib.lines.Line2D at 0x7f2bb5a01550>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(20)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5766509433962265\n",
      "0.4326923076923077\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader, Net))\n",
    "print(_get_accuracy(testloader, Net))\n",
    "print(_get_accuracy(valloader, Net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4339622641509434\n",
      "0.4326923076923077\n",
      "0.3557692307692308\n"
     ]
    }
   ],
   "source": [
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('1conv_softmax.pt'))\n",
    "testing_Net.eval()\n",
    "print(_get_accuracy(trainloader, testing_Net))\n",
    "print(_get_accuracy(testloader, testing_Net))\n",
    "print(_get_accuracy(valloader, testing_Net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even using `running_mean` processed data, the network again overfits. Even increasing window size didn't help (decreasing won't help as it will be closer to raw data then). Increasing too much is also not helpful as the plot will get more and more flat. So, we need to try out other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch implementation of running standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_std_dev(signal, window_size = 10):\n",
    "    ''' Returns running standard deviation of 3D signal (batch_size, length, channels)\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].std(dim = 0)\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = signal[i][j]\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_std_dev` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 150, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f08f04f5630>,\n",
       " <matplotlib.lines.Line2D at 0x7f08f04f5780>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO2deXgUVdbG35uVJQlL2EIgQGRHkEBAQFQQVEABd/FzBRRHx20cR8F9G0dxYZRxRsEFxQUVHUUGBGUTibIvguxrwpYECIGQhCR9vj9OV7rTqe6u7q7u6qTP73n6qe6qW1WnK+m3Tp177rmKiCAIgiDUfqKsNkAQBEEIDSL4giAIEYIIviAIQoQggi8IghAhiOALgiBECDFWG+COJk2aUNu2ba02QxAEoUaxdu3afCJqqrctbAW/bdu2WLNmjdVmCIIg1CiUUvvdbZOQjiAIQoQggi8IghAhiOALgiBECCL4giAIEYIIviAIQoQggi8IghAhiOALgiBECCL4QuiZPx/YscNqKwQh4hDBF0LPrbcCDz1ktRWCEHGI4AuhpawMOHYMWLwYOH3aamsEIaIQwRdCS34+L0tLgQULrLVFECIMEXwhtOTmOt5/9511dghCBCKCL4SWvDxetm0L/O9/QHm5peYIQiQhgi+EFk3wx48Hjh8HVqyw1h5BiCBE8IXQogn+LbcAcXHA999ba48gRBAi+EJoyc0FoqOBtDSgSxfJxxeEECKCL4SWvDwgORmIigKaNweOHrXaIkGIGETwhdCSlwc0tc++JoIvCCFFBF8ILbm5QLNm/L5ZMxZ8ImttEoQIQQRfCC2uHn5JCXDqlLU2CUKEIIIvhBZXwQckrCMIIUIEXwgdZWXAiROOkI4IviCEFFMEXyk1TCm1XSm1Syk10UO765RSpJTKNOO8Qg1Dq6MjHr4gWELAgq+UigbwNoDhALoCuEkp1VWnXSKABwCsDPScQg1FG3Qlgi8IlmCGh98XwC4i2kNEZwHMAjBap90LACYDKDHhnEJNxFXwmzYFlBLBF4QQYYbgpwLIdvqcY19XiVIqA0BrIprr6UBKqQlKqTVKqTV5mjgItQetUqYWw4+J4UFYIviCEBLMEHyls64ysVopFQVgCoC/ejsQEU0jokwiymyqeYFC7cHVwwc4rONcMlkQhKBhhuDnAGjt9LkVgENOnxMBnAtgqVJqH4B+AOZIx20EkpfHJRUaN3ask9G2ghAyzBD81QA6KKXaKaXiAIwBMEfbSEQniagJEbUlorYAfgMwiojWmHBuoSaRmws0acKiryGCLwghI2DBJ6JyAPcBWABgK4AviWiLUup5pdSoQI8v1CKcB11piOALQsiIMeMgRDQPwDyXdU+7aTvIjHMKNRB3gn/6NHDmDFCvnjV2CUKEICNthdCRl+fI0NGQXHxBCBki+ELo0PPwtRuACL4gBB0RfCE0EAEFBUDDhlXXi4cvCCFDBF8IDcXFgM0GJCVVXS+CLwghQwRfCA2FhbxMTKy6XkI6ghAyRPCF0KBNcuLq4cfHc5hHBF8Qgo4IvhAa3Hn4gJRXEIQQIYIvhAZ3Hj7AHr52QxAEIWiI4AuhwZOHn5Ag89oKQggQwRdMpbgYuOwyYMUKlw2ePPyEBB5tKwhCUBHBF0zlxx/59d13Lhs8efiJieLhC0IIEMEXTGWOvU7qli0uGzTBFw9fECxDBL+m8N57OioaXlRUAN9/z++rmXrqFJdFrlu3+o7i4QtCSBDBrwkcPw7cdRdw7bVASfhOCbxqFWdXdusG7N/v4rQXFrJ3r3QmSEtI4O9VXh4yWwUhEhHBrwn8+isvt28HXnrJWls88N13PE3tX+2TWW7d6rTx1Cn9+D3gWC9hHUEIKiL4NYGsLFbSa68FXn4Z2LzZaot0mTMHuPhi4IIL+HOVsE5hoXvBT0jgpQi+IAQVEfyawIoVQEYG8M47QJ06wFtvWW1RNQ4eZI/+iiuAc87higlVBP/UKf0OW8BxI5A4viAEFRH8cKesjIPjAwbwfLDnnw+sXWu1VdXYt4+XXboA0dFA587i4QtCuCGCH+5s3MijmbQ4SUYGh3TKyqy1y4WDB3nZqhUvu3UTD18Qwg0R/HBHG7Lavz8vMzKAs2eBP/6wziYdcnJ46Sz4Bw44abh4+IJgOSL44U5WFpCW5lDSjAxerl9vnU065OQA9esDDRrw565deVmZqSMeviBYjgh+uJOVxfF7jQ4dgHr1wlLwW7VypNl368bLLVvA0xt6SssUD18QQoIIvgUQcb2ZoiIvDQ8cYCXV4vcA94j27AmsWxdUG31FE3yNdu14eeAAgDNn9Kc31BAPXxBCggi+Bfz8M1eU7NwZ+OorDw2zsnjp7OEDHNbZsIFFNExwFfyYGHbcT56E58JpAMeCAPHwBSHIiOBbwIYNvExKAm64AVi82E3DrCwWwx49qq7PyGBx3L07qHYapaICOHSoquADPK9JQQE8l0YGuMZO/foi+IIQZETwLWDzZiA5GfjtN/68cqWbhitWcN59TEzV9WHWcXv0KIu+W8H35uEDMgmKIIQAEXwL2LIFOPdc1r/Wrd1kWJ4+zTn4ruEcgHtEY2LCRvBdUzI1DHv4AF8M8fAFIaiI4IcYIhZ8LYula1c3gr96NbvNeoIfH893iuzsoNpqFE+CbyiGD4iHLwghQAQ/xOTksP6dey5/7tqVc9Wr9b9qHbb9+ukfKCkpbARSPHxBqBmI4IcYrdyAs4dfXMz146uwYgU3atRI/0CJiQ7P2WIOHuSHjuTkquslhi8I4YUIfojRKhs7Cz7gEtax2bgGvl44RyPMPHznQVcamuBToXj4ghAOiOCHmC1bgBYtHN5wly68rCL4R46wUvbs6f5AYTQtYE4OkJpafX3DhnzvOp1f4n56Qw3x8AUh6Ijgh5jNmx3ePcARm5QUl9mhDh/mpZ6KaoRRSMd10JVGw4a8LDhW4X56Qw3x8AUh6IjghxCbjT15Z8EHdDJ1Dh3iZUqK+4OFSUiHyL3ga4XUCo7bPMfvAYeHT2S+kYIgADBJ8JVSw5RS25VSu5RSE3W2P6yU+kMptUkptUgp1caM89Y09u3jsjJaho6GJviVWqd5+J4EPzGRi/FUVATDVMPk53O1Zo8efgE8x+8B/j42W1hP0i4INZ2ABV8pFQ3gbQDDAXQFcJNSqqtLs/UAMomoB4DZACYHet6ayI4dvOzcuer6rl3ZudUmEakU/BYt3B9ME1CLwyCe7k2Vgn9SGfPwgbB4ahGE2ooZHn5fALuIaA8RnQUwC8Bo5wZEtISIztg//gZAxx+s/eTl8dJVx7WO28oZog4fBpo2BWJj3R8sTCpMFhTwUi97tFLwT0V79/ClRLIgBB0zBD8VgPOQzxz7OneMBzBfb4NSaoJSao1Sak2epo61iPx8XjZpUnV9ejovKwfOHjrkOZwDOATf4o5bQ4JfFOvdww+TG5gg1GbMEHy91Avdnjel1C0AMgG8qrediKYRUSYRZTZt2tQE08KL/HwuZ691ZmpoKZrHjtlXHD7sXfA1jzlMPHxN3J2p7LQtjhcPXxDCADMEPwdAa6fPrQAccm2klBoK4AkAo4io1ITz1jjy81nco1yuer16QJ06jicAHD4MtGype4wZM4C1axE2Hv6JE7zUE/zYWK56XFASLx6+IIQBZgj+agAdlFLtlFJxAMYAmOPcQCmVAeBdsNjnmnDOGkl+fvVwjkaTJnYP32bjgVc6Hv7hw8C4ccDIkUBeuT2GEiYevutTi0bDhoSTZ+sZ77QVD18QgkbAgk9E5QDuA7AAwFYAXxLRFqXU80qpUfZmrwJIAPCVUmqDUmqOm8PVavLyuC9Wj+Rku+Dn5XGqpY7gz57NqZv5+cAdz6dz3CwMBD8piUNVejRsABSgAT/CeEI8fEEIOjHem3iHiOYBmOey7mmn90PNOE9NJz/fUTvHlUrB95Dn+MUXPPnVhAnAfffVwzRMwN1hENLRC+doNEi0oQANgbg4zwcSD18Qgo6MtA0hnkI6ycn2GL4m+C4x/AMHuIDmmDHAvfcCHTvYMB/DLfeICwo8C37DpAoW/Pj4ynUjRwKTXUdiiIcvCEFHBD9E2GzswXuN4bvx8L/8kpc33sglaTp3icIenGN5p21BgfsKzgDQMKGq4OfkAHPnAs884zJ/S1wcz+IlHr4gBA0R/BBRUMCi7ymGf/w4YDuoP8p21iygTx9Hzn56OrAH7Rylhy3CW0inYf2yKoK/ZAmvLy1l0a9EqbCqACoItRER/BDhbtCVRnIy3xAK9tldZqdOzlOnOBVz5EhH+/R0oAgJyM3zUIEyBHgN6dgFn+JY8Bcv5u/6l79wiunvvzs1TkgQD18QgogIfojQBg57EnwAOJZ9plr8Xquk2aOHY9055/Byz9H6JlrpO15DOvXOogIxKLLVBREL/qBBwBNPsEP/xhtOjcXDF4SgIoIfIrx5+Nr6Y4dKq8XvXadFBByhnd3HPLjXQaaigrsQPHr4dbn6ZUF5Avbs4c7nSy4BGjcGLrgAWL/eqXGDBsDRo8E1WhAiGBH8EGEkpAMAx3Kr5+Bv2cIRnnbtHOvatgUUbNhT0Nh8Yw1y8iQvPQp+HR5UXVBWH4sX87pLLuHluefyxC9lZfbGgwfz1I65ETs2TxCCigh+iNAE31OnLQDkH4/SFfwuXaoObqpTB0itexx7TjcLgrXG8FRHR6NhfDG3La2LxYu5L7pTJ97WvTvX0t+1y954zBh+bJg9O3hGC0IEI4IfIvLzeUrXevX0t1d6+BUNdAXfdZYsAEhvcAy7S/Rr7oQCT5UyNTTBzylIwE8/sROvzXSoTQRT2XHbvTt/0Vmz+LPNxneD//4X+PRTYMMGvkOYxNat/NSknU4Qajsi+CHC06ArgMPX0dGEY0iuUpjm5EnOXdcT/HOSC7CnrHX1DSHCU+E0jQYxRQCAx99NQ34+cN99jm1dunAhuc2bnXYYMwZYvhzYtIl7dzt0AK65BrjlFiAjA8jMNG0axEcf5VnIbr8d+OUXUw4pCGGNCH6IyMvzLPhKAckNK5CPJlVSMrUMHV0Pv+lpHKKWKC6ymWytMQyFdGJZ8PcejMc99wADBji21anDel4lNfPGG3nZrx+wciXw+uvAqlXc6OGHeVllAmD/WLqUB4A99hj3h1x1FXcou8XiqSQFwQxE8ENEfr77+L1GcoNy9vCdBF8vQ0cjvSWHS/b+UWyWmT5hJKSjefgtm5fjH/+ovr17dxcPv0MH4PzzubbyggUs8n36cPzn4Ye5zdy5AdltswF/+xvQujUP/vrmGx7lPMddSb/Tpzkt6s03AzqvIFiNCH6I8BbSAYDkxDIWfKe6M1u2cNy/bdvq7c9J4/SWPX9YM/G3kZBOvK0Yf8NkfDb1uG4J5XPPBXbv5vnYK/nuO2DbNg7pOJOaCvTqBXz/fUB2//ILsGYN8Nxz3K/StSsv9+51s8M777D7n5UV0HkFwWpE8EOEMcEvrebh//GHI9btSnpbjmXv3l5upqmGKShgu7RCl7qUlmIyHsPFF+tv7t6dQ/JbtzqtbN7c/YxfV17JqZuVs8X4jhavH22feVkpe6mKPTqNi4s5rAQAO3f6fU5BCAdE8H3AZgPK/dDWsjLufPUm+E0SSqrF8N1l6ABAk9R4JKIQe3ab04npK1pZBeWpukOpfXIzp6cWZ6pl6nhj5Ej+Q8zXnRbZECtW8E20sdMQBreC/8EHPCFNz56cMWRSh7EgWIEIvg888ADQpo0jrm4Uba5arx5+vWIcQzIongW/sBA4eJDFSQ+VlIhO2I7NO73Umg8SJ054jt8DcAi+m3r455zD97cqcXxP9OrFyfx+xvFtNn5AuOCCquvbtWPBr6LnFRVcx7l/f2DsWC77IIPChBqMCL5BjhwBpk8HDh3i0PLGjcb31eroeO20rVuMs4hHka0uAEcEQRuoVI3ERJyPlVi1NdGSJBJvhdMAOPLm3Xj40dH8/bZtM3jSqCjgiiu4Q9ePL71tG9+onLOFAPbwT592iRStWMGx+wce4M5kQMI6Qo1GBN8g77zD2jV3Lnukl13mKC3gDW9lFTSS63DP5bFiHp2laYumNdVISkI//IbTJbFmZCr6jCHBLy3lOvd6nRB20tJcauN7Y8gQvvgbNviwE6P1u7p6+Fptoiodt19/zX/sK64QwRdqBSL4BigpAf7zH/7dX3EFD/zMzQVeftnY/rt38zI11XO7JvFcKTK/iD38HTt4vVYZsxqJieiPXwFwmCLUeKuUCYAF3413r9G6tY+Cr/UAL1vmw05MVhbfeF1voprgV8bxbTbgm29QMvRK2OoncppUTIxTHQhBqHmI4Btg1iwW+Ice4s+ZmTzwc8oUL4N17CxZwmHn9u09t0uO5dmrjhVxDH/nTvZ+69Z1s0NSEtKxB03qncFvvxn8MibibfITAIYFv6DAh1L4LVvyxfRD8Fes4HCOa0ezVpiuUvBXr0Z+TjFaLZ2JJk2AK6+KwdaWQ8TDF2o0IvheOHoUmDSJkzSGDHGs//vfWTQef9zz/kQs+IMGeclmgZPgn+IOzp07PYRzACA+HiomBv1a7jdN8ImMZzwaDul4mcC8tb06RE6OsfMCYC9/+XL2xA2Sn89PTa7xe4DHOrRo4ST4s2fj71FP4cSZeIwaBfz8M/BU6ZMi+EKNRgTfAzYbcNtt7Ml+9FFVwU5LA+6/H/jsM86kccf27TxNrVYS2BOp8flQsGHHvlgALE4eBd8+LWD/JruwdatjIJS/VFRwXZlmzYDx47mD2h2lpZyibqjT1ouH36oVL72FdU6f5s7y/HyALrqYv/CmTV4McKDdFPUEH3Bk6oAI+2f9in/TvRg7VmHGDK748OOJ3ijbuU9SM4Uaiwi+B954A1i4kEfUO882pXHXXfzb//xz98fQ5nAdPNj7+ZJQiJ7YgKU/R+PYMdazjh297ZSEfomcJ7pqFa+y2YBHHuHiYEYpL+eb28yZwLBhvOzUCZg3T7+9kbIKAAyHdADvHv7NN/OTVtOmQMzYW1AHxegxohX27fNig5116/gemZGhvz093d5pe+QIns65Cypa4dlneduIEUDh2brIKuohk7QINRYRfDccPw688AIP7JwwQb9Nhw5A375cudcdS5awoLnteHWmtBSDYlbg118dA5E8evgA0KgR+kSvQ1QUTx9YUQHceScPDn31VQ5FeOLAAeCee7hD+bPPOFQ1bx6PfO3YERg1Cpg2rfp+Rgqnad/Jm+BrndmePPylS7nWzZ/+BPzzn8CkSQoPNvgIOfnxuPhiD2URnFi7Fujc2f3I4PR0vh4/f5OPmbgV948+UPn0MWQIEBtjw3wMl7COUHMhorB89e7dm6zkqaeIAKKNGz23e+stbrd5c/VtFRVETZoQ3XabwZPedx/NSbiJAKJx4/i427Z52eeyy4j69qXevbl9/fq8nDiRqFUrot692Q49Tpwg6tSJqG5douuvJ5ozp+r2U6eIhg3j4y1bVnXbDz/w+p9+8mLf8OFEmZleGhE1a0Z055362yoq+BCtWxOdOeO04Y47aF2DQdSokY3atOHv44nUVKKbb3a//cMP+Ts1b3CG0rCPCtdsr7J9cL8z1B0biT74wOv3MRWbLbTnE2o0ANaQG10VD1+H48c5jHPttfqhHGduvJEHD+l5+Zs3c7zZSDgHAFBSggsT1iMqijODoqKqTmuoS/PmwNGjmDMHeP994KabgH//G3jpJU4bXbsW+OST6ruVl3Pp+d27gR9+AL78kqsWOJOQwJUkU1KAp56qGrpevJgLWvbr58U+A522gOfUzC++4GJnL77okrE0cCAyTi7F/HezkZPjKKapx9Gj3NfSu7f7Nlpq5tGTdTEddyGxW1qV7SOujsPv6IHstSEcbfvmm9xhpOXoCkIguLsTWP0K1MM/c4Zo+nSi7du9t3VF8+43bTLWfvhw9j5LShzrjh9n7zoujignx+CJb7mFKD290ls/5xwD+zzyCFGdOrpeYEUFUZ8+RB06VN/84ot8junTvZ9Ce4pZtMixrlcvoosuMmDfwIFEgwd7bXbVVUTdulVfX1JC1LYt0Xnn6Typ/P47G/bxxzRpEr+dP1//+PPm8falS93bcOgQkVJE4zssI2rZstr2LVv4GO/2fc/r9wkYm43oySf5hADR7bcH/5xCrQAePHzLhd3dy1/Bt9mIPvuMKC2Nv12dOkSvv05UXm5s/4oK/q1feaXxcy5YwOd68EH+nJ/PIYi4OKK5c30w/vrribp0oUce4eMNG2Zgn1df5cYnT+pufued6iGnwkKihg2JRo0yZlZxMYdDBg7k63vsGAvjc88Z2LlPH0Nf5P77iZKSqq9//XW2f+FCnZ3Ky4kSE4nuvZeKi4m6dCFKSWFxd3eDc3OZKlm1iqjkwqFEF1xQbZvNRnROnWy6sIGXOJ8ZfPEFGzx+PNF99xFFRxPt3Rv4cU+c4HjhkCFEN97o+Q4o1EgiSvB37CCKiiLKyCD673+JRo7kb3n//cb2//VXbj9zpm/nfeAB3u/pp1l04uKIvv/eR+NHjiTKyKC5c32w+aOPuPHOnbqbDx7kzX//u2Oddo9YudK4aW+/zfvMnUs0eza//+UXAzv26EE0erTXZq+8Ul2Qjx8natSI6PLLPew4ZAg/bhDR+vX8VARw10ZBgaPZ1Vfzk44h0tL4aUuHN86bQQDRmjUGj+UvN9xA1Lw5eyDZ2USxsUR//nNgx9yyhS9CTAxRv35Eycl8jlOnzLHZhZIS/v8TQktECT4RUVaWw6O32Vg4Ae5o9MYjj/Bvy1sHoCslJXyTAdjTXLfOd7vp0kuJ+venkye5E/OLLwzso/WeelDfvn3Z0SZib71FC6KhQ30zrbSUqGNHfo0fT5SQQHT2rIEdO3Vi8fLCZ5/x19iyxbHukUf4ScJjx/kTT7D3W1RUaeeUKaxpgwc7wmxpaURjxhiwt7SUPYanntLdXHDPREpAId16q4FjecBmI1q7lv83b7iBaNcup41nzxI1aEA0bhwVF/P3t42/kyg+nujwYf9OuHo1H7N5c6Lly3md5t0YelQzzt69RNdc40ggeO456XcOJREn+K4UFxN17cqed36++3Y2G1G7dgZDKTocOEA0dapLJokvXHhhZbzb8A9k/Xr+M379tdsmL73ETXJyiN54g6rF442iPXkoRXTFFQZ3atvWrbfszPLlVW/Ke/fyU9Idd3jZcc4c3lETMTszZ/Lqa64h+vFHfv/qqwbs3bmTG3/4of72yZPpfrxJsbE22raNn+L++MPAcV2YOJFPExfHUamEBKL337f/3ZcupWLE05SxGyglhduNuPg0HUYLjuv7yvr1/KjUrh3R/v1Vt117LZ/86FHfj6vD2bPsXCQmEt1zD0eNAKK77zYeVhUCI+IFn4j/52Nj3af+aW2MdmQGhb59fb/baDGb//zHbROts/GKK9h5HT7cP4/LZnOkab7xhsGdUlL4kcAL+/ZVvfY338z9L9nZXnY8etStmmuhK+1l6Ca3cCF57N395BPagfaklK3yuNHRRJMmsWNhhEWLeL/bbuP+kAMHiAYN4nVDhxJ9MuJTOgc7CeD1zzzD16JJXAGtbjCk8mmGiEX04485GlivHlH37tyXVKnr+/cTNW3KWQUufQC5uUTFm3bwFxg71pjxxKHAJ54gevRR/j9wMoeefpq/x1df8Webjeixx3jdvffq/98VFxNt3WrwiVHwigi+nfvu40f9PXv0tz/5JAtibq7ppzZGjx6cruILZ8/yn/HZZ902sdmI2rfnZoMHV/2B+sr27dyfuW+fwR2Sk/mX7oWzZ/nJ4ZlnONQBsIgaIj2dPVUd9u/nPod//cugh/nuu3xyV09YY8kSIoCm3LudJk3ip4c77qBKcfZ2juPHeXxEx45V/w4VFdxPkpjIx+pUb3+Vjuo//iBql1JMDXGc1k36koj4iW3wYG6flkZ01118w4iP57Dd6l9KOHsgKYkVlTiKc9NNnJgAsOP/SN9ltBHdqWKa5+yj06eJHnqI/05RUXwe7dyvvsrhqago/YSiRx/lts8841iXlUXUsyffbzRbxo7l5Kvahs3GPplfoV4fEcG3k5PDj9B6Xv6qVZy5MmSI6ac1TseOBgPNLiQn8/OzBz78kD3KQMTeLxISiP7yF0NNU1I45N+8OQ9Yc+509cj//R+rqBlMnMiPgu6Ue/t20uvVnz6dqnWOu3L0KGc6xcTw/5se2Sv20yf4Pyp59a1q2/busVFa3CFKjDpFXbrYKCGBvfoPPqjqOW/ZQtSmDVG9mBJ6EY/Tgek/0FdfEfXvzzY2aMBPUK++SnTddUTR0fy00gS51LVdETVsyPvfdRffLE+cIFq8mO+rmqdeWMjnWraM/RSAbbn8cqKTR+w50ddey7nJhw+TzcZiDhANGOC4zO3asaP1/vtEt97KN7yoKD7H8uWcKvv772zH8uUBhEtDzfHjHJ/84QeiVavo78+XVaZaO6dvB4OgCz6AYQC2A9gFYKLO9ngAX9i3rwTQ1tsxgzXS1tXLr6jgtMqkJP7nMyPzzW/S0gwErXXo2pWD1eFIbCz/ug0waBB7j8OHE/32mw/nmDKF/5WPHPHPRmduuMHzAIjCQj7XK69UWW2z8b06OprDGkOGcHjl8ss5C/LJJ/nPW6cO0axZHs6vdbjs2KG7edebc+lGfE7X9cumu+92PxL78OI/6DL8UCWklZ7OYypck3IOHiT64K1TdFvCbLoq5nu6d3QOXX01/ya0kBXAT4l6ka7ycg5LlZcT3x0GDuQdUlP5D2p/VCsr4z4uLZPqiitYF53Jz+dkJO2crq+YGKKLL+bvMW0a+zljxvA9/6mn+OkwkA5im41vKmfP+nGcsjKijz+m4p79aDO60rcYRd9iFL2Bhwgg6tf5BAFEkyf7b58RPAm+4u3+o5SKBrADwKUAcgCsBnATEf3h1OZeAD2I6E9KqTEAriaiGz0dNzMzk9asWROQbXocPOgYUdmlC1eEzMvj8uqLFzsKeVlCixbAVVfx9Fq+MHgwD51dvjw4dvmLzcbDkJ9+GnjuOa/Njx7lyWbatPHxPEuWcDnShQuBSy/1z1aNvn25QNDChe7bJBmaLQIAAB+KSURBVCUB48ZxUR8nCgq4uNv+/fy/1b49/38dPMjfrXVrnkQrM9PNcYuKeGh1r148/FmPigqe+T0mhkuHuptJ7M9/Bt5/H7uWH8bsRY3QqRPXRYqO9vDd9+8Hhg/nSV5mzkTZNTdi5UqeTbJuXZ4Pol49D/vn5/P137IF+PhjHoZ+/fXAokU8jNpexKiigkd4t2/v3vxDh7gQ6q5dPNl8p068LiuLayppM7w1aMCDzcvLgX37+F8uOZkL5LVvz++V4ilKDx/m5YkT3N5ebBaxsTyBWkEBv7SK29HRvH/LlkC/8wl9knejYOsRZO85i+yTSThclARbSRlizhYhmioAWwUOlLfEPrSFaxGDi+quwsLiC3Fdk6VYVtQHO/dEo3kLL/XS/UQptZaIdP/LYkw4fl8Au4hoj/1kswCMBuA86d5oAM/a388G8C+llKJA7zZ+kJrK+vDdd/x76d4duPxyLivQoEGorXGhpISn1POV5s25FGS44WU+W1eaN/fzPFr9i02bAhf8vXuBa67x3CY1VbcmdsOGwMqVXMbZtVheWRmLm0fBnT6dvY8nn3TfJjoaeOYZrqExezZwww3V25w+zeVOb7gB7fs0wsQ+nr9OJW3a8Awxo0YBt96K2DZtMHBgPwwcaHD/yZO5nsjcufyjArhs69dfAx98wHMD27+CtyqwLVvyy5nevfl3+o9/cP26qCh23rSy5fn5fOoVK4D16/nyHD/O25o1Y38qJYUL6MXGsrCfOsX/pl278t+vYUOgfn2+KRUX8zH3/VGET95TeKeiPYD2qIcitI45jJYxuYiuE4uKhgmoQDRsUOjXKQ63DVLo2IlvONHR/LPO7H4e4qf9Ha+/+ijOLV6EzFa5uP68HejWPRpKARfdkob2Q3z1dPzAnetv9AXgOgDvOX2+FcC/XNpsBtDK6fNuAE10jjUBwBoAa9LS0oL2yBO2xMdzSoOvPPCA/jBVqzl5kp/DX3st+OdKTaWAk+NPnWJ7//EPz+0uuYQD0Z745hvuvbz2Wu6p9JaCUlzMnRiDBnm3s7ycw3hduuj3NWgdzytWeD+WHseOcXwzNdV4mKy8nO3XG2R3wQWcnltW5p89AVBR4UM6aHk5j1eYOpX7na66imt6xMZSWWIj2v7UTDq2KYdsFQHEjEpLaf6ji+nKZispDiWVoaoLkzb4f0wXEOTiaXrPJa6eu5E2IKJpRJRJRJlNmzY1wbQaBJGhUsK6NGsGFBayKxFOlJby0p/v5Cs9evg0GYoueXm8bNHCc7uWLT3PDvPee/yUMG8e17l+7jme9d7TVGKTJ3PM4amnvNsZHQ08+yzXsJ4ypeo2Ip6AuUcPoH9/78fSo3Fjrpp37BgwdCiHl7w9jC9axPbfemv1bY88wvGWb77xz54A8PpURcSPZePHc/ymTx+e2eidd7hgXevWwIMPImbbZnR8/hY07p4KFRVAKCYuDsNeGYzvj/bFscNl2J91EA9lLENWYTcU7D/p/3GN4u5OYPQFoD+ABU6fJwGY5NJmAYD+9vcxAPIB7j9w97K6PHLIKSnhW/1LL/m+r5Yi4i6V0Cqys9muadOCf67HHuMO4kCSuTdsIG+D2CrPFRen36s3YwYfY/hwR2L+Rx/x01vTpvz3dU0/+uor3uemm4z3FNps/PQQFeUYrVZRwb2YAKe9BMr//seeOcA9pZ6qCd58M6e56aWglJdzSYc+ffzrUZ0/n584lOLX00/7tn9REdfC+OIL7u19/HHuSR88mHNBAR4WfPvtPOQ7OzukQ4OXv72Rxy48nGXK8RDMLB27gO8B0A5AHICNALq5tPkzgHfs78cA+NLbcSNO8AsKyLcRTU5oo03d5fpZxa5dbNeMGcE/16ef8rmMljjV4+ef+Rg//ui53Ztvcru8vOrb2rXjOjWuwrduHafsAFw3I8v+454/n1N3+vc3PnJL49Qpzols0IAT5K+/no//2GPmCVZpKQ8QSE7m1BnnRHqNwkKeVOFPf3J/nP/8h21znVjBEzYbHxPgENaTT/KNVCkeUOCJI0f4t9S3L7d3TvWJjuaBCOefz0OAP/zQkWdqAWXFZdQABTS+48+mHC+ogs/Hxwhwps5uAE/Y1z0PYJT9fR0AX4HTMlcBSPd2zIgT/CNH+M/x73/7vu/Klbyvz9Xagow2xPfzz4N/Lq1U8ief+H+M7783duPUPHLXIj/aDe5f/3K/7+rVnJcYF8e1kwCizp39L22wdy8LV/36LGyPPx4c7zQ/n59AAKJvv626TStF6qnPoKiIB1eMHGn8nP/7Hx/3vvscN9DCQh5z0a0b34xcOXGCr0G9erxvr178RDB7NjsDubnuZwSykOtSsyg16lBg/QN2gi74wXhFnODv309+P4rv3ev/vsFEq1XxzTfBP9fZsyyijz7q/zG0pwRv04xlZXG7efOqrtdqUXvbPz+fO2fr1iV64QXfPXs9bDZzjuOJ0lLuxGzRgjt2nWv2jx7t/UbzzDPc1sgkFTYbD9pq1656mE67MY8dy8N/NbZtc4SgbrrJvyJHFvHe7T/zA+psPybwcMGT4NfOGa/Wr3ck09YUtA5Xf9MyAd8m1y4r46TkYBLKTtvYWM6t27jR/2MUFvIyKclzOy1f0LXj9scfuZPPW85hcjJ3ch45wimY/vzNXVHKnON4Ii4OmDGDO58HDeKcyBdf5A7P2bMd+ZHuuOsuXhrpvP3uO56u7emn+W/rzJVXAhMnAh9+yHnVkycDU6cCAwYAZ85wsv5nn/FgiBrC5X9uDwCY9cYh7PxxH7JXekgKCIDaJ/jaPHZpacDf/uZIxA13AhH8unV5BIlRwSfi+Q3T0jijJFiEUvCBwDN1TtqzJLwJvpbF4yz4FRU8cm/oUO/CB3D6iLfzhCM9e/JM94WF/Dt77z0ePxBjYEhPaioPKvv+e8/tzp5loe/QAbjlFv02//gH8PPPfBN67DHO8U9OBn791f/sJAtp1ScFPepsx0tZg9Dxsra4fkhwdMuMgVfhRePGwOef8ySzU6bwj1JvwtlwIxDBBzg106jgf/IJe1nt2rHXtXlztVGjpqAJvoE5bU0hI4NHeG7fzkMzfaWwkHP4PA4nBd/AmjbltEiN9et5CGegA79qAo8+yi9/GDkSeP55ToHVS70mAiZM4HTWr7/2fCO58EL+G5w+zY5dSkro/teCwFffxmH1dysAAMktg+QkuYv1WP0yJYb/2GPckVUTyu9pGSI//eTf/gMHGhu0k53NWR0DB3JMdsIEPm8w4p1arNWXqbUC4cgRTn+8+27/9r/vPk7TM8IDD/D/llb0R6uBY1Jd+VqLVgrVXeaWVl/ZQ/VXwTOIuBi+xt/+xvU7nnnGaku8E6iH720wkMaTT3L8fsYM9oaee47DC8F4CvKxtELANG8O3HYbf7fcXN/3Lyw0HmZ58UUOUdx1F4/lf+894Lzz+ElLcE9GBl+3OXOqb5s6lb3/sWM5pCOYTu0W/ORk4OGHOXyxdq3V1ngmUMHX6ruQhxGRBQXAl1+yKGrFXlq04LjzZ595H03pK6GO4QPAX//K5337bd/3PXnSuOAnJvI5fv8dGDiQC6+89prv54w0lOJO14ULHf8fAN+kH3gAGD0aePddY/0ggs/UbsEHgL/8hX/EU6dabYlntH/+QDz8oiKuBuWOzz9nYbrzzqrrb76Zi4b9+qt/53aHFYKvlYV8+23fS00UFvpWQW/UKH5imjSJ+w2GDvXtfJHK6NEcdx8yBJg2DRgxgr36Sy8FvviielaOYBq1X/AbNOCKgl9/zSlb4YomTv6Ko5YqqFPFsZL33+ewQ69eVddffTVn+nzyiX/ndkeoO2017riD68Bs2ODbfr6EdDReeAF46SX2+AVjDBsGvPUWkJMD3H03P32/8ALw7behdQ4ikNov+ACndp0+zbm94YoZIR3AfRx//Xr+Yd15Z/XH5cRE9la//JLj+2ZhhYcPcLogwN/ZF/wRfMF3lOICZbt2AatWcWG1J5/0nh0lBExkCP6FF3LO+cyZVlviHjM6bQH3Hv7MmSy8N9+sv/3GG9krNnMSlVB32mq0bs3pub4K/smTYTApQgQRE8PVKevWtdqSiCEyBD8qir38hQt9G40aSgL1ht2N/tTYvJnDOY0a6W+/7DI+t172hL9Y5eErxdkgvk4KIx6+UMuJDMEHWPArKoBZs6y2RJ9APfz69dk7dSf4+/d7njuwfn3udJwzx7xsHU3wreiEy8jgDBqjIaqzZ/lvIIIv1GIiR/C1SUaXLrXaEn1KSvhJxMgQdXe0bKkf0rHZWPDbtvW8/6hRnK2zebP/NjhTWsodtlak2PXqxSLuPBrWE1p2kwi+UIuJHMEHgPPPB1avttoKfbT5bAMRx9RUfQ8/N5fF19vs4CNH8tKssI6/M3iZQUYGL42GdbQ6OhLDF2oxkSX4ffuyB+wpddEqzBBHdx7+/v289Cb4KSl8jcwS/LNnrRP8Dh0468Nox63RSpmCUIOJPMEHwtPL1zz8QEhN5XlFXUtD79vHS28hHYC9/FWrHPO7BoKVHn50NHdSi+ALQiWRJfg9e3KMfNUqqy2pjhmC37IlUF5eXayNevgAlwkAzClFYaXgAxzWMTo3ggi+EAFEluDXqcNeX20VfHeDr/bv53RMI6NBtdj3mjWB2QI4Om2tondvHnC3ZIn3thLDFyKAyBJ8gMM6q1eH34xYZsXwAX3BNxLOAVjwOnSoHR7+jTdykbjx4x0evDvEwxcigMgT/D59+Me9Y4fVllTFrJAOUL3jdt8+Y+Ecjd69a4fg16/PI4yzs7mInidE8IUIIPIEX+u4DbewjhmC36IFp3U6e/hE3gddudK7N4tkoB23VmbpaPTvz/OffvAB17B3N6issJD7d2SYv1CLiTzB79yZvbiZM3nkrR5HjvB0daGktDRwwY+N5Qk4nD38Eyc4ju2r4AOBe/lWe/gazz4L3Hor8NRTXLRLL5yn1cKXOuxCLSbyBD86GnjlFeCnn3hGLI28PP7cvj3no6em8uQpR46Exq6SEnPEMTWVy85q+JKSqaGVTzZD8MNhjtHYWJ5g4+GHuU7+t99WbyN1dIQIoPZNYm6EP/2Jh9xPmcLLpCRg3jyulz9iBHDPPVyH5a23eEKGX37hCb+DiRkhHYCfYJYtc3z2JSVTo0EDvvHVFg8f4LIVkydzCejp04Frrqm6XQRfiAAiz8PXeP11nnwhJ4dTEIcP5xoy33/P0+TNmMHri4t5Jp5ge/pmCX6fPhzS0eL4/gg+AGRm1i7BB/jpbtw4YMECx3XR8HW2K0GogUSu4MfEAO+8w5787t3s+XXpUrVNz57s+R85Alx7rflzvjpjljj26cNLbTTxvn08kXvjxr4dp3dv4MAB/yYD1wiHTltXxo3j5QcfVF3vy3y2glBDiVzBN0q/fjw5dVYWh3aChVkefkYGe7Ka4G/eDKSn+94ZecEFvPz5Z/9tCTcPH+AnncsuY8F37rSXkI4QAYjgG+G229hD/uc/g3cOswS/Xj3g3HNZ8I8d43LQI0b4fpzMTM5jX7zYf1vCpdPWlQkTOJTnPDeCCL4QAYjgG6FePe7o/fZbrhdvNkTmCT7AYZ3Vq9neigrg+ut9P0ZsLHDRRcbKErgjHD18ABg9mq/RX//qSL+VGL4QAYjgG+XeeznTY+pU84+tzcpkljj27ctC9tprnF2k1cfxlUsuAbZtcz+LljfCVfCjo4F33+VU3EmTZLYrIWIQwTdKaipw9dXA55+bf+xApzd0Reu43bYNuO46/wcTXXIJL/3x8isqeIBTOAo+wDfBhx5i4R8/nteJ4Au1HBF8X+jZkzN2iorMPa7Zgt+tm+NY113n/3HOOw9o2NA/wT99mpf16vl//mDz3HPAHXcA//0vf27e3FJzBCHYiOD7Qno6L82O45st+LGx3Onapo3D2/eH6Ghg0CD/Om618g5ayeZwJCEB+PBD4OhRHqx29dVWWyQIQSUgwVdKNVZK/aiU2mlfNtJp01Mp9atSaotSapNS6sZAzmkpwRL84mJemlm4a/p0nqow0Nowl1zC39fX75ydzcvWrQM7fyioX587qGNjrbZEEIJKoB7+RACLiKgDgEX2z66cAXAbEXUDMAzAP5VSDQM8rzVogr9nj7nHPXaMl8nJ5h2zc2egR4/AjzN0KC8XLvRtP62eT6tWgdsgCIIpBCr4owF8ZH//EYCrXBsQ0Q4i2ml/fwhALoCmAZ7XGpKTedYoswVfK0PcpIm5xzWDzp3ZS1+wwLf9cnL46UKr0S8IguUEKvjNiegwANiXzTw1Vkr1BRAHYLeb7ROUUmuUUmvyzJhE22yUYi/fbMHPz+dlOAq+UsDllwOLFjnSR42Qnc2doOE48EoQIhSvgq+U+kkptVnnNdqXEymlUgDMBDCWiHTnFySiaUSUSUSZTZuG6UNAu3aRJfgAMGwYD0xaudL4Pjk5Es4RhDDDa3lkIhrqbptS6qhSKoWIDtsFXbfSllIqCcD/ADxJRL/5bW04kJ7O4Q0i8ybLyM/nDttwTWEcMoQzdhYsAAYONLZPTg7PjSsIQtgQaEhnDoDb7e9vB/CdawOlVByA/wL4mIi+CvB81pOezlk1R4+ad8z8fCBcn2gAzsU//3zf4vjZ2TUjQ0cQIohABf9lAJcqpXYCuNT+GUqpTKXUe/Y2NwC4CMAdSqkN9lfPAM9rHcHI1MnLC99wjsbll/P8AFr4yROFhfySkI4ghBUBzXhFRMcADNFZvwbAnfb3nwD4JJDzhBXOgj9ggDnHzM8Pf8G/6CIOY61bx+WFPaENuhIPXxDCChlp6ytt2nDs3kwPvyYIfseOvNy1y3tbbdCVePiCEFaI4PtKnTpcLiDSBD8lhTuVd+703lYGXQlCWCKC7w/t2plXXuHsWZ5eL9wFXyme2NwXwQ/nOjqCEIGI4PtDerqx0IYRtLIK4Zylo9Ghg/GQjgy6EoSwQwTfH847jycFOXw48GOF+6ArZzp04FBWebnndjLoShDCEhF8f+jfn5e//hr4sWqa4JeVAQcOeG6XkyMZOoIQhojg+0NGBs/klJUV+LFqkuC3b89Lb2Gd7Gzx8AUhDBHB94f4eJ5gxAzBD+dKma5opRI8ddwWFnIntAi+IIQdIvj+MmAAsHatY7Yqf9E8fDNr4QeLFi14shBPgq+FuXr1Co1NgiAYRgTfXwYM4JTKdesCO05+PteqqQmzLWmpmZ5COkuX8ncxaxSyIAimIYLvL1rHbaBhnZow6MqZDh08e/hLlgB9+/KTgCAIYYUIvr80bw6cc05kCr671MxTp7jA2uDBobdLEASviOAHwoABwIoVXFTMX2pCpUxn2rdnsddLzfzlF6CiAhg0KORmCYLgHRH8QDj/fCA311EszB9qmoevTYw+a1b1bUuW8OhaLdwlCEJYIYIfCJmZvFyzxr/9icJ/8hNXMjOBa68Fnn8e2LGj6rYlS/gmGK4zdwlChCOCHwjnnQfExPgv+GfOcFpnTfLwAWDqVK4aOmECYLNPT3zsGGcsSfxeEMIWEfxAqFMH6N7df8GvSaNsnUlJAV57DVi2DJg5k9e9/TaL/3XXWWubIAhuEcEPlMxMFnx/Om61MsLNm5trUygYN47TLx9/nOf3ffNNYNQovgEKghCWiOAHSmYmcOKEf/XxN23iZU0UyagoYMoUrhp60UXA8ePApElWWyUIggdE8AMlkI7bjRt5lG1NrSw5YAAwZgx33l5yCdCvn9UWCYLgARH8QDn3XE5F9EfwN23iNEelzLcrVLzyCndev/ii1ZYIguCFGKsNqPHExbHg+Sr4NhsL/rhxwbErVKSlARs2WG2FIAgGEA/fDDIzuXKmLx23e/YARUWOgUyCIAhBRgTfDDp14jrwJ04Y32fjRl6ed15wbBIEQXBBBN8MWrTg5ZEjxvfZtIkzXbp1C45NgiAILojgm4Em+L5Mar5xI1eelDIEgiCECBF8M/DHw9+4UcI5giCEFBF8M/BV8E+eBPbtE8EXBCGkiOCbQVIS19UxIvhz5gCXXsrv+/QJrl2CIAhOiOCbgVJcUMyb4C9fDowezZUlp08Hhg4NjX2CIAiQgVfm0aKFd8FfupRvDuvX81OBIAhCCBEP3yyMCP7q1UDnziL2giBYggi+WXgTfCJg1SqJ2wuCYBki+GbRogVPaFJWpr89J4frxovgC4JgEQEJvlKqsVLqR6XUTvuykYe2SUqpg0qpfwVyzrBFS83MzdXfvno1L0XwBUGwiEA9/IkAFhFRBwCL7J/d8QKAZQGeL3zxNtp29Wqe/1Zy7wVBsIhABX80gI/s7z8CcJVeI6VUbwDNASwM8Hzhi7fBV6tXc2XMOnVCZ5MgCIITgQp+cyI6DAD2ZTPXBkqpKACvA/ibt4MppSYopdYopdbk5eUFaFqI8ST4NhvXy5dwjiAIFuI1D18p9ROAFjqbnjB4jnsBzCOibOVlZicimgZgGgBkZmb6MSu4hWgTkesJ/q5dXE5BBF8QBAvxKvhE5HY4qFLqqFIqhYgOK6VSAOj1WPYHcKFS6l4ACQDilFKnichTvL/mER8PNG6sL/jz5vGyf//Q2iQIguBEoCNt5wC4HcDL9uV3rg2I6GbtvVLqDgCZtU7sNfRy8SsqgKlTgQsuALp2tcYuQRAEBB7DfxnApUqpnQAutX+GUipTKfVeoMbVOPQEf+5cns7wwQetsUkQBMFOQB4+ER0DMERn/RoAd+qsnwFgRiDnDGtatABWrqy67s03gdatgauvtsYmQRAEOzLS1kxcPfx164AlS4D77+ccfEEQBAsRwTeTVq2AoiJg2TKgpAQYOxZo2hS4s9rDjiAIQsgRwTeTO+7gaphXXQXcfjtPVD5jBtDIbcUJQRCEkCGCbyaNGgHz5/No2i+/5FDOiBFWWyUIggBAJkAxn7ZtgYULgU8/BZ591mprBEEQKhHBDwbduwMvv2y1FYIgCFWQkI4gCEKEIIIvCIIQIYjgC4IgRAgi+IIgCBGCCL4gCEKEIIIvCIIQIYjgC4IgRAgi+IIgCBGCIgrPmQSVUnkA9gdwiCYA8k0yJ1iEu43hbh8gNpqF2GgO4WBjGyJqqrchbAU/UJRSa4go02o7PBHuNoa7fYDYaBZiozmEu40S0hEEQYgQRPAFQRAihNos+NOsNsAA4W5juNsHiI1mITaaQ1jbWGtj+IIgCEJVarOHLwiCIDghgi8IghAh1DrBV0oNU0ptV0rtUkpNtNoeAFBKtVZKLVFKbVVKbVFKPWhf31gp9aNSaqd9afnkt0qpaKXUeqXUXPvndkqplXYbv1BKxVlsX0Ol1Gyl1Db79ewfTtdRKfUX+994s1Lqc6VUnXC4hkqpD5RSuUqpzU7rdK+bYt6y/4Y2KaV6WWTfq/a/8yal1H+VUg2dtk2y27ddKXV5sO1zZ6PTtkeUUqSUamL/HPJraIRaJfhKqWgAbwMYDqArgJuUUl2ttQoAUA7gr0TUBUA/AH+22zURwCIi6gBgkf2z1TwIYKvT51cATLHbeALAeEuscvAmgB+IqDOA88C2hsV1VEqlAngAQCYRnQsgGsAYhMc1nAFgmMs6d9dtOIAO9tcEAP+xyL4fAZxLRD0A7AAwCQDsv50xALrZ9/m3/bdvhY1QSrUGcCmAA06rrbiG3iGiWvMC0B/AAqfPkwBMstouHTu/A/+DbAeQYl+XAmC7xXa1Av/wLwEwF4ACjxqM0bu+FtiXBGAv7MkGTuvD4joCSAWQDaAxePrQuQAuD5drCKAtgM3erhuAdwHcpNculPa5bLsawKf291V+1wAWAOhvxTW0r5sNdj72AWhi5TX09qpVHj4cPziNHPu6sEEp1RZABoCVAJoT0WEAsC+bWWcZAOCfAB4FYLN/TgZQQETl9s9WX890AHkAPrSHnd5TStVHmFxHIjoI4DWwp3cYwEkAaxFe19AZd9ctHH9H4wDMt78PG/uUUqMAHCSijS6bwsZGZ2qb4CuddWGTd6qUSgDwNYCHiKjQanucUUpdCSCXiNY6r9ZpauX1jAHQC8B/iCgDQBHCIwwGALDHwEcDaAegJYD64Ed7V8Lmf9INYfV3V0o9AQ6Lfqqt0mkWcvuUUvUAPAHgab3NOuss/7vXNsHPAdDa6XMrAIcssqUKSqlYsNh/SkTf2FcfVUql2LenAMi1yj4AFwAYpZTaB2AWOKzzTwANlVIx9jZWX88cADlEtNL+eTb4BhAu13EogL1ElEdEZQC+ATAA4XUNnXF33cLmd6SUuh3AlQBuJntsBOFj3zngm/tG+++mFYB1SqkWCB8bq1DbBH81gA72rIg4cMfOHIttglJKAXgfwFYiesNp0xwAt9vf3w6O7VsCEU0iolZE1BZ83RYT0c0AlgC4zt7MahuPAMhWSnWyrxoC4A+Ez3U8AKCfUqqe/W+u2Rc219AFd9dtDoDb7Jkm/QCc1EI/oUQpNQzAYwBGEdEZp01zAIxRSsUrpdqBO0ZXhdo+IvqdiJoRUVv77yYHQC/7/2lYXMNqWN2JEIROlRHgHv3dAJ6w2h67TQPBj3ObAGywv0aAY+SLAOy0Lxtbbavd3kEA5trfp4N/TLsAfAUg3mLbegJYY7+W3wJoFE7XEcBzALYB2AxgJoD4cLiGAD4H9yuUgYVpvLvrBg5HvG3/Df0Ozjqywr5d4Di49pt5x6n9E3b7tgMYbtU1dNm+D45O25BfQyMvKa0gCIIQIdS2kI4gCILgBhF8QRCECEEEXxAEIUIQwRcEQYgQRPAFQRAiBBF8QRCECEEEXxAEIUL4fwcfMlVyRrf6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "mean = running_std_dev(signal, window_size = 5)\n",
    "print(mean.shape)\n",
    "sig_ = signal[0].transpose(0, 1)\n",
    "mean_ = mean[0].transpose(0, 1)\n",
    "t = range(150)\n",
    "plt.plot(t, sig_[0].data.numpy(), 'r', t, mean_[0].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_std_dev` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 5, 3)\n",
    "        self.fc1 = nn.Linear(146 * 5, 5)\n",
    "        self.mp = nn.MaxPool1d(2, 2)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features = 5)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features = 5)\n",
    "        self.bnfc = nn.BatchNorm1d(num_features = 5)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal_ = running_std_dev(signal, window_size = 10)\n",
    "        signal_ = signal_.view(-1, 3, 150)\n",
    "        out = F.relu(self.conv1(signal_))\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.bn2(out)\n",
    "        out = out.view(-1, 146 * 5)\n",
    "        out = F.log_softmax(self.bnfc(self.fc1(out)), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  100  loss =  1.7535799741744995\n",
      "epoch =  0  step =  20  of total steps  100  loss =  1.4038560390472412\n",
      "epoch =  0  step =  40  of total steps  100  loss =  1.8173305988311768\n",
      "epoch =  0  step =  60  of total steps  100  loss =  1.44193696975708\n",
      "epoch =  0  step =  80  of total steps  100  loss =  1.6700127124786377\n",
      "epoch :  0  /  30  | TL :  1.6008486104011537  | VL :  1.495129942893982\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  100  loss =  1.7376351356506348\n",
      "epoch =  1  step =  20  of total steps  100  loss =  1.5920422077178955\n",
      "epoch =  1  step =  40  of total steps  100  loss =  1.5215744972229004\n",
      "epoch =  1  step =  60  of total steps  100  loss =  1.3584239482879639\n",
      "epoch =  1  step =  80  of total steps  100  loss =  1.5897986888885498\n",
      "epoch :  1  /  30  | TL :  1.5530111646652223  | VL :  1.4726649522781372\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  100  loss =  1.594433069229126\n",
      "epoch =  2  step =  20  of total steps  100  loss =  1.4170478582382202\n",
      "epoch =  2  step =  40  of total steps  100  loss =  1.4120570421218872\n",
      "epoch =  2  step =  60  of total steps  100  loss =  1.721779227256775\n",
      "epoch =  2  step =  80  of total steps  100  loss =  1.5191254615783691\n",
      "epoch :  2  /  30  | TL :  1.5364567971229552  | VL :  1.4553524255752563\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  100  loss =  1.6294653415679932\n",
      "epoch =  3  step =  20  of total steps  100  loss =  1.5437837839126587\n",
      "epoch =  3  step =  40  of total steps  100  loss =  1.541150450706482\n",
      "epoch =  3  step =  60  of total steps  100  loss =  1.4942952394485474\n",
      "epoch =  3  step =  80  of total steps  100  loss =  1.4029902219772339\n",
      "epoch :  3  /  30  | TL :  1.534418168067932  | VL :  1.4539934396743774\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  100  loss =  1.361497163772583\n",
      "epoch =  4  step =  20  of total steps  100  loss =  1.637651801109314\n",
      "epoch =  4  step =  40  of total steps  100  loss =  1.5973390340805054\n",
      "epoch =  4  step =  60  of total steps  100  loss =  1.2918139696121216\n",
      "epoch =  4  step =  80  of total steps  100  loss =  1.389025092124939\n",
      "epoch :  4  /  30  | TL :  1.5201689100265503  | VL :  1.446001410484314\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  100  loss =  1.502157211303711\n",
      "epoch =  5  step =  20  of total steps  100  loss =  1.433018445968628\n",
      "epoch =  5  step =  40  of total steps  100  loss =  1.7662243843078613\n",
      "epoch =  5  step =  60  of total steps  100  loss =  1.690007209777832\n",
      "epoch =  5  step =  80  of total steps  100  loss =  1.5118800401687622\n",
      "epoch :  5  /  30  | TL :  1.5109144151210785  | VL :  1.457288146018982\n",
      "epoch =  6  step =  0  of total steps  100  loss =  1.6296179294586182\n",
      "epoch =  6  step =  20  of total steps  100  loss =  1.72256600856781\n",
      "epoch =  6  step =  40  of total steps  100  loss =  1.7374345064163208\n",
      "epoch =  6  step =  60  of total steps  100  loss =  1.5297260284423828\n",
      "epoch =  6  step =  80  of total steps  100  loss =  1.6637169122695923\n",
      "epoch :  6  /  30  | TL :  1.5085696876049042  | VL :  1.4513442516326904\n",
      "epoch =  7  step =  0  of total steps  100  loss =  1.3526595830917358\n",
      "epoch =  7  step =  20  of total steps  100  loss =  1.4559710025787354\n",
      "epoch =  7  step =  40  of total steps  100  loss =  1.1717544794082642\n",
      "epoch =  7  step =  60  of total steps  100  loss =  1.4328370094299316\n",
      "epoch =  7  step =  80  of total steps  100  loss =  1.3998860120773315\n",
      "epoch :  7  /  30  | TL :  1.5036487579345703  | VL :  1.4357163906097412\n",
      "saving model\n",
      "epoch =  8  step =  0  of total steps  100  loss =  1.5953172445297241\n",
      "epoch =  8  step =  20  of total steps  100  loss =  1.510969877243042\n",
      "epoch =  8  step =  40  of total steps  100  loss =  1.4139848947525024\n",
      "epoch =  8  step =  60  of total steps  100  loss =  1.5326756238937378\n",
      "epoch =  8  step =  80  of total steps  100  loss =  1.0986673831939697\n",
      "epoch :  8  /  30  | TL :  1.4976671361923217  | VL :  1.4304059743881226\n",
      "saving model\n",
      "epoch =  9  step =  0  of total steps  100  loss =  1.6165395975112915\n",
      "epoch =  9  step =  20  of total steps  100  loss =  1.3735309839248657\n",
      "epoch =  9  step =  40  of total steps  100  loss =  1.2698614597320557\n",
      "epoch =  9  step =  60  of total steps  100  loss =  1.371591329574585\n",
      "epoch =  9  step =  80  of total steps  100  loss =  1.390161156654358\n",
      "epoch :  9  /  30  | TL :  1.483205621242523  | VL :  1.42489492893219\n",
      "saving model\n",
      "epoch =  10  step =  0  of total steps  100  loss =  1.4987258911132812\n",
      "epoch =  10  step =  20  of total steps  100  loss =  1.411742925643921\n",
      "epoch =  10  step =  40  of total steps  100  loss =  1.8639081716537476\n",
      "epoch =  10  step =  60  of total steps  100  loss =  1.24309241771698\n",
      "epoch =  10  step =  80  of total steps  100  loss =  1.6654512882232666\n",
      "epoch :  10  /  30  | TL :  1.4865060877799987  | VL :  1.4129587411880493\n",
      "saving model\n",
      "epoch =  11  step =  0  of total steps  100  loss =  1.1995155811309814\n",
      "epoch =  11  step =  20  of total steps  100  loss =  1.5201667547225952\n",
      "epoch =  11  step =  40  of total steps  100  loss =  1.280012607574463\n",
      "epoch =  11  step =  60  of total steps  100  loss =  1.6966906785964966\n",
      "epoch =  11  step =  80  of total steps  100  loss =  1.339066743850708\n",
      "epoch :  11  /  30  | TL :  1.4746693027019502  | VL :  1.410372257232666\n",
      "saving model\n",
      "epoch =  12  step =  0  of total steps  100  loss =  1.5775830745697021\n",
      "epoch =  12  step =  20  of total steps  100  loss =  1.0474673509597778\n",
      "epoch =  12  step =  40  of total steps  100  loss =  1.7040984630584717\n",
      "epoch =  12  step =  60  of total steps  100  loss =  1.3802882432937622\n",
      "epoch =  12  step =  80  of total steps  100  loss =  1.2484171390533447\n",
      "epoch :  12  /  30  | TL :  1.4733078861236573  | VL :  1.4176486730575562\n",
      "epoch =  13  step =  0  of total steps  100  loss =  1.547569751739502\n",
      "epoch =  13  step =  20  of total steps  100  loss =  1.5403473377227783\n",
      "epoch =  13  step =  40  of total steps  100  loss =  1.38661789894104\n",
      "epoch =  13  step =  60  of total steps  100  loss =  1.5136066675186157\n",
      "epoch =  13  step =  80  of total steps  100  loss =  1.5323901176452637\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-30de42488699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pyt/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-9325b5d88d16>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, signal)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0msignal_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_std_dev\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0msignal_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-9f76cf7729ed>\u001b[0m in \u001b[0;36mrunning_std_dev\u001b[0;34m(signal, window_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '1conv_softmax.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = np.arange(200)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_get_accuracy(trainloader, Net) * 100, '/', _get_accuracy(valloader, Net) * 100, '/', _get_accuracy(testloader, Net) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('1conv_softmax.pt'))\n",
    "testing_Net.eval()\n",
    "print(_get_accuracy(trainloader, testing_Net) * 100, '/', _get_accuracy(valloader, testing_Net) * 100, '/', _get_accuracy(testloader, testing_Net) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even using running standard deviation of raw data doesn't help reduce overfitting significantly. So, next we try using running RMS of raw data.\n",
    "\n",
    "### PyTorch implementation of `running_rms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_rms(signal, window_size = 10):\n",
    "    ''' Returns running rms of 3D signal (batch_size, length, channels)\n",
    "    Note : torch.norm just gives vector 2-norm, so we need to divide it by\n",
    "    sqrt(window_size) to make it the RMS value\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    n = np.sqrt(window_size)\n",
    "    div = torch.tensor(np.array([n, n, n])).float()\n",
    "    if torch.cuda.is_available() : \n",
    "        div = div.cuda()\n",
    "    \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].norm(dim = 0) / div\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = signal[i][j]\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_rms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 150, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f08ec33e240>,\n",
       " <matplotlib.lines.Line2D at 0x7f08ec33e390>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "if torch.cuda.is_available() :\n",
    "    signal = signal.cuda().float()\n",
    "rms = running_rms(signal, window_size = 10)\n",
    "print(rms.shape)\n",
    "sig_ = signal[0].transpose(0, 1).cpu()\n",
    "mean_ = rms[0].transpose(0, 1).cpu()\n",
    "t = range(150)\n",
    "plt.plot(t, sig_[1].data.numpy(), 'r', t, mean_[1].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_rms` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 5, 3)\n",
    "        self.fc1 = nn.Linear(146 * 5, 5)\n",
    "#         self.mp = nn.MaxPool1d(2, 2)\n",
    "#         self.dropout = nn.Dropout(p = 0.5)\n",
    "#         self.bn1 = nn.BatchNorm1d(num_features = 5)\n",
    "#         self.bn2 = nn.BatchNorm1d(num_features = 5)\n",
    "#         self.bnfc = nn.BatchNorm1d(num_features = 5)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal_ = running_rms(signal, window_size = 10)\n",
    "        signal_ = signal_.view(-1, 3, 150)\n",
    "        out = F.relu(self.conv1(signal_))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out.view(-1, 146 * 5)\n",
    "        out = F.log_softmax(self.fc1(out), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '1conv_softmax.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = np.arange(30)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "        \n",
    "        if torch.cuda.is_available() : \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.cpu().numpy()\n",
    "        pred_ind = pred_ind.data.cpu().numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.eval().cuda()\n",
    "\n",
    "print(_get_accuracy(trainloader, Net) * 100, '/', _get_accuracy(valloader, Net) * 100, '/', _get_accuracy(testloader, Net) * 100)\n",
    "\n",
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('1conv_softmax.pt'))\n",
    "testing_Net.eval().cuda()\n",
    "print(_get_accuracy(trainloader, testing_Net) * 100, '/', _get_accuracy(valloader, testing_Net) * 100, '/', _get_accuracy(testloader, testing_Net) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
