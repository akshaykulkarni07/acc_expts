{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling TechniquE (SMOTE)\n",
    "This notebook has code that tries to use SMOTE (from `imblearn` library) to improve the performance of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import extract_relevant_features\n",
    "import sklearn\n",
    "import sklearn.naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting features using `tsfresh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_only_tsfresh_compatible.csv', names = ['x_acc', 'y_acc', 'z_acc', 'id'])\n",
    "labels = pd.read_csv('../data/labels_only.csv', names = ['Blocking', 'Dodging', 'Inactive', 'Moving', 'Sprinting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [06:13<00:00, 33.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068, 2382)\n"
     ]
    }
   ],
   "source": [
    "extracted_features = extract_features(data, column_id = \"id\", column_sort = None, column_kind = None, column_value = None)\n",
    "print(extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_arr = labels.values\n",
    "label_arr = np.argmax(label_arr, axis = 1)\n",
    "\n",
    "y_features = np.zeros(extracted_features.shape[0])\n",
    "for i in range(len(label_arr)) : \n",
    "    if i % 150 == 0 : \n",
    "        y_features[i // 150] = label_arr[i]\n",
    "        \n",
    "# Also converting into Pandas Series for use in extracting relevant features using tsfresh\n",
    "y = pd.Series(y_features, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068, 2382)\n",
      "(1068, 693)\n",
      "Counter({3.0: 411, 2.0: 213, 4.0: 196, 0.0: 129, 1.0: 119})\n"
     ]
    }
   ],
   "source": [
    "x_features = np.asarray(extracted_features)\n",
    "print(x_features.shape)\n",
    "x_features_relevant = np.asarray(features_filtered)\n",
    "print(x_features_relevant.shape)\n",
    "# Gives the number of examples per label\n",
    "print(Counter(y_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffle and split into train/test datasets, and normalize the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 2382)\n",
      "(267, 2382)\n",
      "(801,)\n",
      "(267,)\n",
      "Counter({3.0: 300, 2.0: 158, 4.0: 145, 0.0: 106, 1.0: 92})\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_f, y_test = train_test_split(x_features, y_features)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_f.shape)\n",
    "print(y_test.shape)\n",
    "x_f = normalize(x_train)\n",
    "x_test_norm = normalize(x_test)\n",
    "print(Counter(y_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Synthetic Minority Oversampling to equalize all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3.0: 300, 4.0: 300, 0.0: 300, 2.0: 300, 1.0: 300})\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state = 33)\n",
    "x_train_norm, y_train = sm.fit_resample(x_f, y_f)\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  3  7  9  4]\n",
      " [ 0  2  3 14  8]\n",
      " [ 3  2 26 16  8]\n",
      " [ 6 10 17 56 22]\n",
      " [ 2  6  4 12 27]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        23\n",
      "         1.0       0.09      0.07      0.08        27\n",
      "         2.0       0.46      0.47      0.46        55\n",
      "         3.0       0.52      0.50      0.51       111\n",
      "         4.0       0.39      0.53      0.45        51\n",
      "\n",
      "    accuracy                           0.42       267\n",
      "   macro avg       0.29      0.32      0.30       267\n",
      "weighted avg       0.40      0.42      0.40       267\n",
      "\n",
      "[[300   0   0   0   0]\n",
      " [  0 299   0   1   0]\n",
      " [  0   0 298   2   0]\n",
      " [  0   1   1 298   0]\n",
      " [  0   1   1   1 297]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       300\n",
      "         1.0       0.99      1.00      1.00       300\n",
      "         2.0       0.99      0.99      0.99       300\n",
      "         3.0       0.99      0.99      0.99       300\n",
      "         4.0       1.00      0.99      0.99       300\n",
      "\n",
      "    accuracy                           0.99      1500\n",
      "   macro avg       0.99      0.99      0.99      1500\n",
      "weighted avg       0.99      0.99      0.99      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_lin = RandomForestClassifier(n_estimators = 300, class_weight = 'balanced')\n",
    "svm_lin.fit(x_train_norm, y_train)\n",
    "y_pred = svm_lin.predict(x_test_norm)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_train_norm)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even using SMOTE did not improve the test accuracy, neither did it significantly reduce the bias due to class unbalance. So, now another option is to repeat the above feature extraction and class balancing on a running window based preprocessing of the data rather than the raw data.\n",
    "### TODO - HIGH-PRIORITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
