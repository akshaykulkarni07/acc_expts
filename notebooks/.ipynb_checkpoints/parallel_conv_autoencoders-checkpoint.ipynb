{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to create 3 parallel autoencoder networks for 3 axis IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.1.post2\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128100, 8)\n",
      "(16200, 8)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 150\n",
    "channels = 1\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' : \n",
    "            self.df = pd.read_csv('../data/train.csv', header = None)\n",
    "        elif mode == 'test' : \n",
    "            self.df = pd.read_csv('../data/test.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.iloc[idx : idx + reqd_len, 0].values\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 1].values\n",
    "        z = self.df.iloc[idx : idx + reqd_len, 2].values\n",
    "        x = x.astype('float')\n",
    "        y = y.astype('float')\n",
    "        z = z.astype('float')\n",
    "        assert(x.shape == (reqd_len, ))\n",
    "        assert(x.shape == (reqd_len, ))\n",
    "        assert(x.shape == (reqd_len, ))\n",
    "        return x, y, z\n",
    "        \n",
    "train_dataset = IMUDataset(mode = 'train')\n",
    "test_dataset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_indices = [(i * reqd_len) for i in range(len(train_dataset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(test_dataset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size = batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "trainloader2 = DataLoader(train_dataset, batch_size = 1, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "testloader2 = DataLoader(test_dataset, batch_size = 1, sampler = SubsetRandomSampler(test_indices), drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x2, y2, z2 = next(iter(trainloader2))\n",
    "# print(x2.shape)\n",
    "# signal = signal.detach().numpy()\n",
    "# signal = np.transpose(signal).reshape(-1)\n",
    "# t = range(150)\n",
    "# plt.plot(t, signal[150 : 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xavier initialization of network\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) : \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # defining layers\n",
    "        self.encoder0 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder0 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5)\n",
    "        )\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder1 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5)\n",
    "        )\n",
    "        self.encoder2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.Conv1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5),\n",
    "            nn.Tanh(),\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 1, kernel_size = 5)\n",
    "        )\n",
    "        self.classifier0 = nn.Sequential(\n",
    "            nn.Linear(142, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 5),\n",
    "            nn.LogSoftmax(dim = 1)\n",
    "        )\n",
    "        self.classifier1 = nn.Sequential(\n",
    "            nn.Linear(142, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 5),\n",
    "            nn.LogSoftmax(dim = 1)\n",
    "        )\n",
    "        self.classifier2 = nn.Sequential(\n",
    "            nn.Linear(142, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 5),\n",
    "            nn.LogSoftmax(dim = 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, y, z, encode = False, classify = False) :\n",
    "        features0 = self.encoder0(x)\n",
    "        features1 = self.encoder1(y)\n",
    "        features2 = self.encoder2(z)\n",
    "        \n",
    "        if encode and not classify:\n",
    "            return features0, features1, features2\n",
    "        elif not encode and classify :\n",
    "#             features = torch.cat((features0, features1, features2), dim = 2)\n",
    "            features0 = features0.view(batch_size, -1)\n",
    "            features1 = features1.view(batch_size, -1)\n",
    "            features2 = features2.view(batch_size, -1)\n",
    "            return self.classifier0(features0), self.classifier1(features1), self.classifier2(features2)\n",
    "        else : \n",
    "            return self.decoder0(features0), self.decoder1(features1), self.decoder2(features2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model on GPU\n"
     ]
    }
   ],
   "source": [
    "Net = AutoEncoder()\n",
    "Net.apply(init_weights)\n",
    "if torch.cuda.is_available() : \n",
    "    Net = Net.cuda()\n",
    "    print('Model on GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 20, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  53  loss =  0.26592668890953064\n",
      "epoch =  0  step =  20  of total steps  53  loss =  0.26794636249542236\n",
      "epoch =  0  step =  40  of total steps  53  loss =  0.22644081711769104\n",
      "Saving model 0.2569625880920662\n",
      "epoch =  1  step =  0  of total steps  53  loss =  0.2228827178478241\n",
      "epoch =  1  step =  20  of total steps  53  loss =  0.19344323873519897\n",
      "epoch =  1  step =  40  of total steps  53  loss =  0.14948439598083496\n",
      "Saving model 0.18375895608146237\n",
      "epoch =  2  step =  0  of total steps  53  loss =  0.15979689359664917\n",
      "epoch =  2  step =  20  of total steps  53  loss =  0.10326531529426575\n",
      "epoch =  2  step =  40  of total steps  53  loss =  0.09690327942371368\n",
      "Saving model 0.11351283738073313\n",
      "epoch =  3  step =  0  of total steps  53  loss =  0.11880318820476532\n",
      "epoch =  3  step =  20  of total steps  53  loss =  0.06902217864990234\n",
      "epoch =  3  step =  40  of total steps  53  loss =  0.0791013240814209\n",
      "Saving model 0.06799083034384926\n",
      "epoch =  4  step =  0  of total steps  53  loss =  0.056314606219530106\n",
      "epoch =  4  step =  20  of total steps  53  loss =  0.04642653837800026\n",
      "epoch =  4  step =  40  of total steps  53  loss =  0.0677587166428566\n",
      "Saving model 0.05426664861305704\n",
      "epoch =  5  step =  0  of total steps  53  loss =  0.04562409594655037\n",
      "epoch =  5  step =  20  of total steps  53  loss =  0.048567794263362885\n",
      "epoch =  5  step =  40  of total steps  53  loss =  0.044992029666900635\n",
      "Saving model 0.04952498384804096\n",
      "epoch =  6  step =  0  of total steps  53  loss =  0.04687284678220749\n",
      "epoch =  6  step =  20  of total steps  53  loss =  0.036034490913152695\n",
      "epoch =  6  step =  40  of total steps  53  loss =  0.05259266495704651\n",
      "Saving model 0.044651914563662604\n",
      "epoch =  7  step =  0  of total steps  53  loss =  0.03326185792684555\n",
      "epoch =  7  step =  20  of total steps  53  loss =  0.046379536390304565\n",
      "epoch =  7  step =  40  of total steps  53  loss =  0.055597927421331406\n",
      "Saving model 0.039255547108796404\n",
      "epoch =  8  step =  0  of total steps  53  loss =  0.03983674198389053\n",
      "epoch =  8  step =  20  of total steps  53  loss =  0.03600480407476425\n",
      "epoch =  8  step =  40  of total steps  53  loss =  0.03594169020652771\n",
      "Saving model 0.03426261316492872\n",
      "epoch =  9  step =  0  of total steps  53  loss =  0.024477776139974594\n",
      "epoch =  9  step =  20  of total steps  53  loss =  0.029592813923954964\n",
      "epoch =  9  step =  40  of total steps  53  loss =  0.02621057629585266\n",
      "Saving model 0.030230959736794797\n",
      "epoch =  10  step =  0  of total steps  53  loss =  0.03113611787557602\n",
      "epoch =  10  step =  20  of total steps  53  loss =  0.028496449813246727\n",
      "epoch =  10  step =  40  of total steps  53  loss =  0.030200369656085968\n",
      "Saving model 0.02689707820426743\n",
      "epoch =  11  step =  0  of total steps  53  loss =  0.03265759348869324\n",
      "epoch =  11  step =  20  of total steps  53  loss =  0.02746015042066574\n",
      "epoch =  11  step =  40  of total steps  53  loss =  0.018891196697950363\n",
      "Saving model 0.02398445056575649\n",
      "epoch =  12  step =  0  of total steps  53  loss =  0.0228887889534235\n",
      "epoch =  12  step =  20  of total steps  53  loss =  0.01942947879433632\n",
      "epoch =  12  step =  40  of total steps  53  loss =  0.023748179897665977\n",
      "Saving model 0.02121408062301717\n",
      "epoch =  13  step =  0  of total steps  53  loss =  0.021713862195611\n",
      "epoch =  13  step =  20  of total steps  53  loss =  0.016478773206472397\n",
      "epoch =  13  step =  40  of total steps  53  loss =  0.024891335517168045\n",
      "Saving model 0.01918921182107813\n",
      "epoch =  14  step =  0  of total steps  53  loss =  0.017987076193094254\n",
      "epoch =  14  step =  20  of total steps  53  loss =  0.022994359955191612\n",
      "epoch =  14  step =  40  of total steps  53  loss =  0.015675906091928482\n",
      "Saving model 0.01799164007786872\n",
      "epoch =  15  step =  0  of total steps  53  loss =  0.02186945080757141\n",
      "epoch =  15  step =  20  of total steps  53  loss =  0.017391785979270935\n",
      "epoch =  15  step =  40  of total steps  53  loss =  0.019592255353927612\n",
      "Saving model 0.017178810763893264\n",
      "epoch =  16  step =  0  of total steps  53  loss =  0.014852495864033699\n",
      "epoch =  16  step =  20  of total steps  53  loss =  0.015661023557186127\n",
      "epoch =  16  step =  40  of total steps  53  loss =  0.00959718693047762\n",
      "Saving model 0.01648708139458355\n",
      "epoch =  17  step =  0  of total steps  53  loss =  0.014825575053691864\n",
      "epoch =  17  step =  20  of total steps  53  loss =  0.010493200272321701\n",
      "epoch =  17  step =  40  of total steps  53  loss =  0.010336970910429955\n",
      "Saving model 0.01577689669112552\n",
      "epoch =  18  step =  0  of total steps  53  loss =  0.01721036434173584\n",
      "epoch =  18  step =  20  of total steps  53  loss =  0.013647889718413353\n",
      "epoch =  18  step =  40  of total steps  53  loss =  0.012651181779801846\n",
      "Saving model 0.015238302197518214\n",
      "epoch =  19  step =  0  of total steps  53  loss =  0.011837287805974483\n",
      "epoch =  19  step =  20  of total steps  53  loss =  0.015650248154997826\n",
      "epoch =  19  step =  40  of total steps  53  loss =  0.01649913564324379\n",
      "Saving model 0.014758789156264853\n",
      "epoch =  20  step =  0  of total steps  53  loss =  0.015555175952613354\n",
      "epoch =  20  step =  20  of total steps  53  loss =  0.014628296718001366\n",
      "epoch =  20  step =  40  of total steps  53  loss =  0.010097724385559559\n",
      "Saving model 0.014208939559054825\n",
      "epoch =  21  step =  0  of total steps  53  loss =  0.017493443563580513\n",
      "epoch =  21  step =  20  of total steps  53  loss =  0.01599857397377491\n",
      "epoch =  21  step =  40  of total steps  53  loss =  0.01879393681883812\n",
      "Saving model 0.013945647778938402\n",
      "epoch =  22  step =  0  of total steps  53  loss =  0.01340693049132824\n",
      "epoch =  22  step =  20  of total steps  53  loss =  0.009883426129817963\n",
      "epoch =  22  step =  40  of total steps  53  loss =  0.014701418578624725\n",
      "Saving model 0.013904720931401793\n",
      "epoch =  23  step =  0  of total steps  53  loss =  0.016168687492609024\n",
      "epoch =  23  step =  20  of total steps  53  loss =  0.018198788166046143\n",
      "epoch =  23  step =  40  of total steps  53  loss =  0.009125666692852974\n",
      "Saving model 0.013775038673489724\n",
      "epoch =  24  step =  0  of total steps  53  loss =  0.011406922712922096\n",
      "epoch =  24  step =  20  of total steps  53  loss =  0.01561066135764122\n",
      "epoch =  24  step =  40  of total steps  53  loss =  0.010508522391319275\n",
      "epoch =  25  step =  0  of total steps  53  loss =  0.012103045359253883\n",
      "epoch =  25  step =  20  of total steps  53  loss =  0.010104995220899582\n",
      "epoch =  25  step =  40  of total steps  53  loss =  0.01359061524271965\n",
      "Saving model 0.013726962484278769\n",
      "epoch =  26  step =  0  of total steps  53  loss =  0.014586375094950199\n",
      "epoch =  26  step =  20  of total steps  53  loss =  0.020114608108997345\n",
      "epoch =  26  step =  40  of total steps  53  loss =  0.017925312742590904\n",
      "Saving model 0.013662888088597442\n",
      "epoch =  27  step =  0  of total steps  53  loss =  0.014740637503564358\n",
      "epoch =  27  step =  20  of total steps  53  loss =  0.017821453511714935\n",
      "epoch =  27  step =  40  of total steps  53  loss =  0.01482214592397213\n",
      "Saving model 0.013610740227378765\n",
      "epoch =  28  step =  0  of total steps  53  loss =  0.013088146224617958\n",
      "epoch =  28  step =  20  of total steps  53  loss =  0.01356558222323656\n",
      "epoch =  28  step =  40  of total steps  53  loss =  0.011929050087928772\n",
      "Saving model 0.013549358478554015\n",
      "epoch =  29  step =  0  of total steps  53  loss =  0.01652870886027813\n",
      "epoch =  29  step =  20  of total steps  53  loss =  0.013512281700968742\n",
      "epoch =  29  step =  40  of total steps  53  loss =  0.011479556560516357\n",
      "Saving model 0.01351968942315511\n",
      "epoch =  30  step =  0  of total steps  53  loss =  0.013006595894694328\n",
      "epoch =  30  step =  20  of total steps  53  loss =  0.018535347655415535\n",
      "epoch =  30  step =  40  of total steps  53  loss =  0.019555144011974335\n",
      "Saving model 0.01347177811318411\n",
      "epoch =  31  step =  0  of total steps  53  loss =  0.011024780571460724\n",
      "epoch =  31  step =  20  of total steps  53  loss =  0.014572592452168465\n",
      "epoch =  31  step =  40  of total steps  53  loss =  0.01359817385673523\n",
      "Saving model 0.013365664941100579\n",
      "epoch =  32  step =  0  of total steps  53  loss =  0.01434608455747366\n",
      "epoch =  32  step =  20  of total steps  53  loss =  0.020349498838186264\n",
      "epoch =  32  step =  40  of total steps  53  loss =  0.010936507023870945\n",
      "Saving model 0.01330311968922615\n",
      "epoch =  33  step =  0  of total steps  53  loss =  0.014117639511823654\n",
      "epoch =  33  step =  20  of total steps  53  loss =  0.014247551560401917\n",
      "epoch =  33  step =  40  of total steps  53  loss =  0.013906585052609444\n",
      "Saving model 0.013291229546632408\n",
      "epoch =  34  step =  0  of total steps  53  loss =  0.01231280155479908\n",
      "epoch =  34  step =  20  of total steps  53  loss =  0.011221512220799923\n",
      "epoch =  34  step =  40  of total steps  53  loss =  0.012533350847661495\n",
      "Saving model 0.0132226529267599\n",
      "epoch =  35  step =  0  of total steps  53  loss =  0.016237737610936165\n",
      "epoch =  35  step =  20  of total steps  53  loss =  0.014336269348859787\n",
      "epoch =  35  step =  40  of total steps  53  loss =  0.014609593898057938\n",
      "Saving model 0.013151039668130424\n",
      "epoch =  36  step =  0  of total steps  53  loss =  0.017476115375757217\n",
      "epoch =  36  step =  20  of total steps  53  loss =  0.017607878893613815\n",
      "epoch =  36  step =  40  of total steps  53  loss =  0.013906346634030342\n",
      "Saving model 0.013023550587020954\n",
      "epoch =  37  step =  0  of total steps  53  loss =  0.01043005846440792\n",
      "epoch =  37  step =  20  of total steps  53  loss =  0.0103900833055377\n",
      "epoch =  37  step =  40  of total steps  53  loss =  0.010117167606949806\n",
      "Saving model 0.012978566213036483\n",
      "epoch =  38  step =  0  of total steps  53  loss =  0.009326476603746414\n",
      "epoch =  38  step =  20  of total steps  53  loss =  0.015636861324310303\n",
      "epoch =  38  step =  40  of total steps  53  loss =  0.01546578761190176\n",
      "Saving model 0.012889061386714567\n",
      "epoch =  39  step =  0  of total steps  53  loss =  0.008821633644402027\n",
      "epoch =  39  step =  20  of total steps  53  loss =  0.01008848287165165\n",
      "epoch =  39  step =  40  of total steps  53  loss =  0.017759151756763458\n",
      "Saving model 0.012862478532248511\n",
      "epoch =  40  step =  0  of total steps  53  loss =  0.012269025668501854\n",
      "epoch =  40  step =  20  of total steps  53  loss =  0.011667192913591862\n",
      "epoch =  40  step =  40  of total steps  53  loss =  0.015254251658916473\n",
      "Saving model 0.01277253548351099\n",
      "epoch =  41  step =  0  of total steps  53  loss =  0.009777038358151913\n",
      "epoch =  41  step =  20  of total steps  53  loss =  0.010091176256537437\n",
      "epoch =  41  step =  40  of total steps  53  loss =  0.01140572689473629\n",
      "Saving model 0.01276654837969339\n",
      "epoch =  42  step =  0  of total steps  53  loss =  0.013623964041471481\n",
      "epoch =  42  step =  20  of total steps  53  loss =  0.008798521012067795\n",
      "epoch =  42  step =  40  of total steps  53  loss =  0.015356380492448807\n",
      "Saving model 0.012759594281889358\n",
      "epoch =  43  step =  0  of total steps  53  loss =  0.011648816056549549\n",
      "epoch =  43  step =  20  of total steps  53  loss =  0.012167751789093018\n",
      "epoch =  43  step =  40  of total steps  53  loss =  0.013346919789910316\n",
      "Saving model 0.012747567234877145\n",
      "epoch =  44  step =  0  of total steps  53  loss =  0.016877004876732826\n",
      "epoch =  44  step =  20  of total steps  53  loss =  0.014934860169887543\n",
      "epoch =  44  step =  40  of total steps  53  loss =  0.01293867826461792\n",
      "Saving model 0.012737667767928456\n",
      "epoch =  45  step =  0  of total steps  53  loss =  0.011726525612175465\n",
      "epoch =  45  step =  20  of total steps  53  loss =  0.010995268821716309\n",
      "epoch =  45  step =  40  of total steps  53  loss =  0.015281285159289837\n",
      "Saving model 0.012728971297378247\n",
      "epoch =  46  step =  0  of total steps  53  loss =  0.011697560548782349\n",
      "epoch =  46  step =  20  of total steps  53  loss =  0.012233870103955269\n",
      "epoch =  46  step =  40  of total steps  53  loss =  0.01126897893846035\n",
      "Saving model 0.01271587250016208\n",
      "epoch =  47  step =  0  of total steps  53  loss =  0.011065016500651836\n",
      "epoch =  47  step =  20  of total steps  53  loss =  0.01026881393045187\n",
      "epoch =  47  step =  40  of total steps  53  loss =  0.012511048465967178\n",
      "Saving model 0.012699815356787646\n",
      "epoch =  48  step =  0  of total steps  53  loss =  0.012482096441090107\n",
      "epoch =  48  step =  20  of total steps  53  loss =  0.018734078854322433\n",
      "epoch =  48  step =  40  of total steps  53  loss =  0.014530529268085957\n",
      "epoch =  49  step =  0  of total steps  53  loss =  0.01221708208322525\n",
      "epoch =  49  step =  20  of total steps  53  loss =  0.00990528054535389\n",
      "epoch =  49  step =  40  of total steps  53  loss =  0.013476135209202766\n",
      "Saving model 0.012676835604855474\n",
      "epoch =  50  step =  0  of total steps  53  loss =  0.011455155909061432\n",
      "epoch =  50  step =  20  of total steps  53  loss =  0.014631947502493858\n",
      "epoch =  50  step =  40  of total steps  53  loss =  0.013071147724986076\n",
      "epoch =  51  step =  0  of total steps  53  loss =  0.012265379540622234\n",
      "epoch =  51  step =  20  of total steps  53  loss =  0.01129850558936596\n",
      "epoch =  51  step =  40  of total steps  53  loss =  0.015887092798948288\n",
      "epoch =  52  step =  0  of total steps  53  loss =  0.01354288961738348\n",
      "epoch =  52  step =  20  of total steps  53  loss =  0.010791163891553879\n",
      "epoch =  52  step =  40  of total steps  53  loss =  0.012537838891148567\n",
      "epoch =  53  step =  0  of total steps  53  loss =  0.013951923698186874\n",
      "epoch =  53  step =  20  of total steps  53  loss =  0.010918447747826576\n",
      "epoch =  53  step =  40  of total steps  53  loss =  0.01844674162566662\n",
      "epoch =  54  step =  0  of total steps  53  loss =  0.014215400442481041\n",
      "epoch =  54  step =  20  of total steps  53  loss =  0.014292867854237556\n",
      "epoch =  54  step =  40  of total steps  53  loss =  0.012265069410204887\n",
      "Saving model 0.012657328614227052\n",
      "epoch =  55  step =  0  of total steps  53  loss =  0.014145229011774063\n",
      "epoch =  55  step =  20  of total steps  53  loss =  0.016385693103075027\n",
      "epoch =  55  step =  40  of total steps  53  loss =  0.013002417981624603\n",
      "Saving model 0.012592082386309246\n",
      "epoch =  56  step =  0  of total steps  53  loss =  0.014468425884842873\n",
      "epoch =  56  step =  20  of total steps  53  loss =  0.00795383844524622\n",
      "epoch =  56  step =  40  of total steps  53  loss =  0.01053637359291315\n",
      "epoch =  57  step =  0  of total steps  53  loss =  0.014458971098065376\n",
      "epoch =  57  step =  20  of total steps  53  loss =  0.01015456486493349\n",
      "epoch =  57  step =  40  of total steps  53  loss =  0.01450156420469284\n",
      "epoch =  58  step =  0  of total steps  53  loss =  0.0091314185410738\n",
      "epoch =  58  step =  20  of total steps  53  loss =  0.015948273241519928\n",
      "epoch =  58  step =  40  of total steps  53  loss =  0.012189172208309174\n",
      "epoch =  59  step =  0  of total steps  53  loss =  0.014941273257136345\n",
      "epoch =  59  step =  20  of total steps  53  loss =  0.013948335312306881\n",
      "epoch =  59  step =  40  of total steps  53  loss =  0.011723153293132782\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 60\n",
    "total_step = len(train_dataset) // (batch_size * 150)\n",
    "train_loss_list = list()\n",
    "min_loss = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (x, y, z) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            x = Variable(x).cuda().float()\n",
    "            y = Variable(y).cuda().float()\n",
    "            z = Variable(z).cuda().float()\n",
    "        else : \n",
    "            x = Variable(x).float()\n",
    "            y = Variable(y).float()\n",
    "            z = Variable(z).float()\n",
    "        \n",
    "        x = x.reshape(-1, 1, 150)\n",
    "        y = y.reshape(-1, 1, 150)\n",
    "        z = z.reshape(-1, 1, 150)\n",
    "        \n",
    "        x_, y_, z_ = Net.forward(x, y, z)\n",
    "        \n",
    "        loss0 = criterion(x_, x)\n",
    "        loss1 = criterion(y_, y)\n",
    "        loss2 = criterion(z_, z)\n",
    "        loss = loss0 + loss1 + loss2\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    if train_loss < min_loss : \n",
    "        min_loss = train_loss\n",
    "        torch.save(Net.state_dict() , '../saved_models/autoencoder8.pt')\n",
    "        print('Saving model', min_loss)\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd11c8cfc50>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = range(60)\n",
    "plt.plot(j, train_loss_list, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying that AutoEncoder has not learnt the identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.1307,  0.7615,  0.3357, -0.0856,  0.3140]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[-0.5221, -0.0769, -0.0661, -0.3954, -0.3377]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[-0.1582,  0.1582, -0.4017, -0.3943,  0.1602]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[0.1559, 0.3260, 0.3958, 0.0255, 0.1097]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.2174, -0.0907,  0.6163,  0.6101,  0.0464]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.3962, -0.0820,  0.6766, -0.2582,  0.4214]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[0.0773, 0.0711, 0.3150, 0.4676, 0.1321]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.2797, -0.0062,  0.3985, -0.0722,  0.1970]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.3320,  0.6357,  0.1248, -0.1135, -0.0492]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[-0.1821,  0.0883, -0.5989, -0.2289, -0.6381]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0776,  0.5160,  0.2382, -0.0473,  0.3851]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[-0.3170, -0.3157,  0.2504, -0.5721,  0.0700]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder8.pt'))\n",
    "Net = Net.eval()\n",
    "print(Net.encoder0[0].weight)\n",
    "print(Net.encoder0[2].weight)\n",
    "print(Net.decoder0[0].weight)\n",
    "print(Net.decoder0[2].weight)\n",
    "print(Net.encoder1[0].weight)\n",
    "print(Net.encoder1[2].weight)\n",
    "print(Net.decoder1[0].weight)\n",
    "print(Net.decoder1[2].weight)\n",
    "print(Net.encoder2[0].weight)\n",
    "print(Net.encoder2[2].weight)\n",
    "print(Net.decoder2[0].weight)\n",
    "print(Net.decoder2[2].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking reconstruction quality visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011887481436133385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd11c85a5c0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Net = Net.eval()\n",
    "x, y, z = next(iter(trainloader))\n",
    "x = x.reshape(-1, 1, 150).float()\n",
    "y = y.reshape(-1, 1, 150).float()\n",
    "z = z.reshape(-1, 1, 150).float()\n",
    "x_, y_, z_ = Net.forward(x.float(), y.float(), z.float())\n",
    "loss0 = criterion(x_, x)\n",
    "loss1 = criterion(y_, y)\n",
    "loss2 = criterion(z_, z)\n",
    "print((loss0 + loss1 + loss2).item())\n",
    "\n",
    "x = x.detach().numpy()\n",
    "y = y.detach().numpy()\n",
    "z = z.detach().numpy()\n",
    "x_ = x_.detach().numpy()\n",
    "y_ = y_.detach().numpy()\n",
    "z_ = z_.detach().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(3, 1)\n",
    "ax[0].plot(x[0][0], 'r', label = 'original')\n",
    "ax[0].plot(x_[0][0], 'g', label = 'reconstructed')\n",
    "ax[1].plot(y[0][0], 'r')\n",
    "ax[1].plot(y_[0][0], 'g')\n",
    "ax[2].plot(z[0][0], 'r')\n",
    "ax[2].plot(z_[0][0], 'g')\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction quality is very much improved compared to using 3 channel autoencoder or using 1 channel data for training autoencoder. Now we can try to train a classifier based on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128100, 8)\n",
      "(15900, 8)\n",
      "(16200, 8)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 150\n",
    "channels = 3\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('../data/train.csv', header = None)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('../data/test.csv', header = None)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('../data/val.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        lab = self.df.iloc[idx : idx + reqd_len, 3 : ].values\n",
    "        ind = np.argmax(np.sum(lab, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + reqd_len, 0].values\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 1].values\n",
    "        z = self.df.iloc[idx : idx + reqd_len, 2].values\n",
    "        x = x.astype('float')\n",
    "        y = y.astype('float')\n",
    "        z = z.astype('float')\n",
    "        assert(x.shape == (reqd_len, ))\n",
    "        assert(y.shape == (reqd_len, ))\n",
    "        assert(z.shape == (reqd_len, ))\n",
    "        assert(label.shape == (5, ))\n",
    "        return x, y, z, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "batch_size = 16\n",
    "train_indices = [(i * reqd_len) for i in range(len(trainset) // reqd_len)]\n",
    "val_indices = [(i * reqd_len) for i in range(len(valset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(testset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading autoencoder saved model\n",
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder8.pt'), strict = False)\n",
    "# freezing encoders' and decoders' layers\n",
    "Net = Net.cuda()\n",
    "\n",
    "for param in Net.encoder0.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.encoder1.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.encoder2.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.decoder0.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.decoder1.parameters() : \n",
    "    param.requires_grad = False\n",
    "for param in Net.decoder2.parameters() : \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  53  loss =  1.562229037284851\n",
      "epoch =  0  step =  20  of total steps  53  loss =  1.513242244720459\n",
      "epoch =  0  step =  40  of total steps  53  loss =  1.5499019622802734\n",
      "epoch :  0  /  100  | TL :  1.5173714678242523  | VL :  1.5593128204345703\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  53  loss =  1.3422439098358154\n",
      "epoch =  1  step =  20  of total steps  53  loss =  1.3854888677597046\n",
      "epoch =  1  step =  40  of total steps  53  loss =  1.494871973991394\n",
      "epoch :  1  /  100  | TL :  1.4518622519834987  | VL :  1.5335348844528198\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  53  loss =  1.6037654876708984\n",
      "epoch =  2  step =  20  of total steps  53  loss =  1.1801064014434814\n",
      "epoch =  2  step =  40  of total steps  53  loss =  1.366023063659668\n",
      "epoch :  2  /  100  | TL :  1.413777859705799  | VL :  1.5698771476745605\n",
      "epoch =  3  step =  0  of total steps  53  loss =  1.259040355682373\n",
      "epoch =  3  step =  20  of total steps  53  loss =  1.487945318222046\n",
      "epoch =  3  step =  40  of total steps  53  loss =  1.2900238037109375\n",
      "epoch :  3  /  100  | TL :  1.370269404267365  | VL :  1.5408649444580078\n",
      "epoch =  4  step =  0  of total steps  53  loss =  1.2478431463241577\n",
      "epoch =  4  step =  20  of total steps  53  loss =  1.3793869018554688\n",
      "epoch =  4  step =  40  of total steps  53  loss =  1.1863030195236206\n",
      "epoch :  4  /  100  | TL :  1.316331483283133  | VL :  1.511387586593628\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  53  loss =  1.3500736951828003\n",
      "epoch =  5  step =  20  of total steps  53  loss =  1.1340303421020508\n",
      "epoch =  5  step =  40  of total steps  53  loss =  1.2383983135223389\n",
      "epoch :  5  /  100  | TL :  1.2670826540803009  | VL :  1.5153861045837402\n",
      "epoch =  6  step =  0  of total steps  53  loss =  1.221041202545166\n",
      "epoch =  6  step =  20  of total steps  53  loss =  1.3132190704345703\n",
      "epoch =  6  step =  40  of total steps  53  loss =  1.2574892044067383\n",
      "epoch :  6  /  100  | TL :  1.1841434240341187  | VL :  1.4989408254623413\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  53  loss =  1.2967734336853027\n",
      "epoch =  7  step =  20  of total steps  53  loss =  1.1788333654403687\n",
      "epoch =  7  step =  40  of total steps  53  loss =  1.2186568975448608\n",
      "epoch :  7  /  100  | TL :  1.150581344118658  | VL :  1.5379455089569092\n",
      "epoch =  8  step =  0  of total steps  53  loss =  1.2648060321807861\n",
      "epoch =  8  step =  20  of total steps  53  loss =  1.2220778465270996\n",
      "epoch =  8  step =  40  of total steps  53  loss =  1.050782322883606\n",
      "epoch :  8  /  100  | TL :  1.1104608391815762  | VL :  1.5840065479278564\n",
      "epoch =  9  step =  0  of total steps  53  loss =  1.076072096824646\n",
      "epoch =  9  step =  20  of total steps  53  loss =  0.9514167308807373\n",
      "epoch =  9  step =  40  of total steps  53  loss =  1.442236304283142\n",
      "epoch :  9  /  100  | TL :  1.0786735629135709  | VL :  1.5542402267456055\n",
      "epoch =  10  step =  0  of total steps  53  loss =  1.0107712745666504\n",
      "epoch =  10  step =  20  of total steps  53  loss =  1.3037465810775757\n",
      "epoch =  10  step =  40  of total steps  53  loss =  0.9683879613876343\n",
      "epoch :  10  /  100  | TL :  1.0435499065327194  | VL :  1.6224974393844604\n",
      "epoch =  11  step =  0  of total steps  53  loss =  0.7347859144210815\n",
      "epoch =  11  step =  20  of total steps  53  loss =  0.9843415021896362\n",
      "epoch =  11  step =  40  of total steps  53  loss =  0.9937604665756226\n",
      "epoch :  11  /  100  | TL :  0.9929925776877493  | VL :  1.615848422050476\n",
      "epoch =  12  step =  0  of total steps  53  loss =  0.8509995937347412\n",
      "epoch =  12  step =  20  of total steps  53  loss =  0.8653847575187683\n",
      "epoch =  12  step =  40  of total steps  53  loss =  1.0950602293014526\n",
      "epoch :  12  /  100  | TL :  0.9739822306722965  | VL :  1.6109378337860107\n",
      "epoch =  13  step =  0  of total steps  53  loss =  0.8807519674301147\n",
      "epoch =  13  step =  20  of total steps  53  loss =  0.7268614172935486\n",
      "epoch =  13  step =  40  of total steps  53  loss =  0.9422390460968018\n",
      "epoch :  13  /  100  | TL :  0.9493899097982442  | VL :  1.657314658164978\n",
      "epoch =  14  step =  0  of total steps  53  loss =  0.887531042098999\n",
      "epoch =  14  step =  20  of total steps  53  loss =  0.8043631315231323\n",
      "epoch =  14  step =  40  of total steps  53  loss =  0.6816136837005615\n",
      "epoch :  14  /  100  | TL :  0.9316049094470042  | VL :  1.684807300567627\n",
      "epoch =  15  step =  0  of total steps  53  loss =  0.687832772731781\n",
      "epoch =  15  step =  20  of total steps  53  loss =  1.0563724040985107\n",
      "epoch =  15  step =  40  of total steps  53  loss =  0.8052522540092468\n",
      "epoch :  15  /  100  | TL :  0.9126264531657381  | VL :  1.7195959091186523\n",
      "epoch =  16  step =  0  of total steps  53  loss =  0.7675713300704956\n",
      "epoch =  16  step =  20  of total steps  53  loss =  0.9553518295288086\n",
      "epoch =  16  step =  40  of total steps  53  loss =  0.7994775176048279\n",
      "epoch :  16  /  100  | TL :  0.8909096616619038  | VL :  1.701128363609314\n",
      "epoch =  17  step =  0  of total steps  53  loss =  0.7860453128814697\n",
      "epoch =  17  step =  20  of total steps  53  loss =  0.9005343914031982\n",
      "epoch =  17  step =  40  of total steps  53  loss =  0.7680897116661072\n",
      "epoch :  17  /  100  | TL :  0.8810907186202284  | VL :  1.7717547416687012\n",
      "epoch =  18  step =  0  of total steps  53  loss =  0.6764048933982849\n",
      "epoch =  18  step =  20  of total steps  53  loss =  1.006136417388916\n",
      "epoch =  18  step =  40  of total steps  53  loss =  0.8353979587554932\n",
      "epoch :  18  /  100  | TL :  0.8747890321713574  | VL :  1.6923502683639526\n",
      "epoch =  19  step =  0  of total steps  53  loss =  0.9651677012443542\n",
      "epoch =  19  step =  20  of total steps  53  loss =  0.9929072260856628\n",
      "epoch =  19  step =  40  of total steps  53  loss =  0.984287440776825\n",
      "epoch :  19  /  100  | TL :  0.8662514506645922  | VL :  1.726624846458435\n",
      "epoch =  20  step =  0  of total steps  53  loss =  0.9968878030776978\n",
      "epoch =  20  step =  20  of total steps  53  loss =  0.8252177238464355\n",
      "epoch =  20  step =  40  of total steps  53  loss =  0.8811101913452148\n",
      "epoch :  20  /  100  | TL :  0.8558490141382757  | VL :  1.7628406286239624\n",
      "epoch =  21  step =  0  of total steps  53  loss =  0.6233868598937988\n",
      "epoch =  21  step =  20  of total steps  53  loss =  0.64353346824646\n",
      "epoch =  21  step =  40  of total steps  53  loss =  1.0840718746185303\n",
      "epoch :  21  /  100  | TL :  0.8415520843469871  | VL :  1.7529082298278809\n",
      "epoch =  22  step =  0  of total steps  53  loss =  0.6356413960456848\n",
      "epoch =  22  step =  20  of total steps  53  loss =  0.895359992980957\n",
      "epoch =  22  step =  40  of total steps  53  loss =  0.7180753946304321\n",
      "epoch :  22  /  100  | TL :  0.8394655157934945  | VL :  1.7546334266662598\n",
      "epoch =  23  step =  0  of total steps  53  loss =  0.9389235377311707\n",
      "epoch =  23  step =  20  of total steps  53  loss =  0.7374728918075562\n",
      "epoch =  23  step =  40  of total steps  53  loss =  1.1082079410552979\n",
      "epoch :  23  /  100  | TL :  0.8347673056260595  | VL :  1.7453831434249878\n",
      "epoch =  24  step =  0  of total steps  53  loss =  1.0535895824432373\n",
      "epoch =  24  step =  20  of total steps  53  loss =  0.6985441446304321\n",
      "epoch =  24  step =  40  of total steps  53  loss =  0.9415066242218018\n",
      "epoch :  24  /  100  | TL :  0.8315388031725613  | VL :  1.7435029745101929\n",
      "epoch =  25  step =  0  of total steps  53  loss =  0.8462798595428467\n",
      "epoch =  25  step =  20  of total steps  53  loss =  1.025573492050171\n",
      "epoch =  25  step =  40  of total steps  53  loss =  0.7634202837944031\n",
      "epoch :  25  /  100  | TL :  0.8246249489064487  | VL :  1.763018012046814\n",
      "epoch =  26  step =  0  of total steps  53  loss =  0.7183568477630615\n",
      "epoch =  26  step =  20  of total steps  53  loss =  0.5047370195388794\n",
      "epoch =  26  step =  40  of total steps  53  loss =  0.9142575263977051\n",
      "epoch :  26  /  100  | TL :  0.8203186347799482  | VL :  1.7855660915374756\n",
      "epoch =  27  step =  0  of total steps  53  loss =  0.8111528754234314\n",
      "epoch =  27  step =  20  of total steps  53  loss =  0.8075342178344727\n",
      "epoch =  27  step =  40  of total steps  53  loss =  0.964353084564209\n",
      "epoch :  27  /  100  | TL :  0.8159959979777066  | VL :  1.7260608673095703\n",
      "epoch =  28  step =  0  of total steps  53  loss =  0.7513421773910522\n",
      "epoch =  28  step =  20  of total steps  53  loss =  1.0990824699401855\n",
      "epoch =  28  step =  40  of total steps  53  loss =  0.5885872840881348\n",
      "epoch :  28  /  100  | TL :  0.8142609180144544  | VL :  1.8005836009979248\n",
      "epoch =  29  step =  0  of total steps  53  loss =  0.5945371985435486\n",
      "epoch =  29  step =  20  of total steps  53  loss =  1.1045939922332764\n",
      "epoch =  29  step =  40  of total steps  53  loss =  0.646213173866272\n",
      "epoch :  29  /  100  | TL :  0.8153460408156773  | VL :  1.811180830001831\n",
      "epoch =  30  step =  0  of total steps  53  loss =  0.9805440902709961\n",
      "epoch =  30  step =  20  of total steps  53  loss =  0.6501809358596802\n",
      "epoch =  30  step =  40  of total steps  53  loss =  0.8143617510795593\n",
      "epoch :  30  /  100  | TL :  0.8120384992293592  | VL :  1.8040083646774292\n",
      "epoch =  31  step =  0  of total steps  53  loss =  0.6901085376739502\n",
      "epoch =  31  step =  20  of total steps  53  loss =  0.977990984916687\n",
      "epoch =  31  step =  40  of total steps  53  loss =  0.9079579710960388\n",
      "epoch :  31  /  100  | TL :  0.8077122276684023  | VL :  1.7685718536376953\n",
      "epoch =  32  step =  0  of total steps  53  loss =  0.6683129072189331\n",
      "epoch =  32  step =  20  of total steps  53  loss =  0.793328046798706\n",
      "epoch =  32  step =  40  of total steps  53  loss =  0.8036892414093018\n",
      "epoch :  32  /  100  | TL :  0.8075723175732594  | VL :  1.7818386554718018\n",
      "epoch =  33  step =  0  of total steps  53  loss =  0.6901324987411499\n",
      "epoch =  33  step =  20  of total steps  53  loss =  1.0075846910476685\n",
      "epoch =  33  step =  40  of total steps  53  loss =  0.9511731863021851\n",
      "epoch :  33  /  100  | TL :  0.8050567845128617  | VL :  1.779098391532898\n",
      "epoch =  34  step =  0  of total steps  53  loss =  0.8258265852928162\n",
      "epoch =  34  step =  20  of total steps  53  loss =  0.7666913270950317\n",
      "epoch =  34  step =  40  of total steps  53  loss =  0.8325895071029663\n",
      "epoch :  34  /  100  | TL :  0.8014244954541044  | VL :  1.7697423696517944\n",
      "epoch =  35  step =  0  of total steps  53  loss =  0.7514791488647461\n",
      "epoch =  35  step =  20  of total steps  53  loss =  1.069990873336792\n",
      "epoch =  35  step =  40  of total steps  53  loss =  0.5319775938987732\n",
      "epoch :  35  /  100  | TL :  0.8042230786017652  | VL :  1.7300968170166016\n",
      "epoch =  36  step =  0  of total steps  53  loss =  0.6100068688392639\n",
      "epoch =  36  step =  20  of total steps  53  loss =  0.6339036226272583\n",
      "epoch =  36  step =  40  of total steps  53  loss =  0.910280704498291\n",
      "epoch :  36  /  100  | TL :  0.802824967874671  | VL :  1.7397831678390503\n",
      "epoch =  37  step =  0  of total steps  53  loss =  0.758587121963501\n",
      "epoch =  37  step =  20  of total steps  53  loss =  0.7656814455986023\n",
      "epoch =  37  step =  40  of total steps  53  loss =  0.7660402059555054\n",
      "epoch :  37  /  100  | TL :  0.802935890431674  | VL :  1.7734136581420898\n",
      "epoch =  38  step =  0  of total steps  53  loss =  0.9272106885910034\n",
      "epoch =  38  step =  20  of total steps  53  loss =  0.7463254332542419\n",
      "epoch =  38  step =  40  of total steps  53  loss =  0.6119034290313721\n",
      "epoch :  38  /  100  | TL :  0.7995617738309896  | VL :  1.8020758628845215\n",
      "epoch =  39  step =  0  of total steps  53  loss =  0.8148436546325684\n",
      "epoch =  39  step =  20  of total steps  53  loss =  0.8717604875564575\n",
      "epoch =  39  step =  40  of total steps  53  loss =  0.9154813289642334\n",
      "epoch :  39  /  100  | TL :  0.8015884745795772  | VL :  1.8024762868881226\n",
      "epoch =  40  step =  0  of total steps  53  loss =  0.8305586576461792\n",
      "epoch =  40  step =  20  of total steps  53  loss =  0.8481770753860474\n",
      "epoch =  40  step =  40  of total steps  53  loss =  0.7119758129119873\n",
      "epoch :  40  /  100  | TL :  0.8017646321710551  | VL :  1.7243614196777344\n",
      "epoch =  41  step =  0  of total steps  53  loss =  0.8128489851951599\n",
      "epoch =  41  step =  20  of total steps  53  loss =  0.6978422403335571\n",
      "epoch =  41  step =  40  of total steps  53  loss =  0.7748862504959106\n",
      "epoch :  41  /  100  | TL :  0.7977700683305848  | VL :  1.7810672521591187\n",
      "epoch =  42  step =  0  of total steps  53  loss =  0.7317419052124023\n",
      "epoch =  42  step =  20  of total steps  53  loss =  0.7775920629501343\n",
      "epoch =  42  step =  40  of total steps  53  loss =  0.8531941175460815\n",
      "epoch :  42  /  100  | TL :  0.7972931378292587  | VL :  1.7555698156356812\n",
      "epoch =  43  step =  0  of total steps  53  loss =  0.8072113394737244\n",
      "epoch =  43  step =  20  of total steps  53  loss =  0.7197403907775879\n",
      "epoch =  43  step =  40  of total steps  53  loss =  0.5942442417144775\n",
      "epoch :  43  /  100  | TL :  0.7977736991531444  | VL :  1.7699573040008545\n",
      "epoch =  44  step =  0  of total steps  53  loss =  0.7581990957260132\n",
      "epoch =  44  step =  20  of total steps  53  loss =  0.6690628528594971\n",
      "epoch =  44  step =  40  of total steps  53  loss =  0.8117372393608093\n",
      "epoch :  44  /  100  | TL :  0.7994562544912662  | VL :  1.7958297729492188\n",
      "epoch =  45  step =  0  of total steps  53  loss =  0.7720417380332947\n",
      "epoch =  45  step =  20  of total steps  53  loss =  0.8341797590255737\n",
      "epoch =  45  step =  40  of total steps  53  loss =  0.7485288381576538\n",
      "epoch :  45  /  100  | TL :  0.7967765477468383  | VL :  1.8223674297332764\n",
      "epoch =  46  step =  0  of total steps  53  loss =  0.7382259368896484\n",
      "epoch =  46  step =  20  of total steps  53  loss =  0.8145838975906372\n",
      "epoch =  46  step =  40  of total steps  53  loss =  0.8499991297721863\n",
      "epoch :  46  /  100  | TL :  0.7981160024427018  | VL :  1.7622795104980469\n",
      "epoch =  47  step =  0  of total steps  53  loss =  0.7548343539237976\n",
      "epoch =  47  step =  20  of total steps  53  loss =  1.0482699871063232\n",
      "epoch =  47  step =  40  of total steps  53  loss =  0.8551933169364929\n",
      "epoch :  47  /  100  | TL :  0.7989052927718973  | VL :  1.8069647550582886\n",
      "epoch =  48  step =  0  of total steps  53  loss =  0.8825002908706665\n",
      "epoch =  48  step =  20  of total steps  53  loss =  0.5759002566337585\n",
      "epoch =  48  step =  40  of total steps  53  loss =  1.0762956142425537\n",
      "epoch :  48  /  100  | TL :  0.7980921200986179  | VL :  1.7737606763839722\n",
      "epoch =  49  step =  0  of total steps  53  loss =  1.110192894935608\n",
      "epoch =  49  step =  20  of total steps  53  loss =  0.6098642349243164\n",
      "epoch =  49  step =  40  of total steps  53  loss =  0.9038044810295105\n",
      "epoch :  49  /  100  | TL :  0.7942157719495162  | VL :  1.7382726669311523\n",
      "epoch =  50  step =  0  of total steps  53  loss =  0.8541048765182495\n",
      "epoch =  50  step =  20  of total steps  53  loss =  0.9086490869522095\n",
      "epoch =  50  step =  40  of total steps  53  loss =  0.9373102188110352\n",
      "epoch :  50  /  100  | TL :  0.7975245365556681  | VL :  1.7978438138961792\n",
      "epoch =  51  step =  0  of total steps  53  loss =  0.8349825739860535\n",
      "epoch =  51  step =  20  of total steps  53  loss =  0.5677346587181091\n",
      "epoch =  51  step =  40  of total steps  53  loss =  0.8801726698875427\n",
      "epoch :  51  /  100  | TL :  0.7978353455381574  | VL :  1.791156530380249\n",
      "epoch =  52  step =  0  of total steps  53  loss =  1.1623986959457397\n",
      "epoch =  52  step =  20  of total steps  53  loss =  1.1302520036697388\n",
      "epoch =  52  step =  40  of total steps  53  loss =  0.7208143472671509\n",
      "epoch :  52  /  100  | TL :  0.7966564578830071  | VL :  1.7980670928955078\n",
      "epoch =  53  step =  0  of total steps  53  loss =  1.0058432817459106\n",
      "epoch =  53  step =  20  of total steps  53  loss =  0.7388017177581787\n",
      "epoch =  53  step =  40  of total steps  53  loss =  0.7860461473464966\n",
      "epoch :  53  /  100  | TL :  0.7967504870216802  | VL :  1.7229136228561401\n",
      "epoch =  54  step =  0  of total steps  53  loss =  0.9370032548904419\n",
      "epoch =  54  step =  20  of total steps  53  loss =  0.6637675762176514\n",
      "epoch =  54  step =  40  of total steps  53  loss =  0.6912059187889099\n",
      "epoch :  54  /  100  | TL :  0.7954450193441139  | VL :  1.7438135147094727\n",
      "epoch =  55  step =  0  of total steps  53  loss =  0.7454997897148132\n",
      "epoch =  55  step =  20  of total steps  53  loss =  0.798850953578949\n",
      "epoch =  55  step =  40  of total steps  53  loss =  0.6982417106628418\n",
      "epoch :  55  /  100  | TL :  0.7973697073054764  | VL :  1.736093282699585\n",
      "epoch =  56  step =  0  of total steps  53  loss =  0.6501731276512146\n",
      "epoch =  56  step =  20  of total steps  53  loss =  0.7043356895446777\n",
      "epoch =  56  step =  40  of total steps  53  loss =  0.6334700584411621\n",
      "epoch :  56  /  100  | TL :  0.7957915495026786  | VL :  1.8052949905395508\n",
      "epoch =  57  step =  0  of total steps  53  loss =  0.9865972399711609\n",
      "epoch =  57  step =  20  of total steps  53  loss =  0.7979493141174316\n",
      "epoch =  57  step =  40  of total steps  53  loss =  0.594149112701416\n",
      "epoch :  57  /  100  | TL :  0.7969978631667372  | VL :  1.8121765851974487\n",
      "epoch =  58  step =  0  of total steps  53  loss =  0.9814493060112\n",
      "epoch =  58  step =  20  of total steps  53  loss =  0.9388644099235535\n",
      "epoch =  58  step =  40  of total steps  53  loss =  0.755510687828064\n",
      "epoch :  58  /  100  | TL :  0.7983751207027795  | VL :  1.7667640447616577\n",
      "epoch =  59  step =  0  of total steps  53  loss =  0.7073996067047119\n",
      "epoch =  59  step =  20  of total steps  53  loss =  0.715411901473999\n",
      "epoch =  59  step =  40  of total steps  53  loss =  0.6645751595497131\n",
      "epoch :  59  /  100  | TL :  0.797224482275405  | VL :  1.7587536573410034\n",
      "epoch =  60  step =  0  of total steps  53  loss =  0.6177495121955872\n",
      "epoch =  60  step =  20  of total steps  53  loss =  0.7592133283615112\n",
      "epoch =  60  step =  40  of total steps  53  loss =  0.7674428820610046\n",
      "epoch :  60  /  100  | TL :  0.7961766967233622  | VL :  1.8153331279754639\n",
      "epoch =  61  step =  0  of total steps  53  loss =  0.8664392232894897\n",
      "epoch =  61  step =  20  of total steps  53  loss =  0.8718305826187134\n",
      "epoch =  61  step =  40  of total steps  53  loss =  0.8129444122314453\n",
      "epoch :  61  /  100  | TL :  0.7959997766422775  | VL :  1.769850730895996\n",
      "epoch =  62  step =  0  of total steps  53  loss =  0.7763240337371826\n",
      "epoch =  62  step =  20  of total steps  53  loss =  0.7655969858169556\n",
      "epoch =  62  step =  40  of total steps  53  loss =  0.8084300756454468\n",
      "epoch :  62  /  100  | TL :  0.7948035406616499  | VL :  1.7980120182037354\n",
      "epoch =  63  step =  0  of total steps  53  loss =  0.8868433237075806\n",
      "epoch =  63  step =  20  of total steps  53  loss =  0.793768048286438\n",
      "epoch =  63  step =  40  of total steps  53  loss =  0.7958507537841797\n",
      "epoch :  63  /  100  | TL :  0.7974786117391767  | VL :  1.7849304676055908\n",
      "epoch =  64  step =  0  of total steps  53  loss =  0.6925909519195557\n",
      "epoch =  64  step =  20  of total steps  53  loss =  0.6362528204917908\n",
      "epoch =  64  step =  40  of total steps  53  loss =  0.7270369529724121\n",
      "epoch :  64  /  100  | TL :  0.7965095993482841  | VL :  1.8127171993255615\n",
      "epoch =  65  step =  0  of total steps  53  loss =  0.8032688498497009\n",
      "epoch =  65  step =  20  of total steps  53  loss =  0.6636034250259399\n",
      "epoch =  65  step =  40  of total steps  53  loss =  0.5759706497192383\n",
      "epoch :  65  /  100  | TL :  0.796373796912859  | VL :  1.7552646398544312\n",
      "epoch =  66  step =  0  of total steps  53  loss =  0.8918389678001404\n",
      "epoch =  66  step =  20  of total steps  53  loss =  0.5803279280662537\n",
      "epoch =  66  step =  40  of total steps  53  loss =  0.7247082591056824\n",
      "epoch :  66  /  100  | TL :  0.7968011498451233  | VL :  1.7980469465255737\n",
      "epoch =  67  step =  0  of total steps  53  loss =  0.7744611501693726\n",
      "epoch =  67  step =  20  of total steps  53  loss =  0.8605378866195679\n",
      "epoch =  67  step =  40  of total steps  53  loss =  0.7306076288223267\n",
      "epoch :  67  /  100  | TL :  0.7978946718404878  | VL :  1.7627623081207275\n",
      "epoch =  68  step =  0  of total steps  53  loss =  0.8236185908317566\n",
      "epoch =  68  step =  20  of total steps  53  loss =  0.9398541450500488\n",
      "epoch =  68  step =  40  of total steps  53  loss =  0.7830781936645508\n",
      "epoch :  68  /  100  | TL :  0.7974128070867287  | VL :  1.7807215452194214\n",
      "epoch =  69  step =  0  of total steps  53  loss =  0.6450594067573547\n",
      "epoch =  69  step =  20  of total steps  53  loss =  0.7196307182312012\n",
      "epoch =  69  step =  40  of total steps  53  loss =  0.994590699672699\n",
      "epoch :  69  /  100  | TL :  0.7952192245789294  | VL :  1.7775806188583374\n",
      "epoch =  70  step =  0  of total steps  53  loss =  0.761938750743866\n",
      "epoch =  70  step =  20  of total steps  53  loss =  0.7426208257675171\n",
      "epoch =  70  step =  40  of total steps  53  loss =  0.7547246217727661\n",
      "epoch :  70  /  100  | TL :  0.7942480917246837  | VL :  1.7584885358810425\n",
      "epoch =  71  step =  0  of total steps  53  loss =  0.7769087553024292\n",
      "epoch =  71  step =  20  of total steps  53  loss =  0.8009669780731201\n",
      "epoch =  71  step =  40  of total steps  53  loss =  0.8413451910018921\n",
      "epoch :  71  /  100  | TL :  0.7966298415975751  | VL :  1.8092074394226074\n",
      "epoch =  72  step =  0  of total steps  53  loss =  0.6373572945594788\n",
      "epoch =  72  step =  20  of total steps  53  loss =  0.7690272331237793\n",
      "epoch =  72  step =  40  of total steps  53  loss =  0.7289595007896423\n",
      "epoch :  72  /  100  | TL :  0.7978308110866906  | VL :  1.7881754636764526\n",
      "epoch =  73  step =  0  of total steps  53  loss =  0.9944941401481628\n",
      "epoch =  73  step =  20  of total steps  53  loss =  0.8307440280914307\n",
      "epoch =  73  step =  40  of total steps  53  loss =  0.7428336143493652\n",
      "epoch :  73  /  100  | TL :  0.7975669930566032  | VL :  1.7920472621917725\n",
      "epoch =  74  step =  0  of total steps  53  loss =  0.992548942565918\n",
      "epoch =  74  step =  20  of total steps  53  loss =  0.7934160232543945\n",
      "epoch =  74  step =  40  of total steps  53  loss =  0.6120578050613403\n",
      "epoch :  74  /  100  | TL :  0.7976112354476497  | VL :  1.819291353225708\n",
      "epoch =  75  step =  0  of total steps  53  loss =  0.6368828415870667\n",
      "epoch =  75  step =  20  of total steps  53  loss =  1.2582225799560547\n",
      "epoch =  75  step =  40  of total steps  53  loss =  0.8311650156974792\n",
      "epoch :  75  /  100  | TL :  0.7934195050653422  | VL :  1.791792631149292\n",
      "epoch =  76  step =  0  of total steps  53  loss =  0.860318660736084\n",
      "epoch =  76  step =  20  of total steps  53  loss =  0.8634695410728455\n",
      "epoch =  76  step =  40  of total steps  53  loss =  0.8606570959091187\n",
      "epoch :  76  /  100  | TL :  0.7969550782779478  | VL :  1.810243010520935\n",
      "epoch =  77  step =  0  of total steps  53  loss =  0.953039824962616\n",
      "epoch =  77  step =  20  of total steps  53  loss =  0.7313398122787476\n",
      "epoch =  77  step =  40  of total steps  53  loss =  0.7650140523910522\n",
      "epoch :  77  /  100  | TL :  0.7991455321042042  | VL :  1.813890814781189\n",
      "epoch =  78  step =  0  of total steps  53  loss =  0.9897003173828125\n",
      "epoch =  78  step =  20  of total steps  53  loss =  0.7024483680725098\n",
      "epoch =  78  step =  40  of total steps  53  loss =  0.7339693307876587\n",
      "epoch :  78  /  100  | TL :  0.7964981546941793  | VL :  1.7923588752746582\n",
      "epoch =  79  step =  0  of total steps  53  loss =  0.9366330504417419\n",
      "epoch =  79  step =  20  of total steps  53  loss =  0.8680128455162048\n",
      "epoch =  79  step =  40  of total steps  53  loss =  0.8849881887435913\n",
      "epoch :  79  /  100  | TL :  0.7959048039508316  | VL :  1.8400046825408936\n",
      "epoch =  80  step =  0  of total steps  53  loss =  0.7700220346450806\n",
      "epoch =  80  step =  20  of total steps  53  loss =  0.6223301887512207\n",
      "epoch =  80  step =  40  of total steps  53  loss =  1.0574676990509033\n",
      "epoch :  80  /  100  | TL :  0.792147049364054  | VL :  1.7768447399139404\n",
      "epoch =  81  step =  0  of total steps  53  loss =  0.7202309370040894\n",
      "epoch =  81  step =  20  of total steps  53  loss =  0.9780774116516113\n",
      "epoch =  81  step =  40  of total steps  53  loss =  0.9171454310417175\n",
      "epoch :  81  /  100  | TL :  0.7975243374986468  | VL :  1.8122801780700684\n",
      "epoch =  82  step =  0  of total steps  53  loss =  0.7418448328971863\n",
      "epoch =  82  step =  20  of total steps  53  loss =  0.9371442198753357\n",
      "epoch =  82  step =  40  of total steps  53  loss =  1.106461524963379\n",
      "epoch :  82  /  100  | TL :  0.7981345147456763  | VL :  1.8452229499816895\n",
      "epoch =  83  step =  0  of total steps  53  loss =  0.8132976293563843\n",
      "epoch =  83  step =  20  of total steps  53  loss =  0.7650536298751831\n",
      "epoch =  83  step =  40  of total steps  53  loss =  0.9766781330108643\n",
      "epoch :  83  /  100  | TL :  0.7962124055286623  | VL :  1.7883286476135254\n",
      "epoch =  84  step =  0  of total steps  53  loss =  0.7104970812797546\n",
      "epoch =  84  step =  20  of total steps  53  loss =  0.683497428894043\n",
      "epoch =  84  step =  40  of total steps  53  loss =  0.7594239711761475\n",
      "epoch :  84  /  100  | TL :  0.7955479498179454  | VL :  1.82956862449646\n",
      "epoch =  85  step =  0  of total steps  53  loss =  0.7552062273025513\n",
      "epoch =  85  step =  20  of total steps  53  loss =  0.7304631471633911\n",
      "epoch =  85  step =  40  of total steps  53  loss =  0.8976495265960693\n",
      "epoch :  85  /  100  | TL :  0.7960536198795967  | VL :  1.8506593704223633\n",
      "epoch =  86  step =  0  of total steps  53  loss =  0.9857778549194336\n",
      "epoch =  86  step =  20  of total steps  53  loss =  0.9046306610107422\n",
      "epoch =  86  step =  40  of total steps  53  loss =  0.8048384189605713\n",
      "epoch :  86  /  100  | TL :  0.7943087051499564  | VL :  1.818336844444275\n",
      "epoch =  87  step =  0  of total steps  53  loss =  0.7896771430969238\n",
      "epoch =  87  step =  20  of total steps  53  loss =  0.824786365032196\n",
      "epoch =  87  step =  40  of total steps  53  loss =  0.7689385414123535\n",
      "epoch :  87  /  100  | TL :  0.7965606214865198  | VL :  1.7301782369613647\n",
      "epoch =  88  step =  0  of total steps  53  loss =  0.8579992055892944\n",
      "epoch =  88  step =  20  of total steps  53  loss =  0.6510627269744873\n",
      "epoch =  88  step =  40  of total steps  53  loss =  0.8793150186538696\n",
      "epoch :  88  /  100  | TL :  0.7954654423695691  | VL :  1.8060811758041382\n",
      "epoch =  89  step =  0  of total steps  53  loss =  0.7298603057861328\n",
      "epoch =  89  step =  20  of total steps  53  loss =  0.879705548286438\n",
      "epoch =  89  step =  40  of total steps  53  loss =  0.897498607635498\n",
      "epoch :  89  /  100  | TL :  0.7987159085723589  | VL :  1.7865540981292725\n",
      "epoch =  90  step =  0  of total steps  53  loss =  0.6717349290847778\n",
      "epoch =  90  step =  20  of total steps  53  loss =  0.9647575616836548\n",
      "epoch =  90  step =  40  of total steps  53  loss =  0.6849374771118164\n",
      "epoch :  90  /  100  | TL :  0.7969740415519139  | VL :  1.7961597442626953\n",
      "epoch =  91  step =  0  of total steps  53  loss =  0.9540898203849792\n",
      "epoch =  91  step =  20  of total steps  53  loss =  0.7651801109313965\n",
      "epoch =  91  step =  40  of total steps  53  loss =  0.8129677176475525\n",
      "epoch :  91  /  100  | TL :  0.7972118809538068  | VL :  1.8430488109588623\n",
      "epoch =  92  step =  0  of total steps  53  loss =  0.8074166178703308\n",
      "epoch =  92  step =  20  of total steps  53  loss =  0.8407682180404663\n",
      "epoch =  92  step =  40  of total steps  53  loss =  0.8384578227996826\n",
      "epoch :  92  /  100  | TL :  0.7973111935381619  | VL :  1.787061095237732\n",
      "epoch =  93  step =  0  of total steps  53  loss =  0.8063692450523376\n",
      "epoch =  93  step =  20  of total steps  53  loss =  0.7388864755630493\n",
      "epoch =  93  step =  40  of total steps  53  loss =  0.8429204821586609\n",
      "epoch :  93  /  100  | TL :  0.7946498135350785  | VL :  1.8190929889678955\n",
      "epoch =  94  step =  0  of total steps  53  loss =  0.8963648676872253\n",
      "epoch =  94  step =  20  of total steps  53  loss =  0.7210702300071716\n",
      "epoch =  94  step =  40  of total steps  53  loss =  0.886042058467865\n",
      "epoch :  94  /  100  | TL :  0.7962514848079322  | VL :  1.7541382312774658\n",
      "epoch =  95  step =  0  of total steps  53  loss =  0.6920912265777588\n",
      "epoch =  95  step =  20  of total steps  53  loss =  0.8911935687065125\n",
      "epoch =  95  step =  40  of total steps  53  loss =  0.9107941389083862\n",
      "epoch :  95  /  100  | TL :  0.7972888046840452  | VL :  1.7458853721618652\n",
      "epoch =  96  step =  0  of total steps  53  loss =  0.8989631533622742\n",
      "epoch =  96  step =  20  of total steps  53  loss =  0.7562589645385742\n",
      "epoch =  96  step =  40  of total steps  53  loss =  0.8797721266746521\n",
      "epoch :  96  /  100  | TL :  0.7976295621889942  | VL :  1.7540401220321655\n",
      "epoch =  97  step =  0  of total steps  53  loss =  0.7741486430168152\n",
      "epoch =  97  step =  20  of total steps  53  loss =  0.6058695316314697\n",
      "epoch =  97  step =  40  of total steps  53  loss =  0.6493162512779236\n",
      "epoch :  97  /  100  | TL :  0.7929467851260923  | VL :  1.723667860031128\n",
      "epoch =  98  step =  0  of total steps  53  loss =  0.7262647151947021\n",
      "epoch =  98  step =  20  of total steps  53  loss =  0.6372025012969971\n",
      "epoch =  98  step =  40  of total steps  53  loss =  0.5443316698074341\n",
      "epoch :  98  /  100  | TL :  0.7977914214134216  | VL :  1.8378223180770874\n",
      "epoch =  99  step =  0  of total steps  53  loss =  0.5239824056625366\n",
      "epoch =  99  step =  20  of total steps  53  loss =  0.8234103918075562\n",
      "epoch =  99  step =  40  of total steps  53  loss =  0.6155709028244019\n",
      "epoch :  99  /  100  | TL :  0.795736164416907  | VL :  1.771073818206787\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (x, y, z, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            x = Variable(x).cuda().float()\n",
    "            y = Variable(y).cuda().float()\n",
    "            z = Variable(z).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            x = Variable(x).float()\n",
    "            y = Variable(y).float()\n",
    "            z = Variable(z).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "        \n",
    "        x = x.reshape(-1, 1, 150)\n",
    "        y = y.reshape(-1, 1, 150)\n",
    "        z = z.reshape(-1, 1, 150)\n",
    "        \n",
    "        x_pred, y_pred, z_pred = Net.forward(x, y, z, classify = True)\n",
    "        \n",
    "#         loss = criterion((x_pred + y_pred + z_pred) / 3, target)\n",
    "        loss0 = criterion(x_pred, target)\n",
    "        loss1 = criterion(y_pred, target)\n",
    "        loss2 = criterion(z_pred, target)      \n",
    "        loss = (loss0 + loss1 + loss2) / 3\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (x, y, z, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                x = Variable(x).cuda().float()\n",
    "                y = Variable(y).cuda().float()\n",
    "                z = Variable(z).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                x = Variable(x).float()\n",
    "                y = Variable(y).float()\n",
    "                z = Variable(z).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "            \n",
    "            x = x.reshape(-1, 1, 150)\n",
    "            y = y.reshape(-1, 1, 150)\n",
    "            z = z.reshape(-1, 1, 150)\n",
    "            \n",
    "            # Forward pass\n",
    "            x_pred, y_pred, z_pred = Net.forward(x, y, z, classify = True)\n",
    "              \n",
    "            loss0 = criterion(x_pred, target)\n",
    "            loss1 = criterion(y_pred, target)\n",
    "            loss2 = criterion(z_pred, target)\n",
    "            loss = (loss0 + loss1 + loss2) / 3\n",
    "\n",
    "#             loss = criterion((x_pred + y_pred + z_pred) / 3, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '../saved_models/autoencoder_classifier3.pt')\n",
    "    \n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd0fd57f6a0>,\n",
       " <matplotlib.lines.Line2D at 0x7fd0fd57f7f0>]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(100)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (x, y, z, labels) in enumerate(dataloader):\n",
    "        x = Variable(x).float()\n",
    "        y = Variable(y).float()\n",
    "        z = Variable(z).float()\n",
    "        labels = Variable(labels).float()\n",
    "        x = x.reshape(-1, 1, 150)\n",
    "        y = y.reshape(-1, 1, 150)\n",
    "        z = z.reshape(-1, 1, 150)\n",
    "        x_pred, y_pred, z_pred = Net(x, y, z, classify = True)\n",
    "        outputs = (x_pred + y_pred + z_pred) / 3\n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7983490566037735\n",
      "0.4270833333333333\n",
      "0.375\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader, Net))\n",
    "print(_get_accuracy(testloader, Net))\n",
    "print(_get_accuracy(valloader, Net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5860849056603774\n",
      "0.375\n",
      "0.3958333333333333\n"
     ]
    }
   ],
   "source": [
    "# Loading autoencoder saved model\n",
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder_classifier3.pt'), strict = False)\n",
    "print(_get_accuracy(trainloader, Net))\n",
    "print(_get_accuracy(testloader, Net))\n",
    "print(_get_accuracy(valloader, Net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying that encoder and decoder weights remained frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.2462, -0.3214, -0.1736, -0.7853, -0.6094]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0662, -0.2246, -0.5446, -0.4810,  0.0476]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1591, -0.6918, -0.3941, -0.3774,  0.1053]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0923, -0.2416, -0.0143,  0.0131, -0.5077]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.0565, -0.3281,  0.3196,  0.4665,  0.3597]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.1202, -0.0430, -0.6723, -0.3769, -0.3517]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.0884,  0.0816, -0.5897, -0.3055, -0.2410]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.1872, -0.1554,  0.3229,  0.4877,  0.3021]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.1684,  0.3523,  0.0530,  0.5104, -0.1104]]])\n",
      "Parameter containing:\n",
      "tensor([[[ 0.1143, -0.1964, -0.4806, -0.6028, -0.4836]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.2961,  0.3455, -0.1918,  0.5298,  0.3771]]])\n",
      "Parameter containing:\n",
      "tensor([[[-0.3689, -0.4148, -0.3165, -0.1430, -0.2685]]])\n"
     ]
    }
   ],
   "source": [
    "print(Net.encoder0[0].weight)\n",
    "print(Net.encoder0[2].weight)\n",
    "print(Net.decoder0[0].weight)\n",
    "print(Net.decoder0[2].weight)\n",
    "print(Net.encoder1[0].weight)\n",
    "print(Net.encoder1[2].weight)\n",
    "print(Net.decoder1[0].weight)\n",
    "print(Net.decoder1[2].weight)\n",
    "print(Net.encoder2[0].weight)\n",
    "print(Net.encoder2[2].weight)\n",
    "print(Net.decoder2[0].weight)\n",
    "print(Net.decoder2[2].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
