{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of this notebook is to balance the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import normalize\n",
    "sys.path.append('../code')\n",
    "import helper_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading 3 axis data from all sets\n",
    "x_test, y_test = helper_functions.return_segments_3axis('../data/test.csv', one_hot_encoded = False)\n",
    "x_train, y_train = helper_functions.return_segments_3axis('../data/train.csv', one_hot_encoded = False)\n",
    "x_val, y_val = helper_functions.return_segments_3axis('../data/val.csv', one_hot_encoded = False)\n",
    "\n",
    "# Extracting features\n",
    "x_train_features = helper_functions.return_features(x_train, axes = 3)\n",
    "x_val_features = helper_functions.return_features(x_val, axes = 3)\n",
    "x_test_features = helper_functions.return_features(x_test, axes = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing examples from class 3 since it has maximum number of examples. This technique is known as undersampling and is used to balance datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = list()\n",
    "new_labels = list()\n",
    "for features, label in zip(x_train_features, y_train) : \n",
    "    if (label == 3) :\n",
    "        if np.random.random() > 0.5 : \n",
    "            new_features.append(features)\n",
    "            new_labels.append(label)\n",
    "    else : \n",
    "        new_features.append(features)\n",
    "        new_labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(672, 24)\n",
      "(672,)\n"
     ]
    }
   ],
   "source": [
    "final_features = np.vstack(new_features)\n",
    "print(final_features.shape)\n",
    "final_labels = np.vstack(new_labels)\n",
    "final_labels = final_labels.ravel()\n",
    "print(final_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = normalize(final_features)\n",
    "x_test_norm = normalize(x_test_features)\n",
    "x_val_norm = normalize(x_val_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  3  3  3  3]\n",
      " [ 2  7  4  4  2]\n",
      " [ 8  3  7  1  4]\n",
      " [ 9  4  8 10  2]\n",
      " [ 3  4  3  3  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.20      0.15        15\n",
      "           1       0.33      0.37      0.35        19\n",
      "           2       0.28      0.30      0.29        23\n",
      "           3       0.48      0.30      0.37        33\n",
      "           4       0.31      0.28      0.29        18\n",
      "\n",
      "    accuracy                           0.30       108\n",
      "   macro avg       0.30      0.29      0.29       108\n",
      "weighted avg       0.33      0.30      0.31       108\n",
      "\n",
      "[[ 2  4  4  4  1]\n",
      " [ 1  1  5  3  3]\n",
      " [ 5  2  8  2  2]\n",
      " [11  7  4  5  8]\n",
      " [ 2  6  9  2  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.13      0.11        15\n",
      "           1       0.05      0.08      0.06        13\n",
      "           2       0.27      0.42      0.33        19\n",
      "           3       0.31      0.14      0.20        35\n",
      "           4       0.26      0.21      0.23        24\n",
      "\n",
      "    accuracy                           0.20       106\n",
      "   macro avg       0.20      0.20      0.19       106\n",
      "weighted avg       0.23      0.20      0.20       106\n",
      "\n",
      "[[ 98   0   0   1   0]\n",
      " [  0  86   0   0   1]\n",
      " [  6   1 159   3   2]\n",
      " [  2   1   8 145   5]\n",
      " [  1   2   5   1 145]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        99\n",
      "           1       0.96      0.99      0.97        87\n",
      "           2       0.92      0.93      0.93       171\n",
      "           3       0.97      0.90      0.93       161\n",
      "           4       0.95      0.94      0.94       154\n",
      "\n",
      "    accuracy                           0.94       672\n",
      "   macro avg       0.94      0.95      0.95       672\n",
      "weighted avg       0.94      0.94      0.94       672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class_wt = {0 : 3, 1 : 3, 2 : 2, 3 : 1, 4 : 2}\n",
    "svm_lin = SVC(C = 1e4, class_weight = 'balanced', gamma = 'scale')\n",
    "svm_lin.fit(x_train_norm, final_labels)\n",
    "y_pred = svm_lin.predict(x_test_norm)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_val_norm)\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "print(classification_report(y_val, y_pred))\n",
    "y_pred = svm_lin.predict(x_train_norm)\n",
    "print(confusion_matrix(final_labels, y_pred))\n",
    "print(classification_report(final_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
