{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all data into single dataframe\n",
    "If we look at the data closely, we will find that the data is already divided into segments of 3 seconds with overlap of 1.5 seconds. So, there is a separation (empty row) between each segment. This means those separations get deleted if we simply remove all rows where accelerometer data is missing. So, we need to consider the case where both timestamp and accelerometer data are missing (this is the separation and should not be deleted as it will be useful in future).\n",
    "\n",
    "Further, since the sampling rate of accelerometer is not constant, the number of samples in each segment is different. So, this needs to be handled in some way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212755\n",
      "   index      time High_level  linear_acc.x  linear_acc.y  linear_acc.z\n",
      "0      0  0.000000    Dodging         345.0       -2701.0        -466.0\n",
      "1      1  0.000000    Dodging         345.0       -2701.0        -466.0\n",
      "2      2  0.021687    Dodging         442.0       -2287.0        -965.0\n",
      "3      3  0.040944    Dodging         676.0       -1968.0       -1323.0\n",
      "4      4  0.061339    Dodging        1406.0       -1561.0       -1228.0\n"
     ]
    }
   ],
   "source": [
    "all_data_list = list()\n",
    "for file in os.listdir('../data/annotated_csv/'):\n",
    "    # check whether file to be loaded is csv \n",
    "    # and also ensure no other files are attempted to be parsed.\n",
    "    if file[-4 : ] == '.csv':\n",
    "        df = pd.read_csv(os.path.join('../data/annotated_csv/', file), names = ['time','Control','High_level','Expectation','Activity','linear_acc.x','linear_acc.y','linear_acc.z','gyro.z','gyro.x','gyro.y','ci','distance','proximity'], skiprows = [0])\n",
    "        all_data_list.append(df)\n",
    "        \n",
    "# Combine all the dataframes\n",
    "all_data_df = pd.concat(all_data_list)\n",
    "# Drop unnecessary data\n",
    "all_data_df.drop(['ci', 'distance', 'Control', 'Expectation', 'Activity', 'proximity', 'gyro.x', 'gyro.y', 'gyro.z'], axis = 1, inplace = True)\n",
    "print(len(all_data_df)) \n",
    "\n",
    "# Due to combination of multiple dataframes, the indices remained the same from the original dataframe\n",
    "# even in the full all_data_df dataframe. So, the indices needed to be reset. Upon resetting the indices\n",
    "# get converted into a column called 'index', so it needs to removed as it is unnecessary. \n",
    "all_data_df.reset_index(inplace = True)\n",
    "print(all_data_df.head())\n",
    "all_data_df.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# Indices are again reset so we can have a column of the correct indices which are required to \n",
    "# eliminate the unnecessary rows (which contained CI and proximity data only and no accelerometer data)\n",
    "all_data_df.reset_index(inplace = True)\n",
    "all_data_df.to_csv('../data/cleaned2.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard rows that don't have accelerometer data (but not rows which indicate change of segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of indices where timestamp is not NaN but accelerometer data is NaN \n",
    "# i.e. indices which don't have any accelerometer data\n",
    "drop_indices = list()\n",
    "for t, x, ind in zip(all_data_df.iloc[:, 1], all_data_df.iloc[:, 3], all_data_df.iloc[:, 0]):\n",
    "    if (pd.isna(x) and (not pd.isna(t))):\n",
    "        drop_indices.append(ind)\n",
    "        \n",
    "# Then, drop those indices and drop the 'index' column created earlier since it is not needed now.\n",
    "all_data_df.drop(all_data_df.index[drop_indices], inplace = True)\n",
    "all_data_df.drop('index', axis = 1, inplace = True)\n",
    "# saving to file for further use\n",
    "all_data_df.to_csv('../data/cleaned3.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
