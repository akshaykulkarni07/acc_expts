{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all data into a single dataframe\n",
    "If we look at the newly annotated data, the data is continuously annotated (not in segments as done previously). So, if we need to take examples of (say) 1 second each, we need to ensure that at any particular instant of time, there exists 1 seconds' worth of data after that particular time instant. If the data is not long enough, then it should be discarded.\n",
    "\n",
    "Since the sampling frequency is not constant at 50 Hz, there will be less or more number of samples than expected. This can be handled later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26473\n",
      "   index      time High_level  linear_acc.x  linear_acc.y  linear_acc.z\n",
      "0      0  0.000000   Inactive         382.0        -382.0        1972.0\n",
      "1      1  0.000000   Inactive         382.0        -382.0        1972.0\n",
      "2      2  0.020986   Inactive         420.0        -213.0        2028.0\n",
      "3      3  0.041613   Inactive         416.0        -119.0        2060.0\n",
      "4      4  0.061474   Inactive         333.0        -127.0        2081.0\n"
     ]
    }
   ],
   "source": [
    "all_data_list = list()\n",
    "for file in os.listdir('../data/new_annotated_data/'):\n",
    "    # check whether file to be loaded is csv \n",
    "    # and also ensure no other files are attempted to be parsed.\n",
    "    if file[-4 : ] == '.csv':\n",
    "        df = pd.read_csv(os.path.join('../data/new_annotated_data/', file), names = ['time','Control','High_level','Expectation','Activity','linear_acc.x','linear_acc.y','linear_acc.z','gyro.z','gyro.x','gyro.y','ci','distance','proximity'], skiprows = [0])\n",
    "        all_data_list.append(df)\n",
    "        \n",
    "# Combine all the dataframes\n",
    "all_data_df = pd.concat(all_data_list)\n",
    "# Drop unnecessary data\n",
    "all_data_df.drop(['ci', 'distance', 'Control', 'Expectation', 'Activity', 'proximity', 'gyro.x', 'gyro.y', 'gyro.z'], axis = 1, inplace = True)\n",
    "print(len(all_data_df)) \n",
    "\n",
    "# Due to combination of multiple dataframes, the indices remained the same from the original dataframe\n",
    "# even in the full all_data_df dataframe. So, the indices needed to be reset. Upon resetting the indices\n",
    "# get converted into a column called 'index', so it needs to removed as it is unnecessary. \n",
    "all_data_df.reset_index(inplace = True)\n",
    "print(all_data_df.head())\n",
    "all_data_df.drop('index', axis = 1, inplace = True)\n",
    "\n",
    "# Indices are again reset so we can have a column of the correct indices which are required to \n",
    "# eliminate the unnecessary rows (which contained CI and proximity data only and no accelerometer data)\n",
    "all_data_df.reset_index(inplace = True)\n",
    "all_data_df.to_csv('../data/cleaned_new.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows that don't have accelerometer data\n",
    "Some rows don't have accelerometer data since at those timestamps, other sensors' (Kinect) data was received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of indices where timestamp is not NaN but accelerometer data is NaN \n",
    "# i.e. indices which don't have any accelerometer data\n",
    "drop_indices = list()\n",
    "for t, x, ind in zip(all_data_df.iloc[:, 1], all_data_df.iloc[:, 3], all_data_df.iloc[:, 0]):\n",
    "    if pd.isna(x):\n",
    "        drop_indices.append(ind)\n",
    "        \n",
    "# Then, drop those indices and drop the 'index' column created earlier since it is not needed now.\n",
    "all_data_df.drop(all_data_df.index[drop_indices], inplace = True)\n",
    "all_data_df.drop('index', axis = 1, inplace = True)\n",
    "# saving to file for further use\n",
    "all_data_df.to_csv('../data/cleaned_new2.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unnecessary columns and normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/cleaned_new2.csv', names = ['time', 'High_level', 'linear_acc.x', 'linear_acc.y', 'linear_acc.z'], header = 0)\n",
    "\n",
    "# We won't drop the timestamps as they are still required to separate the examples later\n",
    "# df.drop(['time'], axis = 1, inplace = True)\n",
    "\n",
    "# normalizing acceleration data using factor of 16384 mentioned in datasheet of MPU6050\n",
    "# to get the acceleration in multiples of 'g' (9.8 m/s^2)\n",
    "df['linear_acc.x'] = df['linear_acc.x'] / 16384.0\n",
    "df['linear_acc.y'] = df['linear_acc.y'] / 16384.0\n",
    "df['linear_acc.z'] = df['linear_acc.z'] / 16384.0\n",
    "# print(df.head())\n",
    "df.to_csv('../data/new_data.csv', index = None, header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important : Read this before executing next cell !\n",
    "#### Delete the files which are already generated before running the scripts to generate them again. This is because the code appends to the file so if you re-run the scripts without deleting the earlier data, it will append to the earlier data.\n",
    "\n",
    "This saved data `new_data.csv` will be passed through `preprocess.py` (in `../code/`) (TODO) to get `new_padded_data.csv` for further processing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
