{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook contains code for testing `tsfresh` feature extraction and SMOTE on running standard deviation of raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import extract_relevant_features\n",
    "import sklearn\n",
    "import sklearn.naive_bayes\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_only_tsfresh_compatible.csv', names = ['x_acc', 'y_acc', 'z_acc', 'id'])\n",
    "labels = pd.read_csv('../data/labels_only.csv', names = ['Blocking', 'Dodging', 'Inactive', 'Moving', 'Sprinting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138840,)\n"
     ]
    }
   ],
   "source": [
    "x_acc = np.asarray(data['x_acc'])\n",
    "y_acc = np.asarray(data['y_acc'])\n",
    "z_acc = np.asarray(data['z_acc'])\n",
    "\n",
    "def running_std_dev(x, window_size = 50) : \n",
    "    num_examples = len(x) // 150\n",
    "    out = np.zeros((len(x) - (num_examples * window_size)))\n",
    "    for i in range(num_examples) :\n",
    "        for j in range(150 - window_size) : \n",
    "            out[(i * (150 - window_size)) + j] = np.std(x[(i * 150) + j : (i * 150) + j + window_size])\n",
    "            \n",
    "    return out\n",
    "\n",
    "outp = running_std_dev(x_acc, window_size = 20)\n",
    "print(outp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 20\n",
    "x_acc_std = running_std_dev(x_acc, window_size = window_size)\n",
    "y_acc_std = running_std_dev(y_acc, window_size = window_size)\n",
    "z_acc_std = running_std_dev(z_acc, window_size = window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138840\n"
     ]
    }
   ],
   "source": [
    "# Generating `id` column needed in dataframe for tsfresh\n",
    "idx = list()\n",
    "k = 0\n",
    "for i in range(len(data) // 150) : \n",
    "    for j in range(150 - window_size) : \n",
    "        idx.append(k)\n",
    "    k = k + 1\n",
    "    \n",
    "print(len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     x_acc     y_acc     z_acc\n",
      "0   0  0.005440  0.004272  0.009425\n",
      "1   0  0.005813  0.002630  0.011778\n",
      "2   0  0.005805  0.002815  0.011892\n",
      "3   0  0.005278  0.003170  0.011793\n",
      "4   0  0.004613  0.003832  0.012200\n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe of standard deviation data for later feature extraction using tsfresh\n",
    "# and also saving to memory for quick future use\n",
    "data_std = pd.DataFrame()\n",
    "data_std['id'] = idx\n",
    "data_std['x_acc'] = x_acc_std\n",
    "data_std['y_acc'] = y_acc_std\n",
    "data_std['z_acc'] = z_acc_std\n",
    "print(data_std.head())\n",
    "data_std.to_csv('../data/std_dev_data_only.csv', header = None, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id     x_acc     y_acc     z_acc\n",
      "138835  1067  0.107691  0.087052  0.049347\n",
      "138836  1067  0.109661  0.100508  0.052019\n",
      "138837  1067  0.107994  0.130055  0.063816\n",
      "138838  1067  0.107784  0.160016  0.082226\n",
      "138839  1067  0.108898  0.162559  0.082415\n"
     ]
    }
   ],
   "source": [
    "# Loading standard deviation data from memory\n",
    "data_std = pd.read_csv('../data/std_dev_data_only.csv', names = ['id', 'x_acc', 'y_acc', 'z_acc'])\n",
    "print(data_std.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting labels into correct format (since size of each example has decreased after finding running standard deviation)\n",
    "label_arr = labels.values\n",
    "label_arr = np.argmax(label_arr, axis = 1)\n",
    "\n",
    "y_features = np.zeros(len(data_std) // (150 - window_size))\n",
    "for i in range(len(label_arr)) : \n",
    "    if i % 150 == 0 : \n",
    "        y_features[i // 150] = label_arr[i]\n",
    "        \n",
    "# Also converting into Pandas Series for use in extracting relevant features using tsfresh\n",
    "y = pd.Series(y_features, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [05:55<00:00, 32.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068, 2382)\n"
     ]
    }
   ],
   "source": [
    "# Now using tsfresh to extract features\n",
    "extracted_features = extract_features(data_std, column_id = \"id\", column_sort = None, column_kind = None, column_value = None)\n",
    "print(extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features, y)\n",
    "print(features_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068, 1048)\n"
     ]
    }
   ],
   "source": [
    "print(features_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068, 2382)\n",
      "(1068, 1048)\n",
      "Counter({3.0: 411, 2.0: 213, 4.0: 196, 0.0: 129, 1.0: 119})\n"
     ]
    }
   ],
   "source": [
    "# Convert feature dataframes into numpy arrays (required for training in sklearn)\n",
    "x_features = np.asarray(extracted_features)\n",
    "print(x_features.shape)\n",
    "x_features_relevant = np.asarray(features_filtered)\n",
    "print(x_features_relevant.shape)\n",
    "# Gives the number of examples per label\n",
    "print(Counter(y_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and split into train/test datasets and normalize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 1048)\n",
      "(267, 1048)\n",
      "(801,)\n",
      "(267,)\n",
      "Counter({3.0: 313, 2.0: 157, 4.0: 144, 0.0: 95, 1.0: 92})\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_f, y_test = train_test_split(x_features_relevant, y_features)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_f.shape)\n",
    "print(y_test.shape)\n",
    "x_f = normalize(x_train)\n",
    "x_test_norm = normalize(x_test)\n",
    "print(Counter(y_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({3.0: 313, 2.0: 313, 4.0: 313, 0.0: 313, 1.0: 313})\n",
      "float64\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state = 33)\n",
    "x_train_norm, y_train = sm.fit_resample(x_f, y_f)\n",
    "print(Counter(y_train))\n",
    "print(y_train.dtype)\n",
    "y_train = y_train.astype(int)\n",
    "print(y_train.dtype)\n",
    "y_test = y_test.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  1  8 13  7]\n",
      " [ 0  3  4  9 11]\n",
      " [ 4  1 28 15  8]\n",
      " [11 11 20 36 20]\n",
      " [ 4  5  5 10 28]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.15      0.17        34\n",
      "           1       0.14      0.11      0.12        27\n",
      "           2       0.43      0.50      0.46        56\n",
      "           3       0.43      0.37      0.40        98\n",
      "           4       0.38      0.54      0.44        52\n",
      "\n",
      "    accuracy                           0.37       267\n",
      "   macro avg       0.32      0.33      0.32       267\n",
      "weighted avg       0.36      0.37      0.36       267\n",
      "\n",
      "[[312   0   1   0   0]\n",
      " [  0 313   0   0   0]\n",
      " [  0   0 309   2   2]\n",
      " [  0   1   0 312   0]\n",
      " [  0   0   1   1 311]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       313\n",
      "           1       1.00      1.00      1.00       313\n",
      "           2       0.99      0.99      0.99       313\n",
      "           3       0.99      1.00      0.99       313\n",
      "           4       0.99      0.99      0.99       313\n",
      "\n",
      "    accuracy                           0.99      1565\n",
      "   macro avg       0.99      0.99      0.99      1565\n",
      "weighted avg       0.99      0.99      0.99      1565\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_lin = RandomForestClassifier(n_estimators = 300)\n",
    "svm_lin.fit(x_train_norm, y_train)\n",
    "y_pred = svm_lin.predict(x_test_norm)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_train_norm)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
