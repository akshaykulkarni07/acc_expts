{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import gradcheck\n",
    "from IPython.display import clear_output\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class (loads data from csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42600, 7)\n",
      "(5300, 7)\n",
      "(5400, 7)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 100\n",
    "channels = 3\n",
    "classes = 4\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('../data/new_train.csv', header = None)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('../data/new_test.csv', header = None)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('../data/new_val.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 3 : ].values\n",
    "        ind = np.argmax(np.sum(y, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + reqd_len, : channels].values\n",
    "        x = x.astype('float')\n",
    "        x = x.reshape(reqd_len, channels)\n",
    "        assert(x.shape == (reqd_len, channels))\n",
    "        assert(label.shape == (classes, ))\n",
    "        return x, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader definitions (provides data in iterable form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "batch_size = 16\n",
    "train_indices = [(i * reqd_len) for i in range(len(trainset) // reqd_len)]\n",
    "val_indices = [(i * reqd_len) for i in range(len(valset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(testset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)\n",
    "\n",
    "# signal, label = next(iter(trainloader))\n",
    "# print(signal.shape)\n",
    "# print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def output_size(n, f, p = 0, s = 1):\n",
    "    ''' Returns output size for given input size (n), filter size (f), padding (p) and stride (s)\n",
    "    for a convolutional layer\n",
    "    '''\n",
    "    return (((n + 2 * p - f) / s) + 1)\n",
    "\n",
    "output_size(50, 5)\n",
    "output_size(46, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sig, lab = next(iter(trainloader))\n",
    "# sig2 = sig\n",
    "# sig = torch.transpose(sig, 1, 2)\n",
    "# sig = sig.reshape(-1, 150)\n",
    "# sig_ = sig.numpy()\n",
    "# sig2_ = sig2.numpy()\n",
    "# plt.plot(sig_[0])\n",
    "# plt.plot(sig2_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 10, 3)\n",
    "        self.pamap = nn.Linear(96 * 10, 12)\n",
    "        self.robogame = nn.Linear(96 * 10, 4)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.pamap.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        nn.init.xavier_uniform_(self.robogame.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    # use flag = True during fine-tuning \n",
    "    def forward(self, signal, flag = False):\n",
    "        signal = torch.transpose(signal, 1, 2)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(-1, 96 * 10)\n",
    "        if flag : \n",
    "            out = self.robogame(out)\n",
    "        else :\n",
    "            out = self.pamap(out)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet().double()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()\n",
    "    \n",
    "Net.load_state_dict(torch.load('../saved_models/model1.pt', map_location = 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, Net.parameters()), lr = 1e-3)\n",
    "# optimizer = optim.SGD(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  26  loss =  1.7622559208354196\n",
      "epoch =  0  step =  20  of total steps  26  loss =  1.0367664862606591\n",
      "epoch :  0  /  100  | TL :  1.2731594874959127  | VL :  1.195170766042133\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  26  loss =  1.29076095157899\n",
      "epoch =  1  step =  20  of total steps  26  loss =  1.0168135179813713\n",
      "epoch :  1  /  100  | TL :  1.1772253809280724  | VL :  1.255578331114603\n",
      "epoch =  2  step =  0  of total steps  26  loss =  1.3415427704323901\n",
      "epoch =  2  step =  20  of total steps  26  loss =  1.0901038278910924\n",
      "epoch :  2  /  100  | TL :  1.1723101846515123  | VL :  1.2826049259106966\n",
      "epoch =  3  step =  0  of total steps  26  loss =  1.0501120580365126\n",
      "epoch =  3  step =  20  of total steps  26  loss =  1.3180113567934237\n",
      "epoch :  3  /  100  | TL :  1.145516304006691  | VL :  1.171600647634758\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  26  loss =  1.05290743654575\n",
      "epoch =  4  step =  20  of total steps  26  loss =  1.302955947583476\n",
      "epoch :  4  /  100  | TL :  1.116892392990671  | VL :  1.1739121505144616\n",
      "epoch =  5  step =  0  of total steps  26  loss =  0.9542458145478852\n",
      "epoch =  5  step =  20  of total steps  26  loss =  1.1862313692494406\n",
      "epoch :  5  /  100  | TL :  1.084638272694726  | VL :  1.1974230510204162\n",
      "epoch =  6  step =  0  of total steps  26  loss =  1.0477505514780907\n",
      "epoch =  6  step =  20  of total steps  26  loss =  1.2033600545838674\n",
      "epoch :  6  /  100  | TL :  1.0767754117405564  | VL :  1.1493090079020511\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  26  loss =  0.9581267591289807\n",
      "epoch =  7  step =  20  of total steps  26  loss =  1.3553337614675143\n",
      "epoch :  7  /  100  | TL :  1.0899319776057808  | VL :  1.2004961979560917\n",
      "epoch =  8  step =  0  of total steps  26  loss =  1.0579092765912033\n",
      "epoch =  8  step =  20  of total steps  26  loss =  1.0354191805774509\n",
      "epoch :  8  /  100  | TL :  1.0441030107375515  | VL :  1.1606072995906243\n",
      "epoch =  9  step =  0  of total steps  26  loss =  1.0066193437039108\n",
      "epoch =  9  step =  20  of total steps  26  loss =  0.9346440442562667\n",
      "epoch :  9  /  100  | TL :  1.039054145373626  | VL :  1.1337442115822804\n",
      "saving model\n",
      "epoch =  10  step =  0  of total steps  26  loss =  1.2200235494503797\n",
      "epoch =  10  step =  20  of total steps  26  loss =  0.9078754150269088\n",
      "epoch :  10  /  100  | TL :  1.004620591860696  | VL :  1.1987302319149393\n",
      "epoch =  11  step =  0  of total steps  26  loss =  0.9545270999180085\n",
      "epoch =  11  step =  20  of total steps  26  loss =  1.0813358873635377\n",
      "epoch :  11  /  100  | TL :  0.9954076884038903  | VL :  1.137001373712172\n",
      "epoch =  12  step =  0  of total steps  26  loss =  1.0363940622902972\n",
      "epoch =  12  step =  20  of total steps  26  loss =  1.0649818895856398\n",
      "epoch :  12  /  100  | TL :  0.9833908424802021  | VL :  1.1082625143083031\n",
      "saving model\n",
      "epoch =  13  step =  0  of total steps  26  loss =  1.0309748851517624\n",
      "epoch =  13  step =  20  of total steps  26  loss =  0.9218128672948028\n",
      "epoch :  13  /  100  | TL :  0.9809790342175665  | VL :  1.2049998574795855\n",
      "epoch =  14  step =  0  of total steps  26  loss =  0.9407080933128065\n",
      "epoch =  14  step =  20  of total steps  26  loss =  0.896408719368148\n",
      "epoch :  14  /  100  | TL :  0.9822123356488652  | VL :  1.1469358381417016\n",
      "epoch =  15  step =  0  of total steps  26  loss =  0.7412532597091327\n",
      "epoch =  15  step =  20  of total steps  26  loss =  1.0133297886265487\n",
      "epoch :  15  /  100  | TL :  0.9796099512570338  | VL :  1.2199732356880382\n",
      "epoch =  16  step =  0  of total steps  26  loss =  0.7387893674661054\n",
      "epoch =  16  step =  20  of total steps  26  loss =  0.8332607156562718\n",
      "epoch :  16  /  100  | TL :  0.9485210650754834  | VL :  1.1848296782146133\n",
      "epoch =  17  step =  0  of total steps  26  loss =  0.8493494924490829\n",
      "epoch =  17  step =  20  of total steps  26  loss =  1.0388247746527919\n",
      "epoch :  17  /  100  | TL :  0.969329072195288  | VL :  1.1367451837925386\n",
      "epoch =  18  step =  0  of total steps  26  loss =  0.7984390432716807\n",
      "epoch =  18  step =  20  of total steps  26  loss =  0.8030198702854282\n",
      "epoch :  18  /  100  | TL :  0.9374457654473835  | VL :  1.23342406668378\n",
      "epoch =  19  step =  0  of total steps  26  loss =  1.1109538937756944\n",
      "epoch =  19  step =  20  of total steps  26  loss =  0.8368298417343394\n",
      "epoch :  19  /  100  | TL :  0.9351458157425211  | VL :  1.1837168003287883\n",
      "epoch =  20  step =  0  of total steps  26  loss =  1.0000348550611509\n",
      "epoch =  20  step =  20  of total steps  26  loss =  1.2928220385984615\n",
      "epoch :  20  /  100  | TL :  0.9479153274506739  | VL :  1.2046410443365427\n",
      "epoch =  21  step =  0  of total steps  26  loss =  0.7591319877255847\n",
      "epoch =  21  step =  20  of total steps  26  loss =  0.991158478374443\n",
      "epoch :  21  /  100  | TL :  0.918295546524327  | VL :  1.1717608518783518\n",
      "epoch =  22  step =  0  of total steps  26  loss =  1.1883147707310946\n",
      "epoch =  22  step =  20  of total steps  26  loss =  0.804586839752752\n",
      "epoch :  22  /  100  | TL :  0.9317324685397913  | VL :  1.132059347765946\n",
      "epoch =  23  step =  0  of total steps  26  loss =  0.8457565040880893\n",
      "epoch =  23  step =  20  of total steps  26  loss =  1.239621565516793\n",
      "epoch :  23  /  100  | TL :  0.916827573471957  | VL :  1.20764066096053\n",
      "epoch =  24  step =  0  of total steps  26  loss =  1.0155886674877352\n",
      "epoch =  24  step =  20  of total steps  26  loss =  0.9288282097080125\n",
      "epoch :  24  /  100  | TL :  0.9128207721501045  | VL :  1.2725776524195416\n",
      "epoch =  25  step =  0  of total steps  26  loss =  1.0850500261736504\n",
      "epoch =  25  step =  20  of total steps  26  loss =  0.9329236198656623\n",
      "epoch :  25  /  100  | TL :  0.9027394437911804  | VL :  1.2233557583947432\n",
      "epoch =  26  step =  0  of total steps  26  loss =  0.8738423773935553\n",
      "epoch =  26  step =  20  of total steps  26  loss =  0.5450847224219982\n",
      "epoch :  26  /  100  | TL :  0.888189278493953  | VL :  1.224432333430603\n",
      "epoch =  27  step =  0  of total steps  26  loss =  0.9305297267379006\n",
      "epoch =  27  step =  20  of total steps  26  loss =  0.978303630687713\n",
      "epoch :  27  /  100  | TL :  0.8838479918470313  | VL :  1.2163393365297201\n",
      "epoch =  28  step =  0  of total steps  26  loss =  1.0075747132129373\n",
      "epoch =  28  step =  20  of total steps  26  loss =  0.7557046448452235\n",
      "epoch :  28  /  100  | TL :  0.8815741711960393  | VL :  1.1895156813105532\n",
      "epoch =  29  step =  0  of total steps  26  loss =  0.7393374291969007\n",
      "epoch =  29  step =  20  of total steps  26  loss =  0.9553346748461844\n",
      "epoch :  29  /  100  | TL :  0.867329192403511  | VL :  1.177848893530687\n",
      "epoch =  30  step =  0  of total steps  26  loss =  0.8064822563243366\n",
      "epoch =  30  step =  20  of total steps  26  loss =  0.7217952140124615\n",
      "epoch :  30  /  100  | TL :  0.8658104386363328  | VL :  1.176876856024379\n",
      "epoch =  31  step =  0  of total steps  26  loss =  0.940736355847803\n",
      "epoch =  31  step =  20  of total steps  26  loss =  0.5876921927630443\n",
      "epoch :  31  /  100  | TL :  0.8632287689418625  | VL :  1.2921562339133161\n",
      "epoch =  32  step =  0  of total steps  26  loss =  0.8747239427542015\n",
      "epoch =  32  step =  20  of total steps  26  loss =  0.8431700332702564\n",
      "epoch :  32  /  100  | TL :  0.8608151410391642  | VL :  1.1959213594353202\n",
      "epoch =  33  step =  0  of total steps  26  loss =  0.7523050101809877\n",
      "epoch =  33  step =  20  of total steps  26  loss =  1.0537574609429154\n",
      "epoch :  33  /  100  | TL :  0.8690951513009305  | VL :  1.3329245099081484\n",
      "epoch =  34  step =  0  of total steps  26  loss =  0.9115555922829814\n",
      "epoch =  34  step =  20  of total steps  26  loss =  0.693000378834582\n",
      "epoch :  34  /  100  | TL :  0.8424394994912837  | VL :  1.249422657439995\n",
      "epoch =  35  step =  0  of total steps  26  loss =  0.5853438765923394\n",
      "epoch =  35  step =  20  of total steps  26  loss =  0.8037523482689013\n",
      "epoch :  35  /  100  | TL :  0.8604491047472258  | VL :  1.2541185096800274\n",
      "epoch =  36  step =  0  of total steps  26  loss =  0.8322789930959648\n",
      "epoch =  36  step =  20  of total steps  26  loss =  0.7693235162982024\n",
      "epoch :  36  /  100  | TL :  0.8419324678023863  | VL :  1.1408963551823985\n",
      "epoch =  37  step =  0  of total steps  26  loss =  0.508689795640086\n",
      "epoch =  37  step =  20  of total steps  26  loss =  0.8190622486803865\n",
      "epoch :  37  /  100  | TL :  0.8387585434905209  | VL :  1.2052326487459177\n",
      "epoch =  38  step =  0  of total steps  26  loss =  0.6206160471622781\n",
      "epoch =  38  step =  20  of total steps  26  loss =  0.881951239255181\n",
      "epoch :  38  /  100  | TL :  0.8373336149736438  | VL :  1.314374776678818\n",
      "epoch =  39  step =  0  of total steps  26  loss =  0.48592979083079446\n",
      "epoch =  39  step =  20  of total steps  26  loss =  0.531406262901736\n",
      "epoch :  39  /  100  | TL :  0.8320853014680534  | VL :  1.2547578123213197\n",
      "epoch =  40  step =  0  of total steps  26  loss =  1.379186019570724\n",
      "epoch =  40  step =  20  of total steps  26  loss =  0.7494015038370995\n",
      "epoch :  40  /  100  | TL :  0.84392808968514  | VL :  1.2622854928315208\n",
      "epoch =  41  step =  0  of total steps  26  loss =  0.5944977356078865\n",
      "epoch =  41  step =  20  of total steps  26  loss =  0.7279588644303213\n",
      "epoch :  41  /  100  | TL :  0.8289570997286103  | VL :  1.2653187140129125\n",
      "epoch =  42  step =  0  of total steps  26  loss =  0.749352690380666\n",
      "epoch =  42  step =  20  of total steps  26  loss =  0.8790190388592956\n",
      "epoch :  42  /  100  | TL :  0.8371392950181421  | VL :  1.3106949656297326\n",
      "epoch =  43  step =  0  of total steps  26  loss =  0.9677151903335462\n",
      "epoch =  43  step =  20  of total steps  26  loss =  0.6576825196748836\n",
      "epoch :  43  /  100  | TL :  0.808903085824869  | VL :  1.2959811236615286\n",
      "epoch =  44  step =  0  of total steps  26  loss =  0.8899819122716099\n",
      "epoch =  44  step =  20  of total steps  26  loss =  0.8958044934209599\n",
      "epoch :  44  /  100  | TL :  0.8176672279445513  | VL :  1.3735605596409493\n",
      "epoch =  45  step =  0  of total steps  26  loss =  0.8184938519009223\n",
      "epoch =  45  step =  20  of total steps  26  loss =  0.7772533887829666\n",
      "epoch :  45  /  100  | TL :  0.8304229612927693  | VL :  1.2477059216502402\n",
      "epoch =  46  step =  0  of total steps  26  loss =  0.8128118320457164\n",
      "epoch =  46  step =  20  of total steps  26  loss =  0.48980562245130066\n",
      "epoch :  46  /  100  | TL :  0.8109458638617321  | VL :  1.2569520074199405\n",
      "epoch =  47  step =  0  of total steps  26  loss =  0.8106843751355668\n",
      "epoch =  47  step =  20  of total steps  26  loss =  0.8743905249138935\n",
      "epoch :  47  /  100  | TL :  0.7971138042337415  | VL :  1.1966783472443039\n",
      "epoch =  48  step =  0  of total steps  26  loss =  0.5193527955557701\n",
      "epoch =  48  step =  20  of total steps  26  loss =  0.6561246524845601\n",
      "epoch :  48  /  100  | TL :  0.8018762467887637  | VL :  1.4112273629379717\n",
      "epoch =  49  step =  0  of total steps  26  loss =  0.8726197167167713\n",
      "epoch =  49  step =  20  of total steps  26  loss =  1.0875874214261898\n",
      "epoch :  49  /  100  | TL :  0.7889232487290063  | VL :  1.332081942025399\n",
      "epoch =  50  step =  0  of total steps  26  loss =  0.5474589821302189\n",
      "epoch =  50  step =  20  of total steps  26  loss =  0.8053861637581685\n",
      "epoch :  50  /  100  | TL :  0.7895134322906562  | VL :  1.299730894943259\n",
      "epoch =  51  step =  0  of total steps  26  loss =  0.643435191261834\n",
      "epoch =  51  step =  20  of total steps  26  loss =  0.8429910396916424\n",
      "epoch :  51  /  100  | TL :  0.7928767365529787  | VL :  1.2987652501089204\n",
      "epoch =  52  step =  0  of total steps  26  loss =  0.6249418690777941\n",
      "epoch =  52  step =  20  of total steps  26  loss =  0.9133108169170812\n",
      "epoch :  52  /  100  | TL :  0.7897100271568898  | VL :  1.3387277845336563\n",
      "epoch =  53  step =  0  of total steps  26  loss =  1.0108775030538562\n",
      "epoch =  53  step =  20  of total steps  26  loss =  0.7436259774638324\n",
      "epoch :  53  /  100  | TL :  0.7726379952819615  | VL :  1.1581676039326112\n",
      "epoch =  54  step =  0  of total steps  26  loss =  0.5209980481849483\n",
      "epoch =  54  step =  20  of total steps  26  loss =  0.983880458878173\n",
      "epoch :  54  /  100  | TL :  0.7656830673107825  | VL :  1.265287283984437\n",
      "epoch =  55  step =  0  of total steps  26  loss =  0.8050996673590584\n",
      "epoch =  55  step =  20  of total steps  26  loss =  0.7459920778016005\n",
      "epoch :  55  /  100  | TL :  0.7680518872789368  | VL :  1.3546198447257993\n",
      "epoch =  56  step =  0  of total steps  26  loss =  0.47825352434188845\n",
      "epoch =  56  step =  20  of total steps  26  loss =  0.8599927226042362\n",
      "epoch :  56  /  100  | TL :  0.7908880372374388  | VL :  1.338711821787389\n",
      "epoch =  57  step =  0  of total steps  26  loss =  0.5151685026201442\n",
      "epoch =  57  step =  20  of total steps  26  loss =  0.4298115693208699\n",
      "epoch :  57  /  100  | TL :  0.7612781694773667  | VL :  1.3966617794882576\n",
      "epoch =  58  step =  0  of total steps  26  loss =  0.6975091393157609\n",
      "epoch =  58  step =  20  of total steps  26  loss =  0.7310186851383688\n",
      "epoch :  58  /  100  | TL :  0.7658223120868827  | VL :  1.2858264046287344\n",
      "epoch =  59  step =  0  of total steps  26  loss =  0.7426820792262152\n",
      "epoch =  59  step =  20  of total steps  26  loss =  1.2681939903428894\n",
      "epoch :  59  /  100  | TL :  0.7489702836432414  | VL :  1.2526286962541733\n",
      "epoch =  60  step =  0  of total steps  26  loss =  0.8910429255711693\n",
      "epoch =  60  step =  20  of total steps  26  loss =  0.8332402297968293\n",
      "epoch :  60  /  100  | TL :  0.7425808789115779  | VL :  1.2982206131480443\n",
      "epoch =  61  step =  0  of total steps  26  loss =  0.8777046911396525\n",
      "epoch =  61  step =  20  of total steps  26  loss =  0.8051567024045433\n",
      "epoch :  61  /  100  | TL :  0.7448147004324923  | VL :  1.285398285393914\n",
      "epoch =  62  step =  0  of total steps  26  loss =  0.7546957551739809\n",
      "epoch =  62  step =  20  of total steps  26  loss =  0.8047566216613039\n",
      "epoch :  62  /  100  | TL :  0.7362413383186521  | VL :  1.3484519980191507\n",
      "epoch =  63  step =  0  of total steps  26  loss =  0.8382858023758131\n",
      "epoch =  63  step =  20  of total steps  26  loss =  0.5755564663785979\n",
      "epoch :  63  /  100  | TL :  0.7491380039441167  | VL :  1.194376827371974\n",
      "epoch =  64  step =  0  of total steps  26  loss =  0.6308524643030112\n",
      "epoch =  64  step =  20  of total steps  26  loss =  0.7786084391245702\n",
      "epoch :  64  /  100  | TL :  0.7319046191267888  | VL :  1.3313223269702454\n",
      "epoch =  65  step =  0  of total steps  26  loss =  0.6068914154471934\n",
      "epoch =  65  step =  20  of total steps  26  loss =  0.46486081379599853\n",
      "epoch :  65  /  100  | TL :  0.7433628247031975  | VL :  1.3721398782823586\n",
      "epoch =  66  step =  0  of total steps  26  loss =  0.5790695323035252\n",
      "epoch =  66  step =  20  of total steps  26  loss =  0.6882011065199415\n",
      "epoch :  66  /  100  | TL :  0.7290746546202432  | VL :  1.4027562497253723\n",
      "epoch =  67  step =  0  of total steps  26  loss =  1.039499986662024\n",
      "epoch =  67  step =  20  of total steps  26  loss =  0.8595818047282429\n",
      "epoch :  67  /  100  | TL :  0.7225312993255849  | VL :  1.3140468015206421\n",
      "epoch =  68  step =  0  of total steps  26  loss =  0.5397091203616637\n",
      "epoch =  68  step =  20  of total steps  26  loss =  0.5502178220431888\n",
      "epoch :  68  /  100  | TL :  0.6972709489220038  | VL :  1.2945102556447565\n",
      "epoch =  69  step =  0  of total steps  26  loss =  0.576502763569177\n",
      "epoch =  69  step =  20  of total steps  26  loss =  0.654103795315639\n",
      "epoch :  69  /  100  | TL :  0.7062332507744116  | VL :  1.3321587997481836\n",
      "epoch =  70  step =  0  of total steps  26  loss =  0.4189601406170582\n",
      "epoch =  70  step =  20  of total steps  26  loss =  0.48980258751958616\n",
      "epoch :  70  /  100  | TL :  0.7276128257684052  | VL :  1.2605604256255583\n",
      "epoch =  71  step =  0  of total steps  26  loss =  0.6187651973982976\n",
      "epoch =  71  step =  20  of total steps  26  loss =  0.7140667892395032\n",
      "epoch :  71  /  100  | TL :  0.7120739600679709  | VL :  1.4437601279324195\n",
      "epoch =  72  step =  0  of total steps  26  loss =  0.7066190894642236\n",
      "epoch =  72  step =  20  of total steps  26  loss =  0.8395618914581159\n",
      "epoch :  72  /  100  | TL :  0.7105362782068492  | VL :  1.4183904774134561\n",
      "epoch =  73  step =  0  of total steps  26  loss =  0.5241846226591901\n",
      "epoch =  73  step =  20  of total steps  26  loss =  0.776491117786845\n",
      "epoch :  73  /  100  | TL :  0.7050642534519199  | VL :  1.4104700902016025\n",
      "epoch =  74  step =  0  of total steps  26  loss =  0.5761639885082882\n",
      "epoch =  74  step =  20  of total steps  26  loss =  0.627106437859355\n",
      "epoch :  74  /  100  | TL :  0.7133752946856019  | VL :  1.4299127613909477\n",
      "epoch =  75  step =  0  of total steps  26  loss =  0.6829868527166079\n",
      "epoch =  75  step =  20  of total steps  26  loss =  0.6216662721712795\n",
      "epoch :  75  /  100  | TL :  0.7034042760689183  | VL :  1.2462740288186558\n",
      "epoch =  76  step =  0  of total steps  26  loss =  0.6858966990752791\n",
      "epoch =  76  step =  20  of total steps  26  loss =  0.5364799221161478\n",
      "epoch :  76  /  100  | TL :  0.7027195556825446  | VL :  1.3589817856867585\n",
      "epoch =  77  step =  0  of total steps  26  loss =  0.7524380752117388\n",
      "epoch =  77  step =  20  of total steps  26  loss =  0.6045113832424514\n",
      "epoch :  77  /  100  | TL :  0.6842056428203183  | VL :  1.4191034760560335\n",
      "epoch =  78  step =  0  of total steps  26  loss =  0.8610333879282251\n",
      "epoch =  78  step =  20  of total steps  26  loss =  0.5878091833259348\n",
      "epoch :  78  /  100  | TL :  0.6933154139161104  | VL :  1.3987061231686575\n",
      "epoch =  79  step =  0  of total steps  26  loss =  0.9217091352250135\n",
      "epoch =  79  step =  20  of total steps  26  loss =  1.0243140963783854\n",
      "epoch :  79  /  100  | TL :  0.6967204878865354  | VL :  1.3490434674623923\n",
      "epoch =  80  step =  0  of total steps  26  loss =  0.6675471499857722\n",
      "epoch =  80  step =  20  of total steps  26  loss =  0.6658741989480579\n",
      "epoch :  80  /  100  | TL :  0.6917812170623309  | VL :  1.4061311773898375\n",
      "epoch =  81  step =  0  of total steps  26  loss =  0.7905829198626957\n",
      "epoch =  81  step =  20  of total steps  26  loss =  0.528053175322612\n",
      "epoch :  81  /  100  | TL :  0.6870227219152107  | VL :  1.4595261870089782\n",
      "epoch =  82  step =  0  of total steps  26  loss =  0.8057496586504366\n",
      "epoch =  82  step =  20  of total steps  26  loss =  0.8749097203440795\n",
      "epoch :  82  /  100  | TL :  0.6791861587027692  | VL :  1.395569058183356\n",
      "epoch =  83  step =  0  of total steps  26  loss =  1.196848683757322\n",
      "epoch =  83  step =  20  of total steps  26  loss =  0.7827831470618402\n",
      "epoch :  83  /  100  | TL :  0.6794322635227305  | VL :  1.2993843168893617\n",
      "epoch =  84  step =  0  of total steps  26  loss =  0.6750023008252246\n",
      "epoch =  84  step =  20  of total steps  26  loss =  0.708813332903355\n",
      "epoch :  84  /  100  | TL :  0.7051426210121403  | VL :  1.2989620609895942\n",
      "epoch =  85  step =  0  of total steps  26  loss =  0.6111458364692034\n",
      "epoch =  85  step =  20  of total steps  26  loss =  0.633083811557948\n",
      "epoch :  85  /  100  | TL :  0.6754711355104026  | VL :  1.4997231509878117\n",
      "epoch =  86  step =  0  of total steps  26  loss =  0.5809989511569478\n",
      "epoch =  86  step =  20  of total steps  26  loss =  0.8015392274697284\n",
      "epoch :  86  /  100  | TL :  0.6666662569183692  | VL :  1.5159626646066637\n",
      "epoch =  87  step =  0  of total steps  26  loss =  0.4619574510074991\n",
      "epoch =  87  step =  20  of total steps  26  loss =  0.39429177801885273\n",
      "epoch :  87  /  100  | TL :  0.676863079293844  | VL :  1.3562753681613209\n",
      "epoch =  88  step =  0  of total steps  26  loss =  0.574622786327549\n",
      "epoch =  88  step =  20  of total steps  26  loss =  1.01325159556726\n",
      "epoch :  88  /  100  | TL :  0.6794591465418389  | VL :  1.443530246360645\n",
      "epoch =  89  step =  0  of total steps  26  loss =  0.6591230270176495\n",
      "epoch =  89  step =  20  of total steps  26  loss =  0.8554545001862783\n",
      "epoch :  89  /  100  | TL :  0.6566055465139229  | VL :  1.35268249827588\n",
      "epoch =  90  step =  0  of total steps  26  loss =  0.5520097356606816\n",
      "epoch =  90  step =  20  of total steps  26  loss =  0.7437907424348433\n",
      "epoch :  90  /  100  | TL :  0.6664992309941622  | VL :  1.4151083281822814\n",
      "epoch =  91  step =  0  of total steps  26  loss =  0.7209212304266521\n",
      "epoch =  91  step =  20  of total steps  26  loss =  0.6001896680092131\n",
      "epoch :  91  /  100  | TL :  0.6532453049535698  | VL :  1.5331504362932835\n",
      "epoch =  92  step =  0  of total steps  26  loss =  0.8476239187940596\n",
      "epoch =  92  step =  20  of total steps  26  loss =  0.6912875235590654\n",
      "epoch :  92  /  100  | TL :  0.6518954275729302  | VL :  1.4097624539870364\n",
      "epoch =  93  step =  0  of total steps  26  loss =  0.42231572033554565\n",
      "epoch =  93  step =  20  of total steps  26  loss =  0.6664400325751468\n",
      "epoch :  93  /  100  | TL :  0.646680699213078  | VL :  1.34637504764416\n",
      "epoch =  94  step =  0  of total steps  26  loss =  0.48621139820940795\n",
      "epoch =  94  step =  20  of total steps  26  loss =  0.5831358507521183\n",
      "epoch :  94  /  100  | TL :  0.6564094844963914  | VL :  1.4919477929996094\n",
      "epoch =  95  step =  0  of total steps  26  loss =  0.3156241897211972\n",
      "epoch =  95  step =  20  of total steps  26  loss =  0.6446910054979601\n",
      "epoch :  95  /  100  | TL :  0.6427810686603781  | VL :  1.473785190944012\n",
      "epoch =  96  step =  0  of total steps  26  loss =  0.5312189098776429\n",
      "epoch =  96  step =  20  of total steps  26  loss =  0.5963625552824453\n",
      "epoch :  96  /  100  | TL :  0.6348737910910249  | VL :  1.5190543553347318\n",
      "epoch =  97  step =  0  of total steps  26  loss =  0.7720886963087994\n",
      "epoch =  97  step =  20  of total steps  26  loss =  0.8554283793940686\n",
      "epoch :  97  /  100  | TL :  0.6483800661745819  | VL :  1.5492706066166886\n",
      "epoch =  98  step =  0  of total steps  26  loss =  0.6233821935162145\n",
      "epoch =  98  step =  20  of total steps  26  loss =  0.5884987507048269\n",
      "epoch :  98  /  100  | TL :  0.6498897658277374  | VL :  1.4205991506005085\n",
      "epoch =  99  step =  0  of total steps  26  loss =  0.59397586740683\n",
      "epoch =  99  step =  20  of total steps  26  loss =  0.43191641758977034\n",
      "epoch :  99  /  100  | TL :  0.6321971363378341  | VL :  1.4095450107559147\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "total_step = len(trainset) // (train_batch_size * reqd_len)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().double()\n",
    "            images.requires_grad = True\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).double()\n",
    "            images.requires_grad = True\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net.forward(images, flag = True)\n",
    "        \n",
    "        loss = F.cross_entropy(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "#             print('Gradient Check : ', gradcheck(Net, (images, )))\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(testloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().double()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).double()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net.forward(images, flag = True)\n",
    "            loss = F.cross_entropy(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '../saved_models/model2_finetuning.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f97826cc7f0>,\n",
       " <matplotlib.lines.Line2D at 0x7f97826cc940>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(100)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.84615384615384 / 58.333333333333336 / 39.58333333333333\n",
      "60.817307692307686 / 54.166666666666664 / 43.75\n"
     ]
    }
   ],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).double()\n",
    "        labels = Variable(labels).double()\n",
    "        \n",
    "        if torch.cuda.is_available() : \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = Net.forward(images, flag = True)\n",
    "        outputs = F.log_softmax(outputs, dim = 1)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.cpu().numpy()\n",
    "        pred_ind = pred_ind.data.cpu().numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.eval()\n",
    "\n",
    "print(_get_accuracy(trainloader, Net) * 100, '/', _get_accuracy(valloader, Net) * 100, '/', _get_accuracy(testloader, Net) * 100)\n",
    "\n",
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('../saved_models/model2_finetuning.pt'))\n",
    "testing_Net.eval().double()\n",
    "print(_get_accuracy(trainloader, testing_Net) * 100, '/', _get_accuracy(valloader, testing_Net) * 100, '/', _get_accuracy(testloader, testing_Net) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directly training NNs on raw data doesn't work well (network overfits most of the time). So, we can try to use some pre-processing to the data before training (like running mean, running std deviation, running rms, etc.)\n",
    "\n",
    "### PyTorch implementation of `running_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean(signal, window_size = 10):\n",
    "    ''' Returns running mean of 3D signal (batch_size, length, channels)\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].mean(dim = 0)\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = signal[i][j]\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_mean` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f012cd56898>,\n",
       " <matplotlib.lines.Line2D at 0x7f012cd569e8>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO2dd3hUZfbHv4dA6BAgNOklYCIqSqgKIkWqNNEfrGsXbNhAEdl13XUtwArKIhakiK6CKL0oVWogEFRAeiiBQJDQe0lyfn+cGZiEKXdm7pTcOZ/nmWeYO++9971k5jvnnvcUYmYoiqIo1qVAqCegKIqiBBYVekVRFIujQq8oimJxVOgVRVEsjgq9oiiKxSkY6gnkJTY2lmvWrBnqaSiKouQrNm7ceIyZyzt7L+yEvmbNmkhJSQn1NBRFUfIVRJTm6j113SiKolgcFXpFURSLo0KvKIpicVToFUVRLI4KvaIoisVRoVcURbE4KvSKoigWR4VeURQlDPi6/2pMfGJVQI4ddglTiqIokciIryuiYrGzeDIAx1aLXlEUJcSkrUnH1stx6NLyTECOr0KvKIoSYhZ8shcA0PmZ6gE5vgq9oihKiFmwrAhqFTyA+h1rBeT4KvSKoigh5NKpS1h6tAG6xO8DFaCAnMOQ0BNRRyLaSUSpRDTExZiHiGgbEW0lou8ctmcT0e+2xxyzJq4oimIFln/yBy6iGDr3Lhawc3iMuiGiKABjAbQHkA5gAxHNYeZtDmPiALwJ4C5mPklEFRwOcZGZG5o8b0VRFEuw4IfzKIoLaD2gQcDOYcSibwIglZn3MvMVAFMBdM8zph+Ascx8EgCY+ai501QURbEenMOYv60m2lT4A0XLFg3YeYwIfRUABx1ep9u2OVIPQD0iWkNE64ioo8N7RYgoxba9h7MTEFF/25iUzMxMry5AURQlv7J78X7szaqBzvdeDOh5jCRMOVsdYCfHiQPQGkBVAKuIqAEznwJQnZkPE1FtAMuIaAsz78l1MOZxAMYBQGJiYt5jK4qiWJL5n6UBqIXOA+oE9DxGLPp0ANUcXlcFcNjJmNnMfJWZ9wHYCRF+MPNh2/NeAMsB3OHnnBVFUSzBglUlkVA4FTXvrhrQ8xgR+g0A4oioFhFFA+gDIG/0zCwA9wIAEcVCXDl7iagMERV22H4XgG1QFEWJcM4dOYcVJ25F51vTA34uj0LPzFkABgBYCGA7gGnMvJWI3iGibrZhCwEcJ6JtAH4B8DozHwcQDyCFiDbZtg9zjNZRFEWJVJaM3oqriEbnvqUDfi5iDi+XeGJiIqekpIR6GoqiKAGlf/xKTN3REMfPF0WhYoX8Ph4RbWTmRGfvaWasoihKkOEcxoJdcbivylZTRN4TKvSKoihBZvOPu3AopzK63JcVlPOp0CuKogSZBRMyAAAdX6oXlPOp0CuKogSZBevK4M6i21G5YcWgnE+FXlEUJYic2HMSSWcaoEvin0E7pwq9oihKEFk0ejtyEIXOj8YG7Zwq9IqiKEFkwfwcxNIxNH40PmjnVKFXFEUJEjlZOfh5X310qLETUdFRQTuvCr2iKEqQ2DJjNzK5PO5rH9xEVRV6RVGUILHsOwmrvPep2kE9rwq9oihKkFi2thjiCu1DtaY3BfW8KvSKoihBIOtSFlYcvRlt4w56HmwyKvSKoihBIOV/O3AWpdCmQ+Br2+RFhV5RFCUILP3+GADg3meCU/bAERV6RVGUILBsYyncXmQnYuuXC/q5VegVRVECzMUTF7HmZALaJGSE5Pwq9IqiKAFm7aQduIwiaHt/8ZCcX4VeURQlwCybeRpRyELLp+uH5Pwq9IqiKAFm6aZyaFJiO0pVLRWS86vQK0okM2kSsHlzqGdhac6kn8GGc/Foc/vxkM1BhV5RIpX9+4EnnwQaNgSeeAI4GPxEnkhg5bgdyEZBtOlZOmRzUKFXlEjl8GF57tABmDIFqFcPGDIEOHUqtPOyGMvmX0BhXEKLp4JXljgvKvSKEqkcOSLPH3wA7NwJPPggMGIEUKcO8PHHwJUroZ2fRVi6rTLuKrMNRWKKhGwOKvSKEqnYhb5yZaBGDeDrr4FffwUaNQJefRV4++3Qzs8CZG4/hs2X6qNt4pmQzkOFXlEilYwMoEABINahpV3DhsCiRUCTJsD69aGbm0VY/uVuAECbh4LXNtAZKvSKEqkcOQJUqABEOel0VK8ekJoa/DlZjKU/X0VJnEHiX28O6TxU6BUlUjlyBKhUyfl7detKFM7ly8Gdk8VYlloN91TYgYJFCoZ0Hir0ihKpeBJ6ZmDfvuDOyUIcTD6M3VdroU3zC6Geigq9okQs7oS+Th15VveNzywbvxcA0Pavwe0m5QwVekWJRHJygD//dG/RAyr0frB0GRBLx9CgR91QT0WFXlEikpMngatXXQt9uXJA6dIq9D7COYxl++vg3iq7UaBg6GU29DNQFCX4OMbQO4NIrHoVep9IXZqGQzmV0abl1VBPBYBBoSeijkS0k4hSiWiIizEPEdE2ItpKRN85bH+MiHbbHo+ZNXFFUfwgw9YAw5VFD4jQ79kTnPlYjKRp6QCAux908UMaZDzG/BBRFICxANoDSAewgYjmMPM2hzFxAN4EcBcznySiCrbtZQG8DSARAAPYaNv3pPmXoiiKYewWvTuhr1MHmD5dXDyFgt/QOj+zdk0OSuE0Eu6vE+qpADBm0TcBkMrMe5n5CoCpALrnGdMPwFi7gDPzUdv2DgAWM/MJ23uLAXQ0Z+qKoviMEaGvWxfIygIOHAjOnCzE2n0V0bRsalj45wFjQl8FgGP90nTbNkfqAahHRGuIaB0RdfRiXxBRfyJKIaKUzMxM47NXFMU3jhwBihYFSpZ0PUYjb3zi7OGz+ONSXTRvcDbUU7mGEaEnJ9s4z+uCAOIAtAbQF8B4IooxuC+YeRwzJzJzYvny5Q1MSVEUv7DH0JOzr6gNFXqf2DAlFTmIQvP2JUI9lWsYEfp0ANUcXlcFcNjJmNnMfJWZ9wHYCRF+I/sqihJs3CVL2alUCShWTBdkvWTtz6cBAE0fDn38vB0jQr8BQBwR1SKiaAB9AMzJM2YWgHsBgIhiIa6cvQAWAriPiMoQURkA99m2KYoSSo4ccR1aaYdIFmTVoveKtZuLIT56D8rUign1VK7hUeiZOQvAAIhAbwcwjZm3EtE7RNTNNmwhgONEtA3ALwBeZ+bjzHwCwL8hPxYbALxj26YoSijJyPBs0QMaS+8lnMNYl1kHzWuEl+PCUEk1Zl4AYEGebf9w+DcDGGh75N13IoCJ/k1TURTTuHwZOHHCuNDPnw9kZzsvZ6zkYvfi/TjOtdCs2Q1LkSElPGJ/FEUJHkdt0c9Ghf7KFeDQocDOySKs/VH+n5r3DI9EKTsq9IoSaRiJobdjj7zRBVlDhFuilB0VekWJNHwR+gjx0+fkSBl+Xwm3RCk74TUbRVECjzdCX6UKEB0dEULPDLRtCzz0kG/7h2OilJ3Q9rdSFCX42IW+YkXPY6OigNq1I0Lo58wBli+XqNK0NKBGDe/2X//tbuTgzrBKlLKjFr2iRBpHjki9+ehoY+MjIMQyOxsYOhSoXl1ejx/v/THWLjwDILwSpeyo0CtKpGE0ht6OvVyxP87rMOfbb4Ft24CRI4FOnYAJE6Semzes3Vw87BKl7KjQK0qkYaT8gSN16wLnz0vrQQty+TLw9ttAo0bAAw8A/fvLb+H8+caPwTmMdcfCL1HKjgq9okQa3gq9xRuFjxsH7N8PvP+++Oe7dAFuugn44gvjx9i1cB9OcFk0bx6wafqFCr2iRBLMvln0gCWF/tw54N13gdatgfbtZVvBgsBTTwE//yyLskZYO10s+ea9witRyo4KvaJEEmfPAhcveif0NWpI9I0FhX70aEkU/uCD3BWbn35ano0uyq5dk4PSOI34LrXNn6QJqNArSiThqSm4MwoVAmrWtJzQHz8OjBgBdO8ONGuW+73q1b1blF27vxKaltsddolSdsJzVoqiBAZvkqUcsWCj8OHD5Qbn3Xedv290UfZ6otQ58ydpEir0ihJJZGTIs7dCX6cOsHu3ZUIsDx0CxowBHnkEaNDA+Riji7Lrv90NRoGwTJSyo0KvKJGEPxb96dNS3tgC/PvfkiT1r3+5HmN0UfZaotRf40yepXmo0CtKJHHkiPjcy5Txbj8LRd7MmCEhlc8+K0sP7jCyKLt2c3EkFE5FTI3Sps3RbFToFSWSOHJEatwU8PKrbxGhX7EC+MtfZPF12DDP4z0tyl5PlMowf7ImokKvKJGEtzH0dmrVkvjDfLwgu2WLRNjUrg3MnSt9z43wzDPOF2XPHTmHZSN/C+tEKTtavVJRIokjR4Bq1bzfr0gR2S+fWvRpaUDHjkCJEuJzL1fO+L6dOwNVyl/G4MdOYlz0QRw8WxoHL1fAKY4BcCcAoGXfqoGZuEmo0CtKJHHkCNC4sW/71qmTL4X++HGgQwcp17N69fUKlYa4dAkFhw7FG5lX8R79HRlFSqBWzEm0Kp+BalUY1WoXws0tyqJeh/iAzd8MVOgVxSIwix+5UCEXA7KzJQ3UF9cNIH76WbN8nl8ouHAB6NpVatksWuQ6lNIpv/4q8ZfbtuHF55/HiyNKAMUN1PAPQ9RHn1/IyQHWrAG2bweuXg31bJQw5P33pVqBywjIzEz5HPkj9JmZwJkzPs8xmGRmSreo9euBKVOAVq0M7piVBbz3HtC0KXDypPh6xo4FihcP6HwDiQp9fmD7dqm6dPfdQEKCrCIlJEhN1bfekk/xhQuhnqUSQq5ckQSgjAzgnXdcDPI1ht5OPmgUziz20MMPA1WrygLqp58CPXsaPMCWLUDLlsDf/y7frz/+EL9PPkddN+HM5ctSbemDD8SaGDsWKFlShH/bNvkQzpolVlqHDsBPP+WuzKREDLNmSbn4226Tj8lzzwH16+cZZJbQp6YCd9zh81wDwdmz0jzk009Fq0uVkmiZZ58Vm8gl2dnA2rXSR3D2bGDXLiAmBvjuO6Bv36DNP9Co0IcrK1fKJ3XHDgn8/egjoEKFG8ddvgx88gnw2muSq/3ss8GfqxJyPv9ckn9+/lkE/vXXRbty4a/Q17ZVZgyzBdnvvwf69ROxv+MO4MsvRaOLnzoklvmVK6L8jo+iRYGkJGDePPHxFCokd80vvQT07m2sn25+gpnD6tGoUSOOaM6fZ+7XjxlgrlmT+eefPe+Tk8Pcvj1zsWLMu3cHfo5KWLF9u3xc3n9fXg8bJq+XLMkz8IMP5I3z530/WaVKzE8+6fv+JjN9OnNUFHOLFszr1slXgZmZ09OZ4+KYixZlrlOHuXx55sKF5frtj9Klmfv2ZZ46lfnUqZBehxkASGEXuhpyYc/7iHihf+cd+bO8/jrzuXPG9zt4UD64LVowZ2UFbn5K2PHKK8yFCjEfOSKvL14UG+HWW/N8FF5+mblUKf9OdvfdzK1a+XcMk5g/X667eXPmM2cc3rCLfMmSzGvW5N7p0iXmzEzmffuYr1wJ5nQDjjuh18XYcCInB6cn/IhDdz0khbK9WeWvWlVcOElJwIcfBm6OSlhx8SLw1VdAr17XvQ1FisjHZ8sWSd2/hq9ZsY5UrXrdBRRCliyRa771VmDBAlm6AgAcPgzce6+sSv/8M9CiRe4dCxcGYmPFz+UyDtV6qNCHiDNnJCJg1Chxxd9zD1ApNgsxaZtQdc336NMH2LvXy4M+/LBECvzjH8DmzQGZtxJeTJsGnDoli6+O9O4tQVpvveUQDZmR4b/Qly4tJwwhq1YB3boB9epJbHxMjO0NR5FfuPBGkY9gVOiDTHa2LBbVrSuJHIMGAdOnS+hu53LrMKzw2xgy6CrmzAFuvhkYOFAy+wxBBHz2mXzyH3lEFmoVS/PZZ/I5yRsjTiTr90ePSnw9AHMs+piYkAp9crKUJKhRA1i82KGUgV3kDx9WkXeGK59OqB5W9tGvXMl8xx3igr/7blksO3bM9uaZM7KY2q8fMzMfOsT81FPMBQowx8QwjxghvldDzJ4tJ3nzzYBchxIe/Pqr/Jk//tj1mEcfZY6OZt67l8U//9JL/p30/fflpIY/jObx22/yXahdW9zw1/jzT+Z69ZhLlGBevTro8woXoIuxoSUtjblPH/nfrlqVecoUh+gAOxMmyICkpFybN29m7tRJ3qpRg3nLFoMnfeIJ+ZXIczzFOvTvL0ElJ064HpOeLvZD755XOVdojq98+qkcJyPDv+N4yZUrzAkJzFWqMO/fn+fNv/9dQm8iWOSZVehDRk4O84cfypexSBHmt992E9l2993M9es7+QUQliyRyLZ69ZhPnzZw8tOn5ZehQgXmlBQfr0AJV06fZi5eXH7PPfHPf8o3fRNuZZ40yb8Tf/utHGzHDv+O4yWjR8tpZ81y8maDBsytWwd1PuGIO6E35KMnoo5EtJOIUoloiJP3HyeiTCL63fZ42uG9bIfteVM4LAszMHiw5DHdd5/kPf3zny5qYO/eLWX1Hn/cZWZr27bA1KmSq9K/v4HWnaVKSdRB0aKSCLJokX8XpIQV334r1RiN5Mc99xxQoABjOh4wx0cPBNVPn5kJvP020L69LMLmYu9eyRDv3j1o88mXuPoFsD8ARAHYA6A2gGgAmwAk5BnzOIBPXOx/ztM5HB9WsOizs5mff14skBdekNdu+dvfxM1y6JDHY9tzXsaONTiZQ4eYb7+duWBB5q+/NriTEs7k5EiM/J13urwBvIFWCZl8KzaJo9sf1qyRD+DChf4dxwueeUY+vtu2OXlz1CiZz969QZtPuAI/LfomAFKZeS8zXwEwFYD+fLogO1v6TH76qaShjxnjoWtbdjYwebLUqrnpJo/HHzxYutO/+iqQkmJgQjfdJP3TWrUCHn0UGD7cwO2AEs6sXSsx8s8+a7y0Uc/4HdiC25B6sYp/Jy9t64saJIv+t9+kv+uAAUC8s5Lvs2dLMH2tWkGZT37FiNBXAXDQ4XW6bVteHiCizUT0IxE5trApQkQpRLSOiHo4OwER9beNScnMzDQ++zDj6lXgr38FJk2SW83hww18EZcuBdLTxW1jgAIF5HehUiXgwQeliqpHSpeWgmd9+wJDhkg9j+xsQ+dTwo9x48Qz503NrR43rQcAzFzpRWslZwTRdcMsH9XYWPk+3cDx4xJUr24bjxgRemdSldcknAugJjPfBmAJgMkO71Vn5kQAfwHwMRHVueFgzOOYOZGZE8uXL29w6uHF5csivFOnisD/858Gra1Jk4AyZZw4H11Trpwkyhw6JL8Phgz06Gjgf/+TwP1PPgH+7/8krVLJVzBLmHiXLtIWzyg1L+3AnQU3YeZsP1Nn7Bb96dP+HccA338vS1fvv++QFOXI/PlSuVWF3iNG/urpABwt9KoADjsOYObjzGzPzvkSQCOH9w7bnvcCWA4gvOqbmsD58/JZmz1bXDWDBxvc8eRJYOZMqU5ZpIhX52zaVCodzJkDjBxpcKcCBWSnUaOAGTOAdu2AY8e8Oq8SWvbtk7ynli293PHIEfSMXYW1ayVx1GeKFweiogJu0Z8/L4EMd94JPPGEi0GzZwNVqgCNGrkYoNgxIvQbAMQRUS0iigbQB0Cu6BkiquzwshuA7bbtZYiosO3fsQDuArDNjImHC0ePSkLe4sXA+PHiSzTM1KlyK+Dyk+yeF1+UVPchQ6TZgmFefRX44Qdplda8ediVnVVcs3q1PN99t5c7HjmCnnW2APCzGyCRWPUBtuiHDZM71v/+V35XbuDiRYkq695dezAYwKPQM3MWgAEAFkIEfBozbyWid4jI7m94iYi2EtEmAC9BonAAIB5Aim37LwCGMbNlhD41VTKt//hDDPOnnvLyAF99JU0s77zTp/MTSdGqWrXEX+uyhZwzHngAWLZM7iqaNZNiaErYs3q16Owtt3i545EjSKh7BXFx8ln1iwCXQdi3D/jPf+RG9667XAxaulS6qqnbxhiuwnFC9cgv4ZXJyVLiulw55rVrfTjA1q0SFjZypN9zSUmRcq09ehgPt7vGrl3MdetKre4ffvB7LkpgSUiQTGmvyMmRD8iQIfzGGxKq6C6b1iN33snctasfB3DPQw9JMliuMgd5efppKelw+XLA5pHfgJYpNpf588VdU6KEGMLNmvlwkJEjgYIFJUzHTxo1klvdWbOkyJVXxMVJvN6dd0on5VGj/J6PEhiOH5cOkl67bU6ckJCwSpXQs6cU0Js3z4+JBLCC5dmzcsfRv7+4352SkwPMnQt06iRBBopHVOi9ZPx4uVuMjxd9rFfPh4NMnCiPV15x3h7QB155RT73Awf6UKE4NlZuhXv1kqicjRtNmZNiLnbvmi/+eQBApUpo3FhSK/xy3wTQdbNokfwm9XAaiG0jOVka5KrbxjAq9Aa5elXWMPv1k1Ts5ct9bCuZnCw56e3aSdNvkyhQQFz+ZcoAffpI1IJXFC0qAdpRURKRo4Qda9ZIr4zGjb3c0UHoCxQQEf35Z3Fx+0QAF2PnzZPPsNsqw7Nny91wp04BmYMVUaE3gL3U9ccfS6TLnDnexTBfIyNDrOYqVSTipqC5vdkrVJBQ+R07xML3mrJlpQOK36t1SiBYvVrcdEWLernjzp3ybMse7dVLglZ8Ln8UIIs+O1vcop06efhqzJ4t9ZucBtcrzlCh98Dy5dJZ/vffgSlTJNzLpw5kly9LpMupU+JML+dnhqIL2raVcMvx4yXhxGt69gS2b78uDkpYcOkSsGGDD24bQO4iK1YEqkk6TKtWYjX7fOMWEyPOdJOzqzdskAJm99/vZtCuXWLJqNvGK1ToXcAsIV7t2smXIjlZXCI+H2zAAHHqf/UVcNttZk71Bv71L1kg7t9fQtW8wv4Fmj3b9HkpvrNxI3DliptwQ3esXw80aXIt3rxQIRHTuXPFJek19uzYaz0KzWHuXPEcdujgZpD9c+lFJrmiQu+UkyfF+B48WAzc9et9iFt25IsvxMQeOlTqJASYQoXk7oNIvg9eZUJWqyb+Ab+yahSzsSdKeS30p0+LBdy0aa7NvXrJzeWKFT5MJkD1bubNk4zfMmXcDJo1S26xq1c39dxWR4XegawsCU+Mi2PMmZ2DkX02YNpdo1Hqo3+J0/vxxyWLY9Ei4xUgV64Ux37nzsA77wR0/o7UrCm9aPftk9t9rxqN9+gBrFvnZ668YiZr1gD16wNel4LasEGemzTJtfm++6Q3gk/LMQGod5OWJtFiXbu6GfTnn3JXrG4b73EVYB+qR6gSppYskUY1AHOrSjv5VzSUF/ZHyZLM1aszx8baBrViXrXK9QGTkph795Y683FxzCdPBu9iHFi3jrlsWelOtXmzwZ22bJFr/OKLgM5NMUZ2tvwNn3zSh53fe0/+lk4+f716MVeubKBfQl6WLZNj/vKLDxNyziefyCF37nQzaPx4GeRvTX2LAk2Yck1qqhiw7doB584BP763E8uP1Mcdz7cA9uyRLJWrV8UfmZYmJYXHjJFFoZYtJUTAHneelQX8+KPUj2nRAliyRPw/q1aFLEKgaVO5qShQQBbhDFU6uOUWoE4ddd+ECTt2SM6TTwux69fLrYCTz1/PnnLTtn69l8cMgEU/b57k7rnNS/npJ3Et3n67aeeNGFz9AoTqESyL/uRJ5tdfl8zw4sWlZ/LFs1elG1OVKsxnz7o/wPnzzMOHi6kFMHfuzFyzpvy7Th3mMWM8HyOI7NsnlQ6KFmX+6ScDOwwaxBwdbbBBrRJIxo2Tj9WuXV7umJMjt3KPPOL07RMn5LjvvuvlcffskR2/+srLHZ1z9qx81AYOdDMoJ0fuph97zJRzWhGoRX+drCzp/hQXJxV7H35YWra++SZQZMJYYNMmYPRoz4HyxYqJtb53rxSfT06W+PgZMyQ0ccAAH4PtA0PNmrKgV7++RFxMmeJhhx49JMzjp5+CMT3FDatXi2++bl0vd0xPl2SpPP55O2XKiAVtd+Mbxn53YJJFv2SJfNTc+ue3b5eS2q1amXLOSCNihJ4ZWLBAIhtfeEGKRqakSN+PypUhWVFvvSWumF69jB+4dGlpf3PsmHwje/Z0UVc19FSsKHkBLVrImvKgQW7C65o3F3VR903IWb1a3DZeV+O1+2TyRNw40rixD0JfqpQ8mxR1M3eufI3cuqbs4UH33GPKOSONiBD6LVskNrdLF7HoZ8+WCr25qgMPHChmxZgxlq5vXbq0BA298ILUL2vVCjhwwMnAqCiJbpg/X5K9lJCQkSE3jT4nSkVHu83baNxYbJzDh10OuZGCBeVu1QShz8m5ng3rNhFx5Uq5Y65d2+9zRiKWFvqzZ0W/77hDrPfRo6V2fLduebR88WJJIx06VBYhLU7hwtJNcNo0YOtWoGFDF9UMe/SQ/8Tly4M9RcWGvaGMz4lSDRvKH9wF9ro5Xlv1JtW7SUmRqEm3bhvm6w3uLWyEBRJLCj2zBL/Ex0t9mqefluial15yUtX08mUxb+PivOgBaA0efFCaTNWoIX77wYPzuHLatpXWceq+CRmrV0ttmzu8bcCZnS0q6sZtA8jvQFSUj356Eyz6efMkIsxtfbLUVLm1UbeNz1hO6FNTJTfpwQfFxZyUBHz+udTrcsqIEbIa+8knXvdttQJ160oOynPPScmHe++ViFIA8v/RqZP4unJyQjrPSGXNGtFqr8uub9smJUxdLMTaKVZM1qtCZdHPnSt3Ky6/n4D6503AMkJ/6ZIknjZoIF+O0aPlw+u2KciePcB770nDjfvuC9pcw40iRSQSacoUSQlo29ahZ3iPHmJNea0Eir+cOwf89psf8fOAR6EHxH2TkmI82RuAKRZ9eroUC3RbxAwQ/3yFChIypviEuXVyQ8iffwLDh4sujRolzRXccvmylDSIjgY++igYUwx7+vSRoprduonYL10KxHbuLItvs2Z5dAPkYvFiscSKFhWzsWjR6/+uXVvq6ShuSU4WD4zP/vmYGHFJeqBxYynFtHevF0tUMTGSNOgH9nUht/55QP3zJmAZoa9RQzIIbZVY3cMMPPOMOECnTDHwqxA5tG8v9favi30ZxLZuLUVRjDRKycoC/vY3cYm5IipKcg0iYOHbH9asEW1r3tyHnZOTc1WsdOcrrfwAAB2ASURBVIfjgqzhP4kJ7QTnzZPz3Xyzm0H790tY2Ouv+3WuSMcyrhvAoMgD0mB18mSp5+tz7WHr0r69+E537QLatAEy2/YRYfaUK5+RIb8OI0YAzz4r3S0uXZJyoIcPi6ts7VoRenc/BAoAsUNuu+16xQHDnD8v4WUG78AaNBD3nVfeObvrxit/z3UuXpQ7xq5dPfwWrVwpz5oo5ReWEnpDTJ8uYZR9+0qClOKUdu1E7HfvBtpMfhRHi9eSBY/u3eUbmvcLbu/QkpICfP21lAEtUkRC+2JiJCutdm05xpNPSl3+Q4dCcWn5guxs+U30yW3z229yAAP+eUDi1xs29FLoS5eWu7eLF32YoPyIXboEdOzoYeCKFbJS26CBT+dRhMgS+pQU4JFH5F544kT1+XmgXTu5vd6TVghtquzEsVfelTCmdu3ki/f557JiOHy4WPIxMeIyeOQR9wcePFiEaOTI4FxIPmTLFvmv9Unok5Pl2aDQA+K++fVXL5pG+VmTfulS+YFp2dLDwBUrZFCByJIqs4mc/730dHE8V6woC4sRGErpC23bitjv3l8IL2YMBQ4elLoRhQtLTGa5ctK7sHdvMQmNWF61akkNhi++cAjvURyxVxl12yTbFevXS3GjChUM79K4sXh8tm83uIOf9W6WLBF7q3hxN4MOHRJ3n7pt/CYyhP7cOYnhOndO/BFefAEU8dMPHSr9zH9eXkSilTZulPvvRx8Vy37qVKBkSeMHffNNue0fPTpg887PJCWJt6tGDR92trcO9AKvM2TtCwc+WPQnTsjdQ9u2Hgba/fMaP+831hf648elL+DmzZLzr74+nxgyRKIjnntOLD8QiV/hyy8lgslbN1h8vBSAGzPG1LrmViEpSax5r72LR49KpIqXQl+vntQqMyz0frhufvlFlnjatfMwcMUKmVTDhl6fQ8mNtYX+p59E2H/5BRg3zsDKj+KKwoXF07J/vwQrmcLQoSLyn31m0gGtQUaGtID0OX4e8C7nAeICb9TIB4vehx/ppUulJpr9LsIlK1ZItliYVoPNT1hT6M+fB55/XmohxMbKp/epp0I9q3xPq1by3zhqlJTt95tGjeTHd9Qo4MIFEw5oDfz2z0dF+VAcR4R30yaDxUr9sOiXLBFvjNtqlUePSmKM+udNwXpCn5wsH/LPPwdee01EXluPmcaIEbL+2r+/FxEa7hg6FMjMBCZMMOFg1iApSe6gfNBq+fw3aOBhldM5jRtLUbvNmw0M9tGiP3BAQnY9um3UP28q1hH6q1elAchdd4lJsmyZVOnS6BpTKVtWKkasX2+Sx6VlS3mMGCH9ABQkJYnoel3IjFn+MF66bewkJsqzIfdN0aJikntp0S9dKs8eF2JXrJByGVoqwxSsI/QHDoiwP/ywmCStW4d6Rpalb1+pATd0qEk5T0OHSvjr//5nwsHyN5cuSUCTT/751FQRXi8XYu3UqHHd0+kRInHfeGnRL10qQW8eYyJWrhTflVv/jmIU6wh9nTpSmnXyZB9yxhVvIJJql1evAi++aMIBO3QQy23YMJP8QfmXjRvl/9Un/7wPiVKOEHnZWtDLejfMIvRt23qIJjpxQjLG1G1jGoaEnog6EtFOIkoloiFO3n+ciDKJ6Hfb42mH9x4jot22x2NmTv4GatYM6OGV69SpI56ymTOlCJpfEEnRqt27r69ERij2jlI+FzIrXhxISPD5/I0bS9LUuXMGBntZqnjbNulV7tE/v2qV/Cqo0JuGR6EnoigAYwF0ApAAoC8ROfskfc/MDW2P8bZ9ywJ4G0BTAE0AvE1EZUybvRJSBg2S2Pq33vK5ttV17Cbs1q1+zys/k5QklYXLl/dh5+RkUWo/whEbN5YeM7/+amCwl81HDPvnV66U1WiP8ZeKUYxY9E0ApDLzXma+AmAqgO4Gj98BwGJmPsHMJwEsBqDB7BahUCHgjTdkSWTRIj8PVrWqBFdv22bK3PIjzNcTpbzm0iXp4uHjQqwdrzJkvbTolyyRO0GP2b6rVsl1aCCFaRgR+ioADjq8Trdty8sDRLSZiH4kInvBYEP7ElF/IkohopTMzEyDU1fCgb/8Rcr5/+c/fh6ISLJlDRdbsR579kikqU8Lsb//Ls59P4W+YkUp921I6L2w6LOypMCpR7cNIIvKmsFuKkaE3tmySd4b9bkAajLzbQCWAJjsxb5g5nHMnMjMieV9umdVQkV0NPDyy3Jbbuh23x0JCRFt0fuVKGVfiPVT6AEvFmS9sOg3bADOnjXgtjl7VvoXVK9u6LiKMYwIfToAx5YeVQEcdhzAzMeZ2Z5P9yWARkb3VfI/zzwj9cz8turj46VBSYTWvlmzRozk+Hgfdk5OFveXCd3SGjeWtoLXmsS7IiZGstCzsjwec+lSuWm7914PAw/aHAAq9KZiROg3AIgjolpEFA2gD4BccRZEVNnhZTcA9vvvhQDuI6IytkXY+2zbFAtRurSI/Q8/SI0Wn7FHi0So+yYpSaJtfCq9vm6dNHUxAbufPiXFw0AvsmOXLJHaZLGxHgampcmzT2U7FVd4/EgxcxaAARCB3g5gGjNvJaJ3iKibbdhLRLSViDYBeAnA47Z9TwD4N+THYgOAd2zbFIvx8ssiUH71WbebshEo9KdOScCRT26bzEz5hTXBbQNcT0b16L4xWO/m/HnplmXIP3/ggDyrRW8qhmwHZl7AzPWYuQ4zv2fb9g9mnmP795vMfAsz387M9zLzDod9JzJzXdtjUmAuQwk1VavKwuyECQZu+V1Rq5aE1UWgnz45WaJu/OooZZLQx8QAt94qVrhbDFr0q1dLdQuP/nlAhL5gQSnGr5iGdTJjlZDz2mtShNLnGjhRUUD9+hFp0SclyR2RT0mtycnyf2diXZhevSSc/c8/3QwyaNEvXSqL9nffbeDEBw6I1aCliU1FhV4xjQYNpDL0f//rc8/oiI28SUqSIqslSviwc3KymODFipk2n9695Q5jxgw3gwxa9IbaBtpJS1O3TQBQoVdM5fXXxWX89dc+HiA+XrqbRFB9+qwsWUv1yT+fk+NXxUpX3HKLZD3/+KObQQYs+mPHJMTfkNsGEItehd50VOgVU7nnHil3O3Kkj/XJEhLElNy50/S5hSt//CG1ZXwS+p07xaI2KeLGDpFY9cuXSw8QpxgQ+kWL5M/Zvr2Bk2ZnSxVTFXrTUaFXTIUIGDxY6pPNnu3DASIw8saeKBUOC7GO9O4tNwyzZrkYYG8G78Z1M3MmUKmSwbWHw4dF7DW00nRU6BXT6dULqF1bOgR6TVycLMRFkJ8+KUnynHwyZJOTxVdev77p87rtNvlz/PCDiwFRUdK824VFf/EisGAB0KOHwdwADa0MGCr0iulERQHPPSeZnl4b5tHRQN26EWfRt2jhoUa7K+wVK33KsnKP3X3zyy/ia3eKm3o3ixfLUkvPngZPqEIfMFTolYDwyCMSDj3Jl8yJ+PiIsejT0yXXySf//IULUjo0AG4bOw8+KN4Ul244N/VuZs6U3wHDzd5U6AOGCr0SECpWBLp2lYZfV696uXNCglQwjIAesvae6F27+rDzxo2iwgEU+oYNxQ3n0n3jop1gVpY0pLn/fi9636alSVNin2JMFXeo0CsB46mnJGJjwQIvd4yPF6VITQ3IvMKFK1eAzz8HOnUSX7jXBHAh1g6RWPVLl0qHvxtw0U5w5UoZb9htA2hoZQBRoVcCRseOkslut1oNEyHFzaZPl9Z6PvfdTU6WshEVKpg6r7z07i2/u07dNy5cNzNnSt+QDh28OJEKfcBQoVcCRsGCwGOPiUWfkeHFjvYIEov76ceMEUveKzF0JDk5oNa8nUaNpB2z0+QpJ4uxzBKS2bGjwWxYO2lpGloZIFTolYDyxBPiRvYqU7Z4cVEWC1v0GzdKRccXXvAxYCYjQ2q3B0Ho7dE3ixc7Md7tPnqHpsEpKbLI7JXb5vRp4MwZtegDhAq9ElDq1QNatgQmTvSygbjF2wqOGSO/Z48/7uMBguCfd6R3b1lUnzMnzxulS8sv+fnz1zbNmCEhtl4tMGvETUBRoVcCzpNPArt2SVy9YRISgB07fKyjEN5kZgJTp4pby14XzGvWrZPu7HfcYercXNGkifSSvcF946QMwsyZElJZtqwXJ1ChDygq9ErAefBBiZibONGLneLjgUuXrnccshBffglcvgwMGODHQZKTJfaxSBHT5uUOu/tm4cI8Lnm70Ns2bt8u5Xd69fLyBNpZKqCo0CsBp3hxoE8fYNo06f1sCHvkjcUWZLOypF5/u3Y+9oYF5C4nJSVobhs7Dz4oIaHz5jlstN+S2Cz6mTPlZffuXh78wAG5Q6lY0e95KjeiQq8EhaeeEjfutGkGd7BocbNZs2Sh0ueQSkB+/M6dC7rQN20KVKly/Y4EwA2umxkzro/zigMHxDcUgFIOigq9EiSaNhXtNhxTHxMjQfgWs+jHjJGAoi5d/DhIkBdi7RQoAAwZAqxYAbRqJUE/js1HDhyQaCKv3TaAxtAHGBV6JSgQiVW/dq0XRrrFIm82b5aM0Rde8LNTXnKyrHTWrWva3IwyYIBY7du3S3z9sj/KyxunTl0rZ+xVWKUdjaEPKCr0StCwFzozvChrbyvoVVxm+DJmDFC0qEQh+czZs6K0997rY7lL/+nZU5paxcYC7R8qg//gNfCp05g5UzpTeV3O4epVqUWvFn3AUKFXgkaFClLk6uuvHXy87oiPF2E7fDjgcws0J04A334LPPywl2GHefn0UznYG2+YNjdfuPlmEfsHHiAMxn/QfWJ3rFzpozV/+LB0OFGhDxgq9EpQef55KXT2zTcGBlso8uYf/5BGHH4twp4/Lz0aO3aUGvQhpkQJ4PvvgQ9L/BML9tZHTo6P/nkNrQw4KvRKUGnbVny7I0YYyIWySOTNvHnA2LHAq69K1yaf+eILybZ66y3T5uYvRMCgm6ZgWet/Y9gwCe33Gk2WCjgq9EpQIQLefFN6yk6f7mFwhQpAmTL52qLPyJB6P7ffDnzwgR8HungR+M9/5JfSpy4lASQmBq2i1+GNN3xcNrALfbVqpk5LuY4KvRJ0evSQGjjDhnlYZyUS900+tehzcqTMwfnzwJQpQOHCfhxs/HipaRxG1vw13LQTNMSBA7KyW6yYeXNScqFCrwSdqChZS/ztN2DRIg+D83FbwY8+koqPH3/sRxYsICvXw4dL8Po995g2P9Nw007QEBpaGXBU6JWQ8Ne/SvbksGEeBiYkSGfqzMygzMssNm4UF1XPnkC/fn4ebNIk4NCh8LTmAXMsevXPB5SCoZ6AEplERwODBgEDB0ohxmbNXAx0XJAtXz5o8wMg8d0ffijnPntW6qU7Ptq1k3oAeQqLnTsH9O0rSwxffulnuPuVK+Lcb95c/PPhiD8WPbMIffv25s5JyYVa9ErI6NdPYsrdLlLaQyy3bAnKnK5x/rwsJgwdKumse/eKC6V8eSkNfM89wP/+J7UM8lRqe+UVaXf7zTdAuXJ+zuObb0QI33orZAlSHomJkcViX5q5nzolv4xq0QcUteiVkFGihMSV/+tfwNatklV5A9Wqif928WKpHRAMjh+Xrhnr10tIY//+zsd16SIhNW3aIHvuAmzYXx7Tp0s9nzfflORVv8jKAt5/H0hMlNj5cMWh3o3Xd10aQx8UVOiVkPLiixI1OHy4i3aDRCK6kyZJffoA1F+/dEnKx2RmAif3HMepkRNx8kRPnGr/LU6vqI0ym8XgrFHj+nOlSkBGm0ew8PlbsXBsKhZXKYSTOTLd7t3lx8tvvvtO7iQ++ih8rXkgdwVLb4VeY+iDggq9ElLKlRODecwY4N//dmHYde0qGUfLl5tm2WZkAPPnA3PnAkuWABcuXJsRgNcRFcWISSGUKgWcPHmjC7pQIXHhAw1RuVw8up/5AR3KrEW7ea8itpmBYmPMQFKS/LrNmSOuj6goKRFpf5w6JQH4999vyjUHDEeL3ltU6IOCIaEnoo4ARgOIAjCemZ3GShBRbwA/AGjMzClEVBPAdgA7bUPWMfOz/k5asRaDBomOf/ihCP4NtG4tMdbz5vkl9MeOSamYuXOlbwcg+vLEE0DH6ttQ491+iCl6GWVmf4XiTRvkMqLPnBFNSku7/hwbC3ToADRoUBj0+y1Ah4HA/dOk6P5tt0myV9766nv2iN/9m2/EWi9WTIS8UiVJFc7JkUd2tvwY9OsX3tY84LSdoGHS0iTBoEIFc+ek5IaZ3T4g4r4HQG0A0QA2AUhwMq4kgJUA1gFItG2rCeAPT+dwfDRq1IiVyOOJJ5iLFGE+fNjFgG7dmGvUYM7J8en4ycnM1aoxEzE3a8b83nvMmzbZDvfbb8xFizLXq8e8b5+PV8DMO3cyV6/OLBLNHBXFXKECc0IC8z33MDdpItuJmNu2ZZ48mfnsWd/PFy5s3izX9eOP3u/70EPMcXHmzykCAZDCLnTViEXfBEAqM+8FACKaCqA7gLxZLP8GMALAa/788CiRydChkj365JPiUrmh0VDXruLi2LbNxaqta778UuqoV64MbNggtXaukZUlJy1VCli1yj/Lsl49CaBftEgc/pmZ13MAMjPFNTNsmJSwrFrV9/OEG3naCXqFxtAHBSNCXwXAQYfX6QBytbYhojsAVGPmeUSUV+hrEdFvAM4A+Dszr8p7AiLqD6A/AFTXP3pEUrcuMGqUVLf8738lRDEXnTvL87x5hoX+0iUR+AkTgPvuk7XNG8IdR46UFN3p081xH8TGAn/5i//HyU/447o5cED8X0pAMRJH78xBeK1CCREVAPARgEFOxmUAqM7MdwAYCOA7Iip1w8GYxzFzIjMnlg92UowSNjz7LNCtm5RH2LQpz5tVqgB33pmnM7Vr0tKAli1F5P/2N2DBAiciv2sX8PbbwAMP+FhfVwEgcbJE3i/GXrkiq+IaWhlwjAh9OgDHsnJVATh2gigJoAGA5US0H0AzAHOIKJGZLzPzcQBg5o0QX389MyauWA8iEeZy5cQovh4JY6NrV4lUOX7c7XEWLhT3zK5d0oz73XedtO7LyQGeflpaPn3yianXEXEUKCDuG28t+vR0Wc3Qu/iAY0ToNwCII6JaRBQNoA+AOfY3mfk0M8cyc01mrglZjO3GEnVTnoiiAICIagOIA7DX9KtQLENsLDB5srjiX8vrBOzSRQT655+d7nvpkrh8OnaUIJYNGySm3SlffCE++Y8+ksGKf/hS70ZDK4OGR6Fn5iwAAwAshIRKTmPmrUT0DhF187B7KwCbiWgTgB8BPMvMJ/ydtGJt2reXkMvPPpP112skJoofff78G/bZvFneHj1akrA2bJC1UaccOAAMHiwneuyxgFxDxOFLvRt7VqwKfcAxFEfPzAsALMiz7R8uxrZ2+Pd0AJ7aSyjKDbz3HrBsmQTEbN4M3HQTxEXQpQswc6ZEyxQsiJwcKQP85psStr5gAdCpk5sDM8tiQE6OWPXhHqOeX/BF6LXhSNDQomZKWFK4sETJXLggRvfZs5KherTlAzh0qhjSZmzE5s0STTNokIj7li0eRB6Qg/70k9SQqVUrKNcSEfjquqlYMSBlLZTcaAkEJWy5+Wax1p95RsLchS4ADgH/J6+KFQPGjZN1VY/GeWYm8PLLUhN5wIDATTwSiYlxEirlAY2hDxoq9EpY068fULKkBGgUKiSPgmNHo9CpTBQa/i5atgRq1jR4sOHDxb0wYYKTMBzFL3yx6NPSgAYNAjMfJRcq9EpYQyRNPHKRBeCV94C7ngRq1jZ2oPPnReAfeOB6jXvFPGJiROhzcpykNTvB3nCkS5fAz01RH72SD+naVZ6dRN+45NtvxZp/8cXAzCnSuflmEe8lS4yNT06Wip1+NdNVjEJSCyd8SExM5BR7aUFFcUV8vPh3Fy70PJZZqkkWLAj8+qtG2gSCy5dlcbtBAwMd3yF3Vr/8IlZ9iRKBn18EQEQbmTnR2Xtq0Sv5k65dpT59njZ+TlmxAvjjD7HmVeQDQ+HC8v+7eLHEw7pj924JkX3uORX5IKFCr+RPunaVWilGXAVjxkhdhRuc/YqpPPOMhEGNGuV+3Ecfyaq6Rj4FDRV6JX/SooUsAE6YIK4ZVxw4IAVv7HVtlMBRtqxkuH33HXD4sPMxmZnSFvKRR6RutBIUVOiV/EmhQlKWcv58aU/lis8+k+fnngvOvCKdV16R7liuCsWNHStFiQY5K3arBApdjFXyLzk5UrVs4UKpapmYZx3q4kVJr2/VCpgxIzRzjER69waWLgUOHsztg79wQRbQmzeXfo6KqehirGJNChSQUpeVKwMPPXRjrZWpU6WksYZUBpdBg+RvMWlS7u2TJ8vf4/XXQzOvCEYteiX/s26ddBm5/37pFEUkfvtGjYCrVyUKRKNtgkuLFsCff0pTgKgocefUry+L4uvW6d8jAKhFr1ibZs2AESMkZG/0aNmWlCQtAgcMUFEJBa+9BuzdKwvhgDzv2SPWvP49go5a9Io1YJZ2gPPmSUORjz8W3316OlC8eKhnF3nYLfjy5eVHt3lzibixW/iK6ahFr1gfImDiRKBqVVkMnD5dQv1U5ENDVJRE4KxbB3z4oZQ8GDhQRT5EqEWvWIsNG4C77pLGJKmpQG2DRc8U8zl/XqKeTp4U3/yBA5JQpQQEteiVyKFxY4m2GTVKRT7UFC9+PX/h+edV5EOIlilWrEevXqGegWJn4ECpR/Tqq6GeSUSjQq8oSuAoVw74739DPYuIR103iqIoFkeFXlEUxeKo0CuKolgcFXpFURSLo0KvKIpicVToFUVRLI4KvaIoisVRoVcURbE4YVfrhogyAaT5cYhYAMdMmk5+Qq87stDrjiyMXHcNZi7v7I2wE3p/IaIUV4V9rIxed2Sh1x1Z+Hvd6rpRFEWxOCr0iqIoFseKQj8u1BMIEXrdkYVed2Th13VbzkevKIqi5MaKFr2iKIrigAq9oiiKxbGM0BNRRyLaSUSpRDQk1PMJJEQ0kYiOEtEfDtvKEtFiItptey4TyjmaDRFVI6JfiGg7EW0lopdt261+3UWIaD0RbbJd979s22sRUbLtur8nouhQzzUQEFEUEf1GRPNsryPluvcT0RYi+p2IUmzbfP6sW0LoiSgKwFgAnQAkAOhLRAmhnVVA+QpAxzzbhgBYysxxAJbaXluJLACDmDkeQDMAL9j+xla/7ssA2jDz7QAaAuhIRM0ADAfwke26TwJ4KoRzDCQvA9ju8DpSrhsA7mXmhg7x8z5/1i0h9ACaAEhl5r3MfAXAVADdQzyngMHMKwGcyLO5O4DJtn9PBtAjqJMKMMycwcy/2v59FvLlrwLrXzcz8znby0K2BwNoA+BH23bLXTcAEFFVAF0AjLe9JkTAdbvB58+6VYS+CoCDDq/TbdsiiYrMnAGIKAKoEOL5BAwiqgngDgDJiIDrtrkvfgdwFMBiAHsAnGLmLNsQq37ePwYwGECO7XU5RMZ1A/JjvoiINhJRf9s2nz/rVmkOTk62adyoBSGiEgCmA3iFmc+IkWdtmDkbQEMiigEwE0C8s2HBnVVgIaKuAI4y80Yiam3f7GSopa7bgbuY+TARVQCwmIh2+HMwq1j06QCqObyuCuBwiOYSKv4kosoAYHs+GuL5mA4RFYKI/LfMPMO22fLXbYeZTwFYDlmjiCEiu6Fmxc/7XQC6EdF+iCu2DcTCt/p1AwCY+bDt+Sjkx70J/PisW0XoNwCIs63IRwPoA2BOiOcUbOYAeMz278cAzA7hXEzH5p+dAGA7M49yeMvq113eZsmDiIoCaAdZn/gFQG/bMMtdNzO/ycxVmbkm5Pu8jJkfhsWvGwCIqDgRlbT/G8B9AP6AH591y2TGElFnyC9+FICJzPxeiKcUMIhoCoDWkNKlfwJ4G8AsANMAVAdwAMCDzJx3wTbfQkR3A1gFYAuu+2yHQvz0Vr7u2yALb1EQw2waM79DRLUhlm5ZAL8B+CszXw7dTAOHzXXzGjN3jYTrtl3jTNvLggC+Y+b3iKgcfPysW0boFUVRFOdYxXWjKIqiuECFXlEUxeKo0CuKolgcFXpFURSLo0KvKIpicVToFUVRLI4KvaIoisX5f9dGe+h6ChrTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "# print(signal.shape)\n",
    "# print(signal[2].shape)\n",
    "# print(signal[2].mean(dim = 0).shape)\n",
    "# print(signal[2][ : 10].mean(dim = 0).shape)\n",
    "# print(signal[1][2].shape)\n",
    "mean = running_mean(signal, window_size = 5)\n",
    "print(mean.shape)\n",
    "sig_ = signal[0].transpose(0, 1)\n",
    "mean_ = mean[0].transpose(0, 1)\n",
    "t = range(50)\n",
    "plt.plot(t, sig_[1].data.numpy(), 'r', t, mean_[1].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_mean` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 10, 3)\n",
    "        self.fc1 = nn.Linear(46 * 10, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.pamap = nn.Linear(64, 12)\n",
    "        self.robogame = nn.Linear(64, 4)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.pamap.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        nn.init.xavier_uniform_(self.robogame.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "        self.conv1.requires_grad = False\n",
    "        self.conv2.requires_grad = False\n",
    "#         self.conv3.requires_grad = False\n",
    "        self.fc1.requires_grad = False\n",
    "        \n",
    "    # use flag = True during fine-tuning \n",
    "    def forward(self, signal, flag = False):\n",
    "        signal = torch.transpose(signal, 1, 2)\n",
    "        out = F.relu(self.conv1(signal))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(-1, 46 * 10)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        if flag : \n",
    "            out = F.log_softmax(self.robogame(out), dim = 1)\n",
    "        else :\n",
    "            out = F.log_softmax(self.pamap(out), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet().double()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()\n",
    "    \n",
    "Net.load_state_dict(torch.load('../saved_models/model5.pt', map_location = 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  24  loss =  40.38579961256982\n",
      "epoch =  0  step =  20  of total steps  24  loss =  11.082769917554113\n",
      "epoch =  0  step =  40  of total steps  24  loss =  4.386315553257795\n",
      "epoch =  0  step =  60  of total steps  24  loss =  4.5303314611552725\n",
      "epoch :  0  /  20  | TL :  10.175358823116795  | VL :  4.0957429852096086\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  24  loss =  2.2734264813851945\n",
      "epoch =  1  step =  20  of total steps  24  loss =  2.560068265577454\n",
      "epoch =  1  step =  40  of total steps  24  loss =  5.460454538465867\n",
      "epoch =  1  step =  60  of total steps  24  loss =  1.640364041251571\n",
      "epoch :  1  /  20  | TL :  2.9486955296092665  | VL :  2.7871905952074583\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  24  loss =  1.641685817389175\n",
      "epoch =  2  step =  20  of total steps  24  loss =  3.171220095012442\n",
      "epoch =  2  step =  40  of total steps  24  loss =  1.6949074627107763\n",
      "epoch =  2  step =  60  of total steps  24  loss =  1.8898738992152464\n",
      "epoch :  2  /  20  | TL :  2.084889712451881  | VL :  2.4027770530013237\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  24  loss =  1.4595966628378245\n",
      "epoch =  3  step =  20  of total steps  24  loss =  2.4750518567044053\n",
      "epoch =  3  step =  40  of total steps  24  loss =  2.137516267740264\n",
      "epoch =  3  step =  60  of total steps  24  loss =  2.3187881308674734\n",
      "epoch :  3  /  20  | TL :  1.7356064331755165  | VL :  2.1142892410331964\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  24  loss =  1.6469333825553476\n",
      "epoch =  4  step =  20  of total steps  24  loss =  1.7054418616286844\n",
      "epoch =  4  step =  40  of total steps  24  loss =  1.680567356252085\n",
      "epoch =  4  step =  60  of total steps  24  loss =  1.1955434742146107\n",
      "epoch :  4  /  20  | TL :  1.5106702881230147  | VL :  1.8413889423247118\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  24  loss =  1.6567471908044213\n",
      "epoch =  5  step =  20  of total steps  24  loss =  1.1158275720626312\n",
      "epoch =  5  step =  40  of total steps  24  loss =  1.3887438090585573\n",
      "epoch =  5  step =  60  of total steps  24  loss =  1.6431585381859621\n",
      "epoch :  5  /  20  | TL :  1.4164035088683855  | VL :  1.9293270089783572\n",
      "epoch =  6  step =  0  of total steps  24  loss =  1.3425372535509923\n",
      "epoch =  6  step =  20  of total steps  24  loss =  1.4961099284460522\n",
      "epoch =  6  step =  40  of total steps  24  loss =  1.1020033698049267\n",
      "epoch =  6  step =  60  of total steps  24  loss =  1.3348990156401497\n",
      "epoch :  6  /  20  | TL :  1.2936357763085276  | VL :  1.7418578478453988\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  24  loss =  1.3058005726811195\n",
      "epoch =  7  step =  20  of total steps  24  loss =  0.616661984528921\n",
      "epoch =  7  step =  40  of total steps  24  loss =  1.5246193723732377\n",
      "epoch =  7  step =  60  of total steps  24  loss =  1.3087683923065438\n",
      "epoch :  7  /  20  | TL :  1.23130672360364  | VL :  1.7806504189870072\n",
      "epoch =  8  step =  0  of total steps  24  loss =  1.0595622124255193\n",
      "epoch =  8  step =  20  of total steps  24  loss =  0.8244724459552348\n",
      "epoch =  8  step =  40  of total steps  24  loss =  1.2716404859532482\n",
      "epoch =  8  step =  60  of total steps  24  loss =  1.35941177883245\n",
      "epoch :  8  /  20  | TL :  1.1733878136739955  | VL :  1.7815597692379488\n",
      "epoch =  9  step =  0  of total steps  24  loss =  0.6887240460282981\n",
      "epoch =  9  step =  20  of total steps  24  loss =  0.973961218744841\n",
      "epoch =  9  step =  40  of total steps  24  loss =  1.4255489516416542\n",
      "epoch =  9  step =  60  of total steps  24  loss =  1.1443442155609076\n",
      "epoch :  9  /  20  | TL :  1.117689054620426  | VL :  1.6661637498917556\n",
      "saving model\n",
      "epoch =  10  step =  0  of total steps  24  loss =  0.7839298908251182\n",
      "epoch =  10  step =  20  of total steps  24  loss =  0.9679741299347808\n",
      "epoch =  10  step =  40  of total steps  24  loss =  0.9276047358300996\n",
      "epoch =  10  step =  60  of total steps  24  loss =  1.1721941772427138\n",
      "epoch :  10  /  20  | TL :  1.0607881621244362  | VL :  1.601590938054959\n",
      "saving model\n",
      "epoch =  11  step =  0  of total steps  24  loss =  0.6463626573536144\n",
      "epoch =  11  step =  20  of total steps  24  loss =  0.8277497976352012\n",
      "epoch =  11  step =  40  of total steps  24  loss =  0.9156837544496328\n",
      "epoch =  11  step =  60  of total steps  24  loss =  1.1899139247512696\n",
      "epoch :  11  /  20  | TL :  1.057769295621444  | VL :  1.6298130616088453\n",
      "epoch =  12  step =  0  of total steps  24  loss =  1.3212486670868682\n",
      "epoch =  12  step =  20  of total steps  24  loss =  0.9030060783244769\n",
      "epoch =  12  step =  40  of total steps  24  loss =  0.8964618203607567\n",
      "epoch =  12  step =  60  of total steps  24  loss =  0.8695932946620523\n",
      "epoch :  12  /  20  | TL :  1.0203534034702704  | VL :  1.7186065388074427\n",
      "epoch =  13  step =  0  of total steps  24  loss =  1.1647714604996913\n",
      "epoch =  13  step =  20  of total steps  24  loss =  1.075135839006023\n",
      "epoch =  13  step =  40  of total steps  24  loss =  0.8746860503573091\n",
      "epoch =  13  step =  60  of total steps  24  loss =  1.1479204623967647\n",
      "epoch :  13  /  20  | TL :  0.9976711162872127  | VL :  1.5587375006983104\n",
      "saving model\n",
      "epoch =  14  step =  0  of total steps  24  loss =  0.8207604890081892\n",
      "epoch =  14  step =  20  of total steps  24  loss =  1.22972897482687\n",
      "epoch =  14  step =  40  of total steps  24  loss =  1.1278041835223638\n",
      "epoch =  14  step =  60  of total steps  24  loss =  1.0143420806214558\n",
      "epoch :  14  /  20  | TL :  0.9724252978077235  | VL :  1.6327743622838176\n",
      "epoch =  15  step =  0  of total steps  24  loss =  0.7892789742268272\n",
      "epoch =  15  step =  20  of total steps  24  loss =  0.8423424020568351\n",
      "epoch =  15  step =  40  of total steps  24  loss =  0.7394852895029351\n",
      "epoch =  15  step =  60  of total steps  24  loss =  0.883641773506376\n",
      "epoch :  15  /  20  | TL :  0.9422222487683921  | VL :  1.597082277885344\n",
      "epoch =  16  step =  0  of total steps  24  loss =  0.8503904834336841\n",
      "epoch =  16  step =  20  of total steps  24  loss =  0.9735615029177268\n",
      "epoch =  16  step =  40  of total steps  24  loss =  0.8196834386577747\n",
      "epoch =  16  step =  60  of total steps  24  loss =  0.546660836343205\n",
      "epoch :  16  /  20  | TL :  0.9235061924872765  | VL :  1.5499680574419743\n",
      "saving model\n",
      "epoch =  17  step =  0  of total steps  24  loss =  0.7302748087140275\n",
      "epoch =  17  step =  20  of total steps  24  loss =  1.1527202390715954\n",
      "epoch =  17  step =  40  of total steps  24  loss =  0.7135103272455835\n",
      "epoch =  17  step =  60  of total steps  24  loss =  0.5736566384414842\n",
      "epoch :  17  /  20  | TL :  0.9190719707803809  | VL :  1.5093811847293013\n",
      "saving model\n",
      "epoch =  18  step =  0  of total steps  24  loss =  1.0273000489604207\n",
      "epoch =  18  step =  20  of total steps  24  loss =  0.687969291221481\n",
      "epoch =  18  step =  40  of total steps  24  loss =  1.358016132038631\n",
      "epoch =  18  step =  60  of total steps  24  loss =  0.8169610734240705\n",
      "epoch :  18  /  20  | TL :  0.9096920452183789  | VL :  1.7122805414019098\n",
      "epoch =  19  step =  0  of total steps  24  loss =  1.1895884760480273\n",
      "epoch =  19  step =  20  of total steps  24  loss =  0.9457142649131994\n",
      "epoch =  19  step =  40  of total steps  24  loss =  0.924966634852499\n",
      "epoch =  19  step =  60  of total steps  24  loss =  0.8396435323227607\n",
      "epoch :  19  /  20  | TL :  0.903707897331913  | VL :  1.673891073086247\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().double()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).double()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().double()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).double()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '../saved_models/model5_finetuning.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f012ccc0358>,\n",
       " <matplotlib.lines.Line2D at 0x7f012ccc04a8>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(20)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).double()\n",
    "        labels = Variable(labels).double()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6429794520547946\n",
      "0.4861111111111111\n",
      "0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader, Net))\n",
    "print(_get_accuracy(testloader, Net))\n",
    "print(_get_accuracy(valloader, Net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6738013698630136\n",
      "0.4722222222222222\n",
      "0.4305555555555556\n"
     ]
    }
   ],
   "source": [
    "testing_Net = ConvNet().double()\n",
    "testing_Net.load_state_dict(torch.load('../saved_models/model5_finetuning.pt'))\n",
    "testing_Net.eval()\n",
    "print(_get_accuracy(trainloader, testing_Net))\n",
    "print(_get_accuracy(testloader, testing_Net))\n",
    "print(_get_accuracy(valloader, testing_Net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even using `running_mean` processed data, the network again overfits. Even increasing window size didn't help (decreasing won't help as it will be closer to raw data then). Increasing too much is also not helpful as the plot will get more and more flat. So, we need to try out other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch implementation of running standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_std_dev(signal, window_size = 10):\n",
    "    ''' Returns running standard deviation of 3D signal (batch_size, length, channels)\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].std(dim = 0)\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = np.abs(signal[i][j])\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_std_dev` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0135a2fa58>,\n",
       " <matplotlib.lines.Line2D at 0x7f0135a2fba8>]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "mean = running_std_dev(signal, window_size = 5)\n",
    "print(mean.shape)\n",
    "sig_ = signal[0].transpose(0, 1)\n",
    "mean_ = mean[0].transpose(0, 1)\n",
    "t = range(50)\n",
    "plt.plot(t, sig_[0].data.numpy(), 'r', t, mean_[0].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_std_dev` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 5, 3)\n",
    "        self.fc1 = nn.Linear(46 * 5, 5)\n",
    "        self.mp = nn.MaxPool1d(2, 2)\n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features = 5)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features = 5)\n",
    "        self.bnfc = nn.BatchNorm1d(num_features = 5)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal_ = running_std_dev(signal, window_size = 10)\n",
    "        signal_ = signal_.view(-1, 3, 50)\n",
    "        out = F.relu(self.conv1(signal_))\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.bn2(out)\n",
    "        out = out.view(-1, 46 * 5)\n",
    "        out = F.log_softmax(self.bnfc(self.fc1(out)), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  24  loss =  1.5915772914886475\n",
      "epoch =  0  step =  20  of total steps  24  loss =  1.5109798908233643\n",
      "epoch =  0  step =  40  of total steps  24  loss =  1.474916696548462\n",
      "epoch =  0  step =  60  of total steps  24  loss =  1.7542158365249634\n",
      "epoch :  0  /  30  | TL :  1.6536096938668865  | VL :  1.5527667999267578\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  24  loss =  1.5564055442810059\n",
      "epoch =  1  step =  20  of total steps  24  loss =  1.458630919456482\n",
      "epoch =  1  step =  40  of total steps  24  loss =  1.3727484941482544\n",
      "epoch =  1  step =  60  of total steps  24  loss =  1.277813196182251\n",
      "epoch :  1  /  30  | TL :  1.4873102919696128  | VL :  1.4842694997787476\n",
      "saving model\n",
      "epoch =  2  step =  0  of total steps  24  loss =  1.3420875072479248\n",
      "epoch =  2  step =  20  of total steps  24  loss =  1.5141997337341309\n",
      "epoch =  2  step =  40  of total steps  24  loss =  1.4671512842178345\n",
      "epoch =  2  step =  60  of total steps  24  loss =  1.388037085533142\n",
      "epoch :  2  /  30  | TL :  1.4383495833775768  | VL :  1.4263825416564941\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  24  loss =  1.365372896194458\n",
      "epoch =  3  step =  20  of total steps  24  loss =  1.408215045928955\n",
      "epoch =  3  step =  40  of total steps  24  loss =  1.558132290840149\n",
      "epoch =  3  step =  60  of total steps  24  loss =  1.3750078678131104\n",
      "epoch :  3  /  30  | TL :  1.4069606555651313  | VL :  1.4214377403259277\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  24  loss =  1.5007541179656982\n",
      "epoch =  4  step =  20  of total steps  24  loss =  1.1930480003356934\n",
      "epoch =  4  step =  40  of total steps  24  loss =  1.3849663734436035\n",
      "epoch =  4  step =  60  of total steps  24  loss =  1.120690941810608\n",
      "epoch :  4  /  30  | TL :  1.3657008719770876  | VL :  1.371471881866455\n",
      "saving model\n",
      "epoch =  5  step =  0  of total steps  24  loss =  1.4087554216384888\n",
      "epoch =  5  step =  20  of total steps  24  loss =  1.3455548286437988\n",
      "epoch =  5  step =  40  of total steps  24  loss =  1.3961673974990845\n",
      "epoch =  5  step =  60  of total steps  24  loss =  1.121755838394165\n",
      "epoch :  5  /  30  | TL :  1.3440023072778362  | VL :  1.3309619426727295\n",
      "saving model\n",
      "epoch =  6  step =  0  of total steps  24  loss =  1.4399425983428955\n",
      "epoch =  6  step =  20  of total steps  24  loss =  1.0823360681533813\n",
      "epoch =  6  step =  40  of total steps  24  loss =  1.3000653982162476\n",
      "epoch =  6  step =  60  of total steps  24  loss =  1.5991154909133911\n",
      "epoch :  6  /  30  | TL :  1.3107717216831365  | VL :  1.30765700340271\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  24  loss =  1.282135248184204\n",
      "epoch =  7  step =  20  of total steps  24  loss =  1.3511239290237427\n",
      "epoch =  7  step =  40  of total steps  24  loss =  1.0557453632354736\n",
      "epoch =  7  step =  60  of total steps  24  loss =  1.5855082273483276\n",
      "epoch :  7  /  30  | TL :  1.2851432080138219  | VL :  1.3126702308654785\n",
      "epoch =  8  step =  0  of total steps  24  loss =  1.2972432374954224\n",
      "epoch =  8  step =  20  of total steps  24  loss =  1.5268574953079224\n",
      "epoch =  8  step =  40  of total steps  24  loss =  0.9553670287132263\n",
      "epoch =  8  step =  60  of total steps  24  loss =  1.161264419555664\n",
      "epoch :  8  /  30  | TL :  1.2642034422861386  | VL :  1.3216208219528198\n",
      "epoch =  9  step =  0  of total steps  24  loss =  1.5361160039901733\n",
      "epoch =  9  step =  20  of total steps  24  loss =  1.1575207710266113\n",
      "epoch =  9  step =  40  of total steps  24  loss =  1.1924257278442383\n",
      "epoch =  9  step =  60  of total steps  24  loss =  1.0472818613052368\n",
      "epoch :  9  /  30  | TL :  1.2581690909111336  | VL :  1.296156406402588\n",
      "saving model\n",
      "epoch =  10  step =  0  of total steps  24  loss =  1.4648655652999878\n",
      "epoch =  10  step =  20  of total steps  24  loss =  1.449369192123413\n",
      "epoch =  10  step =  40  of total steps  24  loss =  1.0382721424102783\n",
      "epoch =  10  step =  60  of total steps  24  loss =  1.2700061798095703\n",
      "epoch :  10  /  30  | TL :  1.2365038901159209  | VL :  1.2643380165100098\n",
      "saving model\n",
      "epoch =  11  step =  0  of total steps  24  loss =  1.2757078409194946\n",
      "epoch =  11  step =  20  of total steps  24  loss =  1.2455470561981201\n",
      "epoch =  11  step =  40  of total steps  24  loss =  1.1325781345367432\n",
      "epoch =  11  step =  60  of total steps  24  loss =  1.3849530220031738\n",
      "epoch :  11  /  30  | TL :  1.2093324057043415  | VL :  1.3011257648468018\n",
      "epoch =  12  step =  0  of total steps  24  loss =  1.3356448411941528\n",
      "epoch =  12  step =  20  of total steps  24  loss =  1.173122525215149\n",
      "epoch =  12  step =  40  of total steps  24  loss =  1.0693538188934326\n",
      "epoch =  12  step =  60  of total steps  24  loss =  1.1765739917755127\n",
      "epoch :  12  /  30  | TL :  1.2051251791927913  | VL :  1.2863506078720093\n",
      "epoch =  13  step =  0  of total steps  24  loss =  0.9185419082641602\n",
      "epoch =  13  step =  20  of total steps  24  loss =  1.1788575649261475\n",
      "epoch =  13  step =  40  of total steps  24  loss =  1.0805847644805908\n",
      "epoch =  13  step =  60  of total steps  24  loss =  1.1558542251586914\n",
      "epoch :  13  /  30  | TL :  1.1838056110355952  | VL :  1.2896466255187988\n",
      "epoch =  14  step =  0  of total steps  24  loss =  1.0677951574325562\n",
      "epoch =  14  step =  20  of total steps  24  loss =  1.24543297290802\n",
      "epoch =  14  step =  40  of total steps  24  loss =  1.3538049459457397\n",
      "epoch =  14  step =  60  of total steps  24  loss =  1.076460361480713\n",
      "epoch :  14  /  30  | TL :  1.1747662498526377  | VL :  1.262938380241394\n",
      "saving model\n",
      "epoch =  15  step =  0  of total steps  24  loss =  1.300122618675232\n",
      "epoch =  15  step =  20  of total steps  24  loss =  1.270992636680603\n",
      "epoch =  15  step =  40  of total steps  24  loss =  1.3661311864852905\n",
      "epoch =  15  step =  60  of total steps  24  loss =  1.1055549383163452\n",
      "epoch :  15  /  30  | TL :  1.173721730709076  | VL :  1.2685959339141846\n",
      "epoch =  16  step =  0  of total steps  24  loss =  1.0054668188095093\n",
      "epoch =  16  step =  20  of total steps  24  loss =  0.9830688238143921\n",
      "epoch =  16  step =  40  of total steps  24  loss =  1.1810587644577026\n",
      "epoch =  16  step =  60  of total steps  24  loss =  1.389623999595642\n",
      "epoch :  16  /  30  | TL :  1.16385477046444  | VL :  1.2561317682266235\n",
      "saving model\n",
      "epoch =  17  step =  0  of total steps  24  loss =  1.3564980030059814\n",
      "epoch =  17  step =  20  of total steps  24  loss =  1.1083053350448608\n",
      "epoch =  17  step =  40  of total steps  24  loss =  1.2584996223449707\n",
      "epoch =  17  step =  60  of total steps  24  loss =  1.1147863864898682\n",
      "epoch :  17  /  30  | TL :  1.1411574646218183  | VL :  1.2523555755615234\n",
      "saving model\n",
      "epoch =  18  step =  0  of total steps  24  loss =  1.023354411125183\n",
      "epoch =  18  step =  20  of total steps  24  loss =  0.8993639349937439\n",
      "epoch =  18  step =  40  of total steps  24  loss =  1.4132812023162842\n",
      "epoch =  18  step =  60  of total steps  24  loss =  0.8489101529121399\n",
      "epoch :  18  /  30  | TL :  1.1374710422672638  | VL :  1.2577648162841797\n",
      "epoch =  19  step =  0  of total steps  24  loss =  1.2338194847106934\n",
      "epoch =  19  step =  20  of total steps  24  loss =  1.0799100399017334\n",
      "epoch =  19  step =  40  of total steps  24  loss =  1.451222538948059\n",
      "epoch =  19  step =  60  of total steps  24  loss =  1.2180944681167603\n",
      "epoch :  19  /  30  | TL :  1.13540703139893  | VL :  1.2481663227081299\n",
      "saving model\n",
      "epoch =  20  step =  0  of total steps  24  loss =  1.1720162630081177\n",
      "epoch =  20  step =  20  of total steps  24  loss =  1.0338292121887207\n",
      "epoch =  20  step =  40  of total steps  24  loss =  1.1189615726470947\n",
      "epoch =  20  step =  60  of total steps  24  loss =  1.273023009300232\n",
      "epoch :  20  /  30  | TL :  1.132810398323895  | VL :  1.2598633766174316\n",
      "epoch =  21  step =  0  of total steps  24  loss =  1.0840789079666138\n",
      "epoch =  21  step =  20  of total steps  24  loss =  1.1232646703720093\n",
      "epoch =  21  step =  40  of total steps  24  loss =  1.3584263324737549\n",
      "epoch =  21  step =  60  of total steps  24  loss =  1.2384157180786133\n",
      "epoch :  21  /  30  | TL :  1.130017149121794  | VL :  1.2476024627685547\n",
      "saving model\n",
      "epoch =  22  step =  0  of total steps  24  loss =  1.0938506126403809\n",
      "epoch =  22  step =  20  of total steps  24  loss =  1.1870313882827759\n",
      "epoch =  22  step =  40  of total steps  24  loss =  1.3916808366775513\n",
      "epoch =  22  step =  60  of total steps  24  loss =  1.1255205869674683\n",
      "epoch :  22  /  30  | TL :  1.119125005317061  | VL :  1.2653919458389282\n",
      "epoch =  23  step =  0  of total steps  24  loss =  1.1669145822525024\n",
      "epoch =  23  step =  20  of total steps  24  loss =  1.1095833778381348\n",
      "epoch =  23  step =  40  of total steps  24  loss =  1.1835598945617676\n",
      "epoch =  23  step =  60  of total steps  24  loss =  1.2113662958145142\n",
      "epoch :  23  /  30  | TL :  1.118927776813507  | VL :  1.2656968832015991\n",
      "epoch =  24  step =  0  of total steps  24  loss =  1.150303602218628\n",
      "epoch =  24  step =  20  of total steps  24  loss =  1.2837120294570923\n",
      "epoch =  24  step =  40  of total steps  24  loss =  0.9228520393371582\n",
      "epoch =  24  step =  60  of total steps  24  loss =  1.0768330097198486\n",
      "epoch :  24  /  30  | TL :  1.1125250622017744  | VL :  1.314347267150879\n",
      "epoch =  25  step =  0  of total steps  24  loss =  0.9356022477149963\n",
      "epoch =  25  step =  20  of total steps  24  loss =  0.8457363843917847\n",
      "epoch =  25  step =  40  of total steps  24  loss =  0.9789284467697144\n",
      "epoch =  25  step =  60  of total steps  24  loss =  1.1486220359802246\n",
      "epoch :  25  /  30  | TL :  1.1042957754984295  | VL :  1.2577146291732788\n",
      "epoch =  26  step =  0  of total steps  24  loss =  0.8912360072135925\n",
      "epoch =  26  step =  20  of total steps  24  loss =  0.9030160307884216\n",
      "epoch =  26  step =  40  of total steps  24  loss =  1.6674878597259521\n",
      "epoch =  26  step =  60  of total steps  24  loss =  0.9227238893508911\n",
      "epoch :  26  /  30  | TL :  1.106340471195848  | VL :  1.2593603134155273\n",
      "epoch =  27  step =  0  of total steps  24  loss =  1.2544090747833252\n",
      "epoch =  27  step =  20  of total steps  24  loss =  0.7962004542350769\n",
      "epoch =  27  step =  40  of total steps  24  loss =  1.028196096420288\n",
      "epoch =  27  step =  60  of total steps  24  loss =  1.4845099449157715\n",
      "epoch :  27  /  30  | TL :  1.09473007019252  | VL :  1.2836909294128418\n",
      "epoch =  28  step =  0  of total steps  24  loss =  1.4272736310958862\n",
      "epoch =  28  step =  20  of total steps  24  loss =  0.9168794751167297\n",
      "epoch =  28  step =  40  of total steps  24  loss =  0.8348355293273926\n",
      "epoch =  28  step =  60  of total steps  24  loss =  1.0307475328445435\n",
      "epoch :  28  /  30  | TL :  1.097880589635405  | VL :  1.2698009014129639\n",
      "epoch =  29  step =  0  of total steps  24  loss =  1.32150399684906\n",
      "epoch =  29  step =  20  of total steps  24  loss =  1.1018472909927368\n",
      "epoch =  29  step =  40  of total steps  24  loss =  1.0353072881698608\n",
      "epoch =  29  step =  60  of total steps  24  loss =  1.522422432899475\n",
      "epoch :  29  /  30  | TL :  1.0906353356087044  | VL :  1.2615635395050049\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '1conv_softmax.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0135c5ee80>,\n",
       " <matplotlib.lines.Line2D at 0x7f0135c5efd0>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(30)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.81849315068494 / 47.91666666666667 / 48.61111111111111\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader, Net) * 100, '/', _get_accuracy(valloader, Net) * 100, '/', _get_accuracy(testloader, Net) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.59246575342466 / 53.47222222222222 / 52.77777777777778\n"
     ]
    }
   ],
   "source": [
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('1conv_softmax.pt'))\n",
    "testing_Net.eval()\n",
    "print(_get_accuracy(trainloader, testing_Net) * 100, '/', _get_accuracy(valloader, testing_Net) * 100, '/', _get_accuracy(testloader, testing_Net) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even using running standard deviation of raw data doesn't help reduce overfitting significantly. So, next we try using running RMS of raw data.\n",
    "\n",
    "### PyTorch implementation of `running_rms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_rms(signal, window_size = 10):\n",
    "    ''' Returns running rms of 3D signal (batch_size, length, channels)\n",
    "    Note : torch.norm just gives vector 2-norm, so we need to divide it by\n",
    "    sqrt(window_size) to make it the RMS value\n",
    "    '''\n",
    "    mean = torch.zeros_like(signal)\n",
    "    n = np.sqrt(window_size)\n",
    "    div = torch.tensor(np.array([n, n, n])).float()\n",
    "    if torch.cuda.is_available() : \n",
    "        div = div.cuda()\n",
    "    \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size) : \n",
    "            mean[i][j] = signal[i][j : j + window_size].norm(dim = 0) / div\n",
    "            \n",
    "    for i in range(signal.shape[0]) :\n",
    "        for j in range(signal.shape[1] - window_size, signal.shape[1]) :\n",
    "            mean[i][j] = signal[i][j]\n",
    "            \n",
    "    return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shows working of `running_rms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected backend CPU and dtype Double but got backend CPU and dtype Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-97bcda305a94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mrms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_rms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msig_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-f81c4c7abaca>\u001b[0m in \u001b[0;36mrunning_rms\u001b[0;34m(signal, window_size)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mmean\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mdiv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected backend CPU and dtype Double but got backend CPU and dtype Float"
     ]
    }
   ],
   "source": [
    "signal, label = next(iter(trainloader))\n",
    "if torch.cuda.is_available() :\n",
    "    signal = signal.cuda().float()\n",
    "rms = running_rms(signal, window_size = 10)\n",
    "print(rms.shape)\n",
    "sig_ = signal[0].transpose(0, 1).cpu()\n",
    "mean_ = rms[0].transpose(0, 1).cpu()\n",
    "t = range(50)\n",
    "plt.plot(t, sig_[1].data.numpy(), 'r', t, mean_[1].data.numpy(), 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training network using `running_rms` processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 5, 3)\n",
    "        self.conv2 = nn.Conv1d(5, 5, 3)\n",
    "        self.fc1 = nn.Linear(46 * 5, 5)\n",
    "#         self.mp = nn.MaxPool1d(2, 2)\n",
    "#         self.dropout = nn.Dropout(p = 0.5)\n",
    "#         self.bn1 = nn.BatchNorm1d(num_features = 5)\n",
    "#         self.bn2 = nn.BatchNorm1d(num_features = 5)\n",
    "#         self.bnfc = nn.BatchNorm1d(num_features = 5)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.conv2.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        nn.init.xavier_uniform_(self.fc1.weight, gain = nn.init.calculate_gain('sigmoid'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal_ = running_rms(signal, window_size = 10)\n",
    "        signal_ = signal_.view(-1, 3, 50)\n",
    "        out = F.relu(self.conv1(signal_))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = out.view(-1, 46 * 5)\n",
    "        out = F.log_softmax(self.fc1(out), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = ConvNet()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  24  loss =  1.8811068534851074\n",
      "epoch =  0  step =  20  of total steps  24  loss =  1.3653590679168701\n",
      "epoch =  0  step =  40  of total steps  24  loss =  1.2853695154190063\n",
      "epoch =  0  step =  60  of total steps  24  loss =  1.291702389717102\n",
      "epoch :  0  /  30  | TL :  1.3621268599000695  | VL :  1.3164602518081665\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  24  loss =  1.2448471784591675\n",
      "epoch =  1  step =  20  of total steps  24  loss =  1.0377711057662964\n",
      "epoch =  1  step =  40  of total steps  24  loss =  1.0086761713027954\n",
      "epoch =  1  step =  60  of total steps  24  loss =  1.180564522743225\n",
      "epoch :  1  /  30  | TL :  1.2508377130717447  | VL :  1.3296135663986206\n",
      "epoch =  2  step =  0  of total steps  24  loss =  1.1189979314804077\n",
      "epoch =  2  step =  20  of total steps  24  loss =  1.2224631309509277\n",
      "epoch =  2  step =  40  of total steps  24  loss =  1.1607489585876465\n",
      "epoch =  2  step =  60  of total steps  24  loss =  1.1938399076461792\n",
      "epoch :  2  /  30  | TL :  1.2393064768347022  | VL :  1.3060611486434937\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  24  loss =  1.3021384477615356\n",
      "epoch =  3  step =  20  of total steps  24  loss =  1.0817525386810303\n",
      "epoch =  3  step =  40  of total steps  24  loss =  1.2776519060134888\n",
      "epoch =  3  step =  60  of total steps  24  loss =  1.546712875366211\n",
      "epoch :  3  /  30  | TL :  1.2372265988833284  | VL :  1.301056981086731\n",
      "saving model\n",
      "epoch =  4  step =  0  of total steps  24  loss =  1.532987117767334\n",
      "epoch =  4  step =  20  of total steps  24  loss =  1.1698825359344482\n",
      "epoch =  4  step =  40  of total steps  24  loss =  1.30800461769104\n",
      "epoch =  4  step =  60  of total steps  24  loss =  1.0630090236663818\n",
      "epoch :  4  /  30  | TL :  1.2289143237349105  | VL :  1.302204966545105\n",
      "epoch =  5  step =  0  of total steps  24  loss =  1.2924392223358154\n",
      "epoch =  5  step =  20  of total steps  24  loss =  1.6495826244354248\n",
      "epoch =  5  step =  40  of total steps  24  loss =  1.4081907272338867\n",
      "epoch =  5  step =  60  of total steps  24  loss =  1.017055869102478\n",
      "epoch :  5  /  30  | TL :  1.2346076810196653  | VL :  1.3025054931640625\n",
      "epoch =  6  step =  0  of total steps  24  loss =  1.2474825382232666\n",
      "epoch =  6  step =  20  of total steps  24  loss =  1.3606036901474\n",
      "epoch =  6  step =  40  of total steps  24  loss =  1.1784090995788574\n",
      "epoch =  6  step =  60  of total steps  24  loss =  1.2484744787216187\n",
      "epoch :  6  /  30  | TL :  1.219812417683536  | VL :  1.2974063158035278\n",
      "saving model\n",
      "epoch =  7  step =  0  of total steps  24  loss =  1.1820281744003296\n",
      "epoch =  7  step =  20  of total steps  24  loss =  1.241288661956787\n",
      "epoch =  7  step =  40  of total steps  24  loss =  1.4275249242782593\n",
      "epoch =  7  step =  60  of total steps  24  loss =  1.2391878366470337\n",
      "epoch :  7  /  30  | TL :  1.2275948687775495  | VL :  1.289915919303894\n",
      "saving model\n",
      "epoch =  8  step =  0  of total steps  24  loss =  1.4555037021636963\n",
      "epoch =  8  step =  20  of total steps  24  loss =  1.2025268077850342\n",
      "epoch =  8  step =  40  of total steps  24  loss =  1.2675487995147705\n",
      "epoch =  8  step =  60  of total steps  24  loss =  1.2545719146728516\n",
      "epoch :  8  /  30  | TL :  1.2197730794344863  | VL :  1.2958641052246094\n",
      "epoch =  9  step =  0  of total steps  24  loss =  1.1848511695861816\n",
      "epoch =  9  step =  20  of total steps  24  loss =  1.05252206325531\n",
      "epoch =  9  step =  40  of total steps  24  loss =  1.082357406616211\n",
      "epoch =  9  step =  60  of total steps  24  loss =  1.1562994718551636\n",
      "epoch :  9  /  30  | TL :  1.2205718968012562  | VL :  1.2908395528793335\n",
      "epoch =  10  step =  0  of total steps  24  loss =  1.2513833045959473\n",
      "epoch =  10  step =  20  of total steps  24  loss =  1.293017029762268\n",
      "epoch =  10  step =  40  of total steps  24  loss =  1.0824171304702759\n",
      "epoch =  10  step =  60  of total steps  24  loss =  1.2718755006790161\n",
      "epoch :  10  /  30  | TL :  1.216893639466534  | VL :  1.3025002479553223\n",
      "epoch =  11  step =  0  of total steps  24  loss =  1.1819859743118286\n",
      "epoch =  11  step =  20  of total steps  24  loss =  1.2223892211914062\n",
      "epoch =  11  step =  40  of total steps  24  loss =  0.9674538373947144\n",
      "epoch =  11  step =  60  of total steps  24  loss =  1.4180184602737427\n",
      "epoch :  11  /  30  | TL :  1.2137230520379054  | VL :  1.2875325679779053\n",
      "saving model\n",
      "epoch =  12  step =  0  of total steps  24  loss =  1.0180778503417969\n",
      "epoch =  12  step =  20  of total steps  24  loss =  1.232564091682434\n",
      "epoch =  12  step =  40  of total steps  24  loss =  1.1419188976287842\n",
      "epoch =  12  step =  60  of total steps  24  loss =  1.365647554397583\n",
      "epoch :  12  /  30  | TL :  1.2164667501841506  | VL :  1.292335033416748\n",
      "epoch =  13  step =  0  of total steps  24  loss =  1.1962147951126099\n",
      "epoch =  13  step =  20  of total steps  24  loss =  1.2276442050933838\n",
      "epoch =  13  step =  40  of total steps  24  loss =  1.3981281518936157\n",
      "epoch =  13  step =  60  of total steps  24  loss =  1.1903408765792847\n",
      "epoch :  13  /  30  | TL :  1.2139642524392638  | VL :  1.29463529586792\n",
      "epoch =  14  step =  0  of total steps  24  loss =  1.1561352014541626\n",
      "epoch =  14  step =  20  of total steps  24  loss =  1.2134164571762085\n",
      "epoch =  14  step =  40  of total steps  24  loss =  1.145789384841919\n",
      "epoch =  14  step =  60  of total steps  24  loss =  1.2947076559066772\n",
      "epoch :  14  /  30  | TL :  1.210951222948832  | VL :  1.3021929264068604\n",
      "epoch =  15  step =  0  of total steps  24  loss =  1.118507742881775\n",
      "epoch =  15  step =  20  of total steps  24  loss =  0.9740551710128784\n",
      "epoch =  15  step =  40  of total steps  24  loss =  1.240596890449524\n",
      "epoch =  15  step =  60  of total steps  24  loss =  1.222632884979248\n",
      "epoch :  15  /  30  | TL :  1.211065943110479  | VL :  1.301877498626709\n",
      "epoch =  16  step =  0  of total steps  24  loss =  0.9485311508178711\n",
      "epoch =  16  step =  20  of total steps  24  loss =  1.2361562252044678\n",
      "epoch =  16  step =  40  of total steps  24  loss =  1.2679914236068726\n",
      "epoch =  16  step =  60  of total steps  24  loss =  1.2756195068359375\n",
      "epoch :  16  /  30  | TL :  1.2083104391620583  | VL :  1.2752752304077148\n",
      "saving model\n",
      "epoch =  17  step =  0  of total steps  24  loss =  1.366483449935913\n",
      "epoch =  17  step =  20  of total steps  24  loss =  1.118767499923706\n",
      "epoch =  17  step =  40  of total steps  24  loss =  1.4251952171325684\n",
      "epoch =  17  step =  60  of total steps  24  loss =  1.199074387550354\n",
      "epoch :  17  /  30  | TL :  1.2085544026061281  | VL :  1.291746973991394\n",
      "epoch =  18  step =  0  of total steps  24  loss =  1.32235848903656\n",
      "epoch =  18  step =  20  of total steps  24  loss =  1.3394056558609009\n",
      "epoch =  18  step =  40  of total steps  24  loss =  1.1178864240646362\n",
      "epoch =  18  step =  60  of total steps  24  loss =  1.2698698043823242\n",
      "epoch :  18  /  30  | TL :  1.2111185707458079  | VL :  1.2884950637817383\n",
      "epoch =  19  step =  0  of total steps  24  loss =  1.285465121269226\n",
      "epoch =  19  step =  20  of total steps  24  loss =  1.075966238975525\n",
      "epoch =  19  step =  40  of total steps  24  loss =  1.3953883647918701\n",
      "epoch =  19  step =  60  of total steps  24  loss =  1.3944604396820068\n",
      "epoch :  19  /  30  | TL :  1.206787540488047  | VL :  1.2658805847167969\n",
      "saving model\n",
      "epoch =  20  step =  0  of total steps  24  loss =  1.3673038482666016\n",
      "epoch =  20  step =  20  of total steps  24  loss =  1.4407153129577637\n",
      "epoch =  20  step =  40  of total steps  24  loss =  0.9142886400222778\n",
      "epoch =  20  step =  60  of total steps  24  loss =  1.0346355438232422\n",
      "epoch :  20  /  30  | TL :  1.2091668207351476  | VL :  1.296800136566162\n",
      "epoch =  21  step =  0  of total steps  24  loss =  1.12722647190094\n",
      "epoch =  21  step =  20  of total steps  24  loss =  1.309962272644043\n",
      "epoch =  21  step =  40  of total steps  24  loss =  1.048552393913269\n",
      "epoch =  21  step =  60  of total steps  24  loss =  1.4039450883865356\n",
      "epoch :  21  /  30  | TL :  1.2020688195751137  | VL :  1.294471025466919\n",
      "epoch =  22  step =  0  of total steps  24  loss =  1.223084568977356\n",
      "epoch =  22  step =  20  of total steps  24  loss =  1.4052660465240479\n",
      "epoch =  22  step =  40  of total steps  24  loss =  1.2221784591674805\n",
      "epoch =  22  step =  60  of total steps  24  loss =  1.170488715171814\n",
      "epoch :  22  /  30  | TL :  1.2048019391216644  | VL :  1.2658984661102295\n",
      "epoch =  23  step =  0  of total steps  24  loss =  1.30437171459198\n",
      "epoch =  23  step =  20  of total steps  24  loss =  1.1575068235397339\n",
      "epoch =  23  step =  40  of total steps  24  loss =  1.118457317352295\n",
      "epoch =  23  step =  60  of total steps  24  loss =  1.249645471572876\n",
      "epoch :  23  /  30  | TL :  1.2043895892900964  | VL :  1.2968378067016602\n",
      "epoch =  24  step =  0  of total steps  24  loss =  1.1930707693099976\n",
      "epoch =  24  step =  20  of total steps  24  loss =  1.2849507331848145\n",
      "epoch =  24  step =  40  of total steps  24  loss =  1.4297460317611694\n",
      "epoch =  24  step =  60  of total steps  24  loss =  1.4166173934936523\n",
      "epoch :  24  /  30  | TL :  1.2044420968996334  | VL :  1.2831717729568481\n",
      "epoch =  25  step =  0  of total steps  24  loss =  1.5505131483078003\n",
      "epoch =  25  step =  20  of total steps  24  loss =  1.1154916286468506\n",
      "epoch =  25  step =  40  of total steps  24  loss =  1.3296321630477905\n",
      "epoch =  25  step =  60  of total steps  24  loss =  1.117674708366394\n",
      "epoch :  25  /  30  | TL :  1.2002378318407765  | VL :  1.286512017250061\n",
      "epoch =  26  step =  0  of total steps  24  loss =  1.082871675491333\n",
      "epoch =  26  step =  20  of total steps  24  loss =  1.0742998123168945\n",
      "epoch =  26  step =  40  of total steps  24  loss =  1.3187546730041504\n",
      "epoch =  26  step =  60  of total steps  24  loss =  1.2550493478775024\n",
      "epoch :  26  /  30  | TL :  1.20274107341897  | VL :  1.2927815914154053\n",
      "epoch =  27  step =  0  of total steps  24  loss =  1.1299846172332764\n",
      "epoch =  27  step =  20  of total steps  24  loss =  1.1077907085418701\n",
      "epoch =  27  step =  40  of total steps  24  loss =  0.93753981590271\n",
      "epoch =  27  step =  60  of total steps  24  loss =  1.264987826347351\n",
      "epoch :  27  /  30  | TL :  1.200698932556257  | VL :  1.2815316915512085\n",
      "epoch =  28  step =  0  of total steps  24  loss =  1.385637640953064\n",
      "epoch =  28  step =  20  of total steps  24  loss =  1.2711786031723022\n",
      "epoch =  28  step =  40  of total steps  24  loss =  1.269797444343567\n",
      "epoch =  28  step =  60  of total steps  24  loss =  1.189910888671875\n",
      "epoch :  28  /  30  | TL :  1.1992432515915126  | VL :  1.2752134799957275\n",
      "epoch =  29  step =  0  of total steps  24  loss =  1.288767695426941\n",
      "epoch =  29  step =  20  of total steps  24  loss =  1.16928231716156\n",
      "epoch =  29  step =  40  of total steps  24  loss =  1.0412744283676147\n",
      "epoch =  29  step =  60  of total steps  24  loss =  1.248137354850769\n",
      "epoch :  29  /  30  | TL :  1.1998709236105827  | VL :  1.2694483995437622\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net(images)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net(images)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, ' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), '1conv_softmax.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f012e066dd8>,\n",
       " <matplotlib.lines.Line2D at 0x7f012dffdd68>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(30)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.171232876712324 / 44.44444444444444 / 45.13888888888889\n",
      "48.88698630136986 / 45.13888888888889 / 43.75\n"
     ]
    }
   ],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "        \n",
    "        if torch.cuda.is_available() : \n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        outputs = Net(images)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.cpu().numpy()\n",
    "        pred_ind = pred_ind.data.cpu().numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.eval()\n",
    "\n",
    "print(_get_accuracy(trainloader, Net) * 100, '/', _get_accuracy(valloader, Net) * 100, '/', _get_accuracy(testloader, Net) * 100)\n",
    "\n",
    "testing_Net = ConvNet()\n",
    "testing_Net.load_state_dict(torch.load('1conv_softmax.pt'))\n",
    "testing_Net.eval()\n",
    "print(_get_accuracy(trainloader, testing_Net) * 100, '/', _get_accuracy(valloader, testing_Net) * 100, '/', _get_accuracy(testloader, testing_Net) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
