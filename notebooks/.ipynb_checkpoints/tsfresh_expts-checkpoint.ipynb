{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import extract_relevant_features\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/data_only_tsfresh_compatible.csv', names = ['x_acc', 'y_acc', 'z_acc', 'id'])\n",
    "labels = pd.read_csv('../data/labels_only.csv', names = ['Blocking', 'Dodging', 'Inactive', 'Moving', 'Sprinting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [07:26<00:00, 38.74s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_features = extract_features(data, column_id = \"id\", column_sort = None, column_kind = None, column_value = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068, 2382)\n"
     ]
    }
   ],
   "source": [
    "print(extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_arr = labels.values\n",
    "label_arr = np.argmax(label_arr, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert these labels also such that there is one label per example (right now there are 150 per example due to the way data was annotated). Also we need to convert the `extracted_features` dataframe into a NumPy array. This is required before attempting any sort of classification, of course.\n",
    "\n",
    "#### Reducing the labels to the correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_features = np.zeros(extracted_features.shape[0])\n",
    "for i in range(len(label_arr)) : \n",
    "    if i % 150 == 0 : \n",
    "        y_features[i // 150] = label_arr[i]\n",
    "        \n",
    "# Also converting into Pandas Series for use in extracting relevant features using tsfresh\n",
    "y = pd.Series(y_features, dtype = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068, 693)\n"
     ]
    }
   ],
   "source": [
    "print(features_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1068, 2382)\n",
      "(1068, 693)\n"
     ]
    }
   ],
   "source": [
    "x_features = np.asarray(extracted_features)\n",
    "print(x_features.shape)\n",
    "x_features_relevant = np.asarray(features_filtered)\n",
    "print(x_features_relevant.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating the examples into training, validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(801, 693)\n",
      "(267, 693)\n",
      "(801,)\n",
      "(267,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_features_relevant, y_features)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_norm = normalize(x_train)\n",
    "x_test_norm = normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  6 32  4]\n",
      " [ 0  1  3 25  9]\n",
      " [ 1  0 16 22  1]\n",
      " [ 0  0 12 77  6]\n",
      " [ 0  1  1 40 10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        42\n",
      "         1.0       0.50      0.03      0.05        38\n",
      "         2.0       0.42      0.40      0.41        40\n",
      "         3.0       0.39      0.81      0.53        95\n",
      "         4.0       0.33      0.19      0.24        52\n",
      "\n",
      "    accuracy                           0.39       267\n",
      "   macro avg       0.33      0.29      0.25       267\n",
      "weighted avg       0.34      0.39      0.30       267\n",
      "\n",
      "[[ 87   0   0   0   0]\n",
      " [  0  80   0   0   1]\n",
      " [  0   0 169   2   2]\n",
      " [  0   2   1 312   1]\n",
      " [  0   0   1   1 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        87\n",
      "         1.0       0.98      0.99      0.98        81\n",
      "         2.0       0.99      0.98      0.98       173\n",
      "         3.0       0.99      0.99      0.99       316\n",
      "         4.0       0.97      0.99      0.98       144\n",
      "\n",
      "    accuracy                           0.99       801\n",
      "   macro avg       0.99      0.99      0.99       801\n",
      "weighted avg       0.99      0.99      0.99       801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_wt = {0 : 2, 1 : 2, 2 : 2, 3 : 1, 4 : 1}\n",
    "svm_lin = RandomForestClassifier(n_estimators = 100, class_weight = class_wt)\n",
    "svm_lin.fit(x_train_norm, y_train)\n",
    "y_pred = svm_lin.predict(x_test_norm)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_train_norm)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some improvement in accuracy using both all features and only relevant features. But there is still some bias due to the unbalanced classes. So, need to re-try this using the balanced training set. \n",
    "\n",
    "#### Reducing some examples from class 3 (since it has most examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features = list()\n",
    "new_labels = list()\n",
    "for features, label in zip(x_train_norm, y_train) : \n",
    "    if (label == 3) :\n",
    "        if np.random.random() > 0.55 : \n",
    "            new_features.append(features)\n",
    "            new_labels.append(label)\n",
    "    elif (label == 2 or label == 4) :\n",
    "        if np.random.random() < 0.75 : \n",
    "            new_features.append(features)\n",
    "            new_labels.append(label)\n",
    "    else : \n",
    "        new_features.append(features)\n",
    "        new_labels.append(label)\n",
    "\n",
    "x_train_norm = new_features\n",
    "y_train = new_labels\n",
    "\n",
    "new_features = list()\n",
    "new_labels = list()\n",
    "for features, label in zip(x_test_norm, y_test) : \n",
    "    if (label == 3) :\n",
    "        if np.random.random() > 0.5 : \n",
    "            new_features.append(features)\n",
    "            new_labels.append(label)\n",
    "    elif (label == 2 or label == 4) :\n",
    "        if np.random.random() < 0.75 : \n",
    "            new_features.append(features)\n",
    "            new_labels.append(label)\n",
    "    else : \n",
    "        new_features.append(features)\n",
    "        new_labels.append(label)\n",
    "        \n",
    "x_test_norm = new_features\n",
    "y_test = new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(557, 693)\n",
      "(188, 693)\n",
      "(557,)\n",
      "(188,)\n"
     ]
    }
   ],
   "source": [
    "x_train_norm = np.vstack(x_train_norm)\n",
    "x_test_norm = np.vstack(x_test_norm)\n",
    "y_train = np.vstack(y_train)\n",
    "y_train = y_train.ravel()\n",
    "y_test = np.vstack(y_test)\n",
    "y_test = y_test.ravel()\n",
    "print(x_train_norm.shape)\n",
    "print(x_test_norm.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  3  5  7  3]\n",
      " [ 0 13  5  9 10]\n",
      " [ 2  3 25 11  7]\n",
      " [ 4  4 13 20  8]\n",
      " [ 0  3  3  9 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      0.22      0.29        23\n",
      "         1.0       0.50      0.35      0.41        37\n",
      "         2.0       0.49      0.52      0.51        48\n",
      "         3.0       0.36      0.41      0.38        49\n",
      "         4.0       0.36      0.52      0.43        31\n",
      "\n",
      "    accuracy                           0.42       188\n",
      "   macro avg       0.43      0.40      0.40       188\n",
      "weighted avg       0.43      0.42      0.42       188\n",
      "\n",
      "[[105   0   1   0   0]\n",
      " [  0  81   0   0   1]\n",
      " [  0   0 126   0   0]\n",
      " [  0   0   1 131   0]\n",
      " [  0   1   0   0 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       106\n",
      "         1.0       0.99      0.99      0.99        82\n",
      "         2.0       0.98      1.00      0.99       126\n",
      "         3.0       1.00      0.99      1.00       132\n",
      "         4.0       0.99      0.99      0.99       111\n",
      "\n",
      "    accuracy                           0.99       557\n",
      "   macro avg       0.99      0.99      0.99       557\n",
      "weighted avg       0.99      0.99      0.99       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class_wt = {0 : 2, 1 : 2, 2 : 2, 3 : 1, 4 : 2}\n",
    "svm_lin = RandomForestClassifier(n_estimators = 1000, class_weight = None)\n",
    "svm_lin.fit(x_train_norm, y_train)\n",
    "y_pred = svm_lin.predict(x_test_norm)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_train_norm)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
