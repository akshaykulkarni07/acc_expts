{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "from torch.autograd import Variable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128100, 8)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 150\n",
    "channels = 3\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, transform = None):\n",
    "        self.df = pd.read_csv('../../data/train.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.iloc[idx : idx + reqd_len, : channels].values\n",
    "        x = x.astype('float')\n",
    "        x = x.reshape(reqd_len, channels)\n",
    "        assert(x.shape == (reqd_len, channels))\n",
    "        return x\n",
    "        \n",
    "dataset = IMUDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_indices = [(i * reqd_len) for i in range(len(dataset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(dataset, batch_size = batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "trainloader2 = DataLoader(dataset, batch_size = 1, sampler = SubsetRandomSampler(train_indices), drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 150, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb90b778e48>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "signal = next(iter(trainloader2))\n",
    "print(signal.shape)\n",
    "signal = signal.detach().numpy()\n",
    "signal = np.transpose(signal).reshape(-1)\n",
    "t = range(150)\n",
    "plt.plot(t, signal[150 : 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for xavier initialization of network\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "class AutoEncoder(nn.Module) :\n",
    "    def __init__(self) : \n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # defining layers\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 3, out_channels = 2, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels = 2, out_channels = 1, kernel_size = 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels = 1, out_channels = 2, kernel_size = 3),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(in_channels = 2, out_channels = 3, kernel_size = 3),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(146, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 5),\n",
    "            nn.LogSoftmax(dim = 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, encode = False, classify = False) :\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        features = self.encoder(x)\n",
    "        \n",
    "        if encode and not classify:\n",
    "            return features\n",
    "        elif not encode and classify :\n",
    "            features = features.view(-1, 146)\n",
    "            return self.classifier(features)\n",
    "        else : \n",
    "            return self.decoder(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = AutoEncoder()\n",
    "Net.apply(init_weights)\n",
    "if torch.cuda.is_available() : \n",
    "    Net = Net.cuda()\n",
    "    print('Model on GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  106  loss =  0.0831257551908493\n",
      "epoch =  0  step =  20  of total steps  106  loss =  0.07013648748397827\n",
      "epoch =  0  step =  40  of total steps  106  loss =  0.047700412571430206\n",
      "epoch =  0  step =  60  of total steps  106  loss =  0.03370576351881027\n",
      "epoch =  0  step =  80  of total steps  106  loss =  0.03989891707897186\n",
      "epoch =  0  step =  100  of total steps  106  loss =  0.031583286821842194\n",
      "Saving model 0.0491446710174095\n",
      "epoch =  1  step =  0  of total steps  106  loss =  0.023870324715971947\n",
      "epoch =  1  step =  20  of total steps  106  loss =  0.024894848465919495\n",
      "epoch =  1  step =  40  of total steps  106  loss =  0.021613162010908127\n",
      "epoch =  1  step =  60  of total steps  106  loss =  0.022487884387373924\n",
      "epoch =  1  step =  80  of total steps  106  loss =  0.03452196717262268\n",
      "epoch =  1  step =  100  of total steps  106  loss =  0.015771478414535522\n",
      "Saving model 0.02321476935637447\n",
      "epoch =  2  step =  0  of total steps  106  loss =  0.016907991841435432\n",
      "epoch =  2  step =  20  of total steps  106  loss =  0.02384425327181816\n",
      "epoch =  2  step =  40  of total steps  106  loss =  0.011525008827447891\n",
      "epoch =  2  step =  60  of total steps  106  loss =  0.016632677987217903\n",
      "epoch =  2  step =  80  of total steps  106  loss =  0.02018657885491848\n",
      "epoch =  2  step =  100  of total steps  106  loss =  0.021221419796347618\n",
      "Saving model 0.020234892329306534\n",
      "epoch =  3  step =  0  of total steps  106  loss =  0.02062201127409935\n",
      "epoch =  3  step =  20  of total steps  106  loss =  0.023876983672380447\n",
      "epoch =  3  step =  40  of total steps  106  loss =  0.017655864357948303\n",
      "epoch =  3  step =  60  of total steps  106  loss =  0.03039124794304371\n",
      "epoch =  3  step =  80  of total steps  106  loss =  0.023481614887714386\n",
      "epoch =  3  step =  100  of total steps  106  loss =  0.01749563403427601\n",
      "Saving model 0.020202941366664645\n",
      "epoch =  4  step =  0  of total steps  106  loss =  0.014480017125606537\n",
      "epoch =  4  step =  20  of total steps  106  loss =  0.026042671874165535\n",
      "epoch =  4  step =  40  of total steps  106  loss =  0.01895803026854992\n",
      "epoch =  4  step =  60  of total steps  106  loss =  0.023566802963614464\n",
      "epoch =  4  step =  80  of total steps  106  loss =  0.020801188424229622\n",
      "epoch =  4  step =  100  of total steps  106  loss =  0.024144524708390236\n",
      "Saving model 0.020182518868373252\n",
      "epoch =  5  step =  0  of total steps  106  loss =  0.017926976084709167\n",
      "epoch =  5  step =  20  of total steps  106  loss =  0.020706554874777794\n",
      "epoch =  5  step =  40  of total steps  106  loss =  0.01023621391505003\n",
      "epoch =  5  step =  60  of total steps  106  loss =  0.016918156296014786\n",
      "epoch =  5  step =  80  of total steps  106  loss =  0.019368667155504227\n",
      "epoch =  5  step =  100  of total steps  106  loss =  0.017081068828701973\n",
      "Saving model 0.020141319749560557\n",
      "epoch =  6  step =  0  of total steps  106  loss =  0.011210796423256397\n",
      "epoch =  6  step =  20  of total steps  106  loss =  0.029786160215735435\n",
      "epoch =  6  step =  40  of total steps  106  loss =  0.02079363353550434\n",
      "epoch =  6  step =  60  of total steps  106  loss =  0.018794989213347435\n",
      "epoch =  6  step =  80  of total steps  106  loss =  0.026518359780311584\n",
      "epoch =  6  step =  100  of total steps  106  loss =  0.03437105566263199\n",
      "epoch =  7  step =  0  of total steps  106  loss =  0.013399933464825153\n",
      "epoch =  7  step =  20  of total steps  106  loss =  0.021601587533950806\n",
      "epoch =  7  step =  40  of total steps  106  loss =  0.02478092722594738\n",
      "epoch =  7  step =  60  of total steps  106  loss =  0.013758770190179348\n",
      "epoch =  7  step =  80  of total steps  106  loss =  0.01663324236869812\n",
      "epoch =  7  step =  100  of total steps  106  loss =  0.024577658623456955\n",
      "epoch =  8  step =  0  of total steps  106  loss =  0.015373492613434792\n",
      "epoch =  8  step =  20  of total steps  106  loss =  0.0233907550573349\n",
      "epoch =  8  step =  40  of total steps  106  loss =  0.019577598199248314\n",
      "epoch =  8  step =  60  of total steps  106  loss =  0.01681174896657467\n",
      "epoch =  8  step =  80  of total steps  106  loss =  0.019033093005418777\n",
      "epoch =  8  step =  100  of total steps  106  loss =  0.03225381672382355\n",
      "epoch =  9  step =  0  of total steps  106  loss =  0.03097955696284771\n",
      "epoch =  9  step =  20  of total steps  106  loss =  0.02228364162147045\n",
      "epoch =  9  step =  40  of total steps  106  loss =  0.02233968675136566\n",
      "epoch =  9  step =  60  of total steps  106  loss =  0.01671816222369671\n",
      "epoch =  9  step =  80  of total steps  106  loss =  0.03534409776329994\n",
      "epoch =  9  step =  100  of total steps  106  loss =  0.018720760941505432\n",
      "epoch =  10  step =  0  of total steps  106  loss =  0.018917204812169075\n",
      "epoch =  10  step =  20  of total steps  106  loss =  0.016183603554964066\n",
      "epoch =  10  step =  40  of total steps  106  loss =  0.015784861519932747\n",
      "epoch =  10  step =  60  of total steps  106  loss =  0.022840021178126335\n",
      "epoch =  10  step =  80  of total steps  106  loss =  0.029432158917188644\n",
      "epoch =  10  step =  100  of total steps  106  loss =  0.017618518322706223\n",
      "Saving model 0.02002981204082662\n",
      "epoch =  11  step =  0  of total steps  106  loss =  0.019255438819527626\n",
      "epoch =  11  step =  20  of total steps  106  loss =  0.025304017588496208\n",
      "epoch =  11  step =  40  of total steps  106  loss =  0.02955668419599533\n",
      "epoch =  11  step =  60  of total steps  106  loss =  0.03267177566885948\n",
      "epoch =  11  step =  80  of total steps  106  loss =  0.02827620320022106\n",
      "epoch =  11  step =  100  of total steps  106  loss =  0.01325917523354292\n",
      "epoch =  12  step =  0  of total steps  106  loss =  0.016945764422416687\n",
      "epoch =  12  step =  20  of total steps  106  loss =  0.018824465572834015\n",
      "epoch =  12  step =  40  of total steps  106  loss =  0.018258290365338326\n",
      "epoch =  12  step =  60  of total steps  106  loss =  0.013149702921509743\n",
      "epoch =  12  step =  80  of total steps  106  loss =  0.012826317921280861\n",
      "epoch =  12  step =  100  of total steps  106  loss =  0.01819702610373497\n",
      "epoch =  13  step =  0  of total steps  106  loss =  0.01786811649799347\n",
      "epoch =  13  step =  20  of total steps  106  loss =  0.02847355604171753\n",
      "epoch =  13  step =  40  of total steps  106  loss =  0.027771420776844025\n",
      "epoch =  13  step =  60  of total steps  106  loss =  0.01966884545981884\n",
      "epoch =  13  step =  80  of total steps  106  loss =  0.03184233978390694\n",
      "epoch =  13  step =  100  of total steps  106  loss =  0.027116287499666214\n",
      "epoch =  14  step =  0  of total steps  106  loss =  0.02423654869198799\n",
      "epoch =  14  step =  20  of total steps  106  loss =  0.02496984973549843\n",
      "epoch =  14  step =  40  of total steps  106  loss =  0.017297929152846336\n",
      "epoch =  14  step =  60  of total steps  106  loss =  0.026677219197154045\n",
      "epoch =  14  step =  80  of total steps  106  loss =  0.016749318689107895\n",
      "epoch =  14  step =  100  of total steps  106  loss =  0.013013654388487339\n",
      "epoch =  15  step =  0  of total steps  106  loss =  0.02298295684158802\n",
      "epoch =  15  step =  20  of total steps  106  loss =  0.01384385209530592\n",
      "epoch =  15  step =  40  of total steps  106  loss =  0.01877814717590809\n",
      "epoch =  15  step =  60  of total steps  106  loss =  0.024516526609659195\n",
      "epoch =  15  step =  80  of total steps  106  loss =  0.019347473978996277\n",
      "epoch =  15  step =  100  of total steps  106  loss =  0.01720736362040043\n",
      "epoch =  16  step =  0  of total steps  106  loss =  0.022525407373905182\n",
      "epoch =  16  step =  20  of total steps  106  loss =  0.020757446065545082\n",
      "epoch =  16  step =  40  of total steps  106  loss =  0.027916228398680687\n",
      "epoch =  16  step =  60  of total steps  106  loss =  0.01757480576634407\n",
      "epoch =  16  step =  80  of total steps  106  loss =  0.01853168196976185\n",
      "epoch =  16  step =  100  of total steps  106  loss =  0.014904235489666462\n",
      "epoch =  17  step =  0  of total steps  106  loss =  0.013898405246436596\n",
      "epoch =  17  step =  20  of total steps  106  loss =  0.022392814978957176\n",
      "epoch =  17  step =  40  of total steps  106  loss =  0.024785256013274193\n",
      "epoch =  17  step =  60  of total steps  106  loss =  0.022579530254006386\n",
      "epoch =  17  step =  80  of total steps  106  loss =  0.008074110373854637\n",
      "epoch =  17  step =  100  of total steps  106  loss =  0.01716381125152111\n",
      "epoch =  18  step =  0  of total steps  106  loss =  0.022041920572519302\n",
      "epoch =  18  step =  20  of total steps  106  loss =  0.020779764279723167\n",
      "epoch =  18  step =  40  of total steps  106  loss =  0.027268240228295326\n",
      "epoch =  18  step =  60  of total steps  106  loss =  0.014637250453233719\n",
      "epoch =  18  step =  80  of total steps  106  loss =  0.020137760788202286\n",
      "epoch =  18  step =  100  of total steps  106  loss =  0.01642618328332901\n",
      "Saving model 0.019991236378632066\n",
      "epoch =  19  step =  0  of total steps  106  loss =  0.0182297732681036\n",
      "epoch =  19  step =  20  of total steps  106  loss =  0.013361879624426365\n",
      "epoch =  19  step =  40  of total steps  106  loss =  0.01585882529616356\n",
      "epoch =  19  step =  60  of total steps  106  loss =  0.021146554499864578\n",
      "epoch =  19  step =  80  of total steps  106  loss =  0.024106435477733612\n",
      "epoch =  19  step =  100  of total steps  106  loss =  0.016765063628554344\n",
      "epoch =  20  step =  0  of total steps  106  loss =  0.02124130167067051\n",
      "epoch =  20  step =  20  of total steps  106  loss =  0.015683593228459358\n",
      "epoch =  20  step =  40  of total steps  106  loss =  0.02437693066895008\n",
      "epoch =  20  step =  60  of total steps  106  loss =  0.02996527962386608\n",
      "epoch =  20  step =  80  of total steps  106  loss =  0.016695210710167885\n",
      "epoch =  20  step =  100  of total steps  106  loss =  0.023792210966348648\n",
      "Saving model 0.019988494828554255\n",
      "epoch =  21  step =  0  of total steps  106  loss =  0.010462729260325432\n",
      "epoch =  21  step =  20  of total steps  106  loss =  0.03528795763850212\n",
      "epoch =  21  step =  40  of total steps  106  loss =  0.011227112263441086\n",
      "epoch =  21  step =  60  of total steps  106  loss =  0.025766557082533836\n",
      "epoch =  21  step =  80  of total steps  106  loss =  0.018717430531978607\n",
      "epoch =  21  step =  100  of total steps  106  loss =  0.015498671680688858\n",
      "Saving model 0.019941518250149937\n",
      "epoch =  22  step =  0  of total steps  106  loss =  0.021622296422719955\n",
      "epoch =  22  step =  20  of total steps  106  loss =  0.024729494005441666\n",
      "epoch =  22  step =  40  of total steps  106  loss =  0.01493895798921585\n",
      "epoch =  22  step =  60  of total steps  106  loss =  0.019315043464303017\n",
      "epoch =  22  step =  80  of total steps  106  loss =  0.02265050634741783\n",
      "epoch =  22  step =  100  of total steps  106  loss =  0.027357758954167366\n",
      "epoch =  23  step =  0  of total steps  106  loss =  0.02519167959690094\n",
      "epoch =  23  step =  20  of total steps  106  loss =  0.025783469900488853\n",
      "epoch =  23  step =  40  of total steps  106  loss =  0.020280824974179268\n",
      "epoch =  23  step =  60  of total steps  106  loss =  0.016467124223709106\n",
      "epoch =  23  step =  80  of total steps  106  loss =  0.019367199391126633\n",
      "epoch =  23  step =  100  of total steps  106  loss =  0.022427359595894814\n",
      "epoch =  24  step =  0  of total steps  106  loss =  0.0250299870967865\n",
      "epoch =  24  step =  20  of total steps  106  loss =  0.019630203023552895\n",
      "epoch =  24  step =  40  of total steps  106  loss =  0.015591331757605076\n",
      "epoch =  24  step =  60  of total steps  106  loss =  0.020505454391241074\n",
      "epoch =  24  step =  80  of total steps  106  loss =  0.024756692349910736\n",
      "epoch =  24  step =  100  of total steps  106  loss =  0.025745339691638947\n",
      "epoch =  25  step =  0  of total steps  106  loss =  0.025058940052986145\n",
      "epoch =  25  step =  20  of total steps  106  loss =  0.024671321734786034\n",
      "epoch =  25  step =  40  of total steps  106  loss =  0.017793899402022362\n",
      "epoch =  25  step =  60  of total steps  106  loss =  0.014542890712618828\n",
      "epoch =  25  step =  80  of total steps  106  loss =  0.014702395536005497\n",
      "epoch =  25  step =  100  of total steps  106  loss =  0.02099011279642582\n",
      "epoch =  26  step =  0  of total steps  106  loss =  0.022649463266134262\n",
      "epoch =  26  step =  20  of total steps  106  loss =  0.018136175349354744\n",
      "epoch =  26  step =  40  of total steps  106  loss =  0.00620662048459053\n",
      "epoch =  26  step =  60  of total steps  106  loss =  0.024814747273921967\n",
      "epoch =  26  step =  80  of total steps  106  loss =  0.02366427518427372\n",
      "epoch =  26  step =  100  of total steps  106  loss =  0.01722993142902851\n",
      "epoch =  27  step =  0  of total steps  106  loss =  0.022689230740070343\n",
      "epoch =  27  step =  20  of total steps  106  loss =  0.019824819639325142\n",
      "epoch =  27  step =  40  of total steps  106  loss =  0.014212762005627155\n",
      "epoch =  27  step =  60  of total steps  106  loss =  0.026249947026371956\n",
      "epoch =  27  step =  80  of total steps  106  loss =  0.01413055695593357\n",
      "epoch =  27  step =  100  of total steps  106  loss =  0.019208209589123726\n",
      "epoch =  28  step =  0  of total steps  106  loss =  0.017380084842443466\n",
      "epoch =  28  step =  20  of total steps  106  loss =  0.011410144157707691\n",
      "epoch =  28  step =  40  of total steps  106  loss =  0.02345919981598854\n",
      "epoch =  28  step =  60  of total steps  106  loss =  0.02494731731712818\n",
      "epoch =  28  step =  80  of total steps  106  loss =  0.022451402619481087\n",
      "epoch =  28  step =  100  of total steps  106  loss =  0.017877787351608276\n",
      "Saving model 0.01992861017637517\n",
      "epoch =  29  step =  0  of total steps  106  loss =  0.022398466244339943\n",
      "epoch =  29  step =  20  of total steps  106  loss =  0.02882583625614643\n",
      "epoch =  29  step =  40  of total steps  106  loss =  0.006615696009248495\n",
      "epoch =  29  step =  60  of total steps  106  loss =  0.032459791749715805\n",
      "epoch =  29  step =  80  of total steps  106  loss =  0.016810541972517967\n",
      "epoch =  29  step =  100  of total steps  106  loss =  0.010914941318333149\n",
      "epoch =  30  step =  0  of total steps  106  loss =  0.023530228063464165\n",
      "epoch =  30  step =  20  of total steps  106  loss =  0.0247185155749321\n",
      "epoch =  30  step =  40  of total steps  106  loss =  0.016668660566210747\n",
      "epoch =  30  step =  60  of total steps  106  loss =  0.020816151052713394\n",
      "epoch =  30  step =  80  of total steps  106  loss =  0.018073800951242447\n",
      "epoch =  30  step =  100  of total steps  106  loss =  0.014305602759122849\n",
      "epoch =  31  step =  0  of total steps  106  loss =  0.014134849421679974\n",
      "epoch =  31  step =  20  of total steps  106  loss =  0.015867086127400398\n",
      "epoch =  31  step =  40  of total steps  106  loss =  0.016395775601267815\n",
      "epoch =  31  step =  60  of total steps  106  loss =  0.013110940344631672\n",
      "epoch =  31  step =  80  of total steps  106  loss =  0.024859542027115822\n",
      "epoch =  31  step =  100  of total steps  106  loss =  0.013525562360882759\n",
      "epoch =  32  step =  0  of total steps  106  loss =  0.015045388601720333\n",
      "epoch =  32  step =  20  of total steps  106  loss =  0.010598297230899334\n",
      "epoch =  32  step =  40  of total steps  106  loss =  0.01577969454228878\n",
      "epoch =  32  step =  60  of total steps  106  loss =  0.009875576943159103\n",
      "epoch =  32  step =  80  of total steps  106  loss =  0.01878158003091812\n",
      "epoch =  32  step =  100  of total steps  106  loss =  0.018013395369052887\n",
      "Saving model 0.01991569415121427\n",
      "epoch =  33  step =  0  of total steps  106  loss =  0.016283078119158745\n",
      "epoch =  33  step =  20  of total steps  106  loss =  0.023615572601556778\n",
      "epoch =  33  step =  40  of total steps  106  loss =  0.021934453397989273\n",
      "epoch =  33  step =  60  of total steps  106  loss =  0.014745818451046944\n",
      "epoch =  33  step =  80  of total steps  106  loss =  0.017090609297156334\n",
      "epoch =  33  step =  100  of total steps  106  loss =  0.023899096995592117\n",
      "epoch =  34  step =  0  of total steps  106  loss =  0.02459043823182583\n",
      "epoch =  34  step =  20  of total steps  106  loss =  0.01427876390516758\n",
      "epoch =  34  step =  40  of total steps  106  loss =  0.02383510209619999\n",
      "epoch =  34  step =  60  of total steps  106  loss =  0.014833076857030392\n",
      "epoch =  34  step =  80  of total steps  106  loss =  0.01963701844215393\n",
      "epoch =  34  step =  100  of total steps  106  loss =  0.02258492261171341\n",
      "epoch =  35  step =  0  of total steps  106  loss =  0.023313259705901146\n",
      "epoch =  35  step =  20  of total steps  106  loss =  0.02298763208091259\n",
      "epoch =  35  step =  40  of total steps  106  loss =  0.019764017313718796\n",
      "epoch =  35  step =  60  of total steps  106  loss =  0.021449660882353783\n",
      "epoch =  35  step =  80  of total steps  106  loss =  0.01900273747742176\n",
      "epoch =  35  step =  100  of total steps  106  loss =  0.019879501312971115\n",
      "epoch =  36  step =  0  of total steps  106  loss =  0.023999443277716637\n",
      "epoch =  36  step =  20  of total steps  106  loss =  0.015929028391838074\n",
      "epoch =  36  step =  40  of total steps  106  loss =  0.0126796280965209\n",
      "epoch =  36  step =  60  of total steps  106  loss =  0.018450584262609482\n",
      "epoch =  36  step =  80  of total steps  106  loss =  0.01571143977344036\n",
      "epoch =  36  step =  100  of total steps  106  loss =  0.027727359905838966\n",
      "epoch =  37  step =  0  of total steps  106  loss =  0.023231809958815575\n",
      "epoch =  37  step =  20  of total steps  106  loss =  0.022392235696315765\n",
      "epoch =  37  step =  40  of total steps  106  loss =  0.022174077108502388\n",
      "epoch =  37  step =  60  of total steps  106  loss =  0.010041982866823673\n",
      "epoch =  37  step =  80  of total steps  106  loss =  0.013232638128101826\n",
      "epoch =  37  step =  100  of total steps  106  loss =  0.02842131443321705\n",
      "epoch =  38  step =  0  of total steps  106  loss =  0.034913867712020874\n",
      "epoch =  38  step =  20  of total steps  106  loss =  0.02876315265893936\n",
      "epoch =  38  step =  40  of total steps  106  loss =  0.020045312121510506\n",
      "epoch =  38  step =  60  of total steps  106  loss =  0.010556678287684917\n",
      "epoch =  38  step =  80  of total steps  106  loss =  0.01531368587166071\n",
      "epoch =  38  step =  100  of total steps  106  loss =  0.016550282016396523\n",
      "epoch =  39  step =  0  of total steps  106  loss =  0.02846207655966282\n",
      "epoch =  39  step =  20  of total steps  106  loss =  0.019419852644205093\n",
      "epoch =  39  step =  40  of total steps  106  loss =  0.02182094193994999\n",
      "epoch =  39  step =  60  of total steps  106  loss =  0.025732722133398056\n",
      "epoch =  39  step =  80  of total steps  106  loss =  0.020883973687887192\n",
      "epoch =  39  step =  100  of total steps  106  loss =  0.01383218914270401\n",
      "epoch =  40  step =  0  of total steps  106  loss =  0.016214927658438683\n",
      "epoch =  40  step =  20  of total steps  106  loss =  0.018031595274806023\n",
      "epoch =  40  step =  40  of total steps  106  loss =  0.01130190584808588\n",
      "epoch =  40  step =  60  of total steps  106  loss =  0.015356611460447311\n",
      "epoch =  40  step =  80  of total steps  106  loss =  0.02872534655034542\n",
      "epoch =  40  step =  100  of total steps  106  loss =  0.018693407997488976\n",
      "Saving model 0.019836113621252326\n",
      "epoch =  41  step =  0  of total steps  106  loss =  0.019034020602703094\n",
      "epoch =  41  step =  20  of total steps  106  loss =  0.020483409985899925\n",
      "epoch =  41  step =  40  of total steps  106  loss =  0.019075555726885796\n",
      "epoch =  41  step =  60  of total steps  106  loss =  0.015051216818392277\n",
      "epoch =  41  step =  80  of total steps  106  loss =  0.016672395169734955\n",
      "epoch =  41  step =  100  of total steps  106  loss =  0.023760100826621056\n",
      "epoch =  42  step =  0  of total steps  106  loss =  0.017793504521250725\n",
      "epoch =  42  step =  20  of total steps  106  loss =  0.020827271044254303\n",
      "epoch =  42  step =  40  of total steps  106  loss =  0.015542298555374146\n",
      "epoch =  42  step =  60  of total steps  106  loss =  0.025057394057512283\n",
      "epoch =  42  step =  80  of total steps  106  loss =  0.01902383752167225\n",
      "epoch =  42  step =  100  of total steps  106  loss =  0.025892503559589386\n",
      "epoch =  43  step =  0  of total steps  106  loss =  0.02949250116944313\n",
      "epoch =  43  step =  20  of total steps  106  loss =  0.017836494371294975\n",
      "epoch =  43  step =  40  of total steps  106  loss =  0.028810109943151474\n",
      "epoch =  43  step =  60  of total steps  106  loss =  0.017687657848000526\n",
      "epoch =  43  step =  80  of total steps  106  loss =  0.034025125205516815\n",
      "epoch =  43  step =  100  of total steps  106  loss =  0.03291969373822212\n",
      "epoch =  44  step =  0  of total steps  106  loss =  0.016872946172952652\n",
      "epoch =  44  step =  20  of total steps  106  loss =  0.014314928092062473\n",
      "epoch =  44  step =  40  of total steps  106  loss =  0.015807565301656723\n",
      "epoch =  44  step =  60  of total steps  106  loss =  0.02593599632382393\n",
      "epoch =  44  step =  80  of total steps  106  loss =  0.022677624598145485\n",
      "epoch =  44  step =  100  of total steps  106  loss =  0.027111083269119263\n",
      "epoch =  45  step =  0  of total steps  106  loss =  0.029705598950386047\n",
      "epoch =  45  step =  20  of total steps  106  loss =  0.012730518355965614\n",
      "epoch =  45  step =  40  of total steps  106  loss =  0.022294463589787483\n",
      "epoch =  45  step =  60  of total steps  106  loss =  0.02578960545361042\n",
      "epoch =  45  step =  80  of total steps  106  loss =  0.014781726524233818\n",
      "epoch =  45  step =  100  of total steps  106  loss =  0.02072189375758171\n",
      "epoch =  46  step =  0  of total steps  106  loss =  0.01790471188724041\n",
      "epoch =  46  step =  20  of total steps  106  loss =  0.021319610998034477\n",
      "epoch =  46  step =  40  of total steps  106  loss =  0.022509010508656502\n",
      "epoch =  46  step =  60  of total steps  106  loss =  0.022848324850201607\n",
      "epoch =  46  step =  80  of total steps  106  loss =  0.01229935698211193\n",
      "epoch =  46  step =  100  of total steps  106  loss =  0.013835473917424679\n",
      "epoch =  47  step =  0  of total steps  106  loss =  0.019003475084900856\n",
      "epoch =  47  step =  20  of total steps  106  loss =  0.024391692131757736\n",
      "epoch =  47  step =  40  of total steps  106  loss =  0.013323197141289711\n",
      "epoch =  47  step =  60  of total steps  106  loss =  0.018596183508634567\n",
      "epoch =  47  step =  80  of total steps  106  loss =  0.025321301072835922\n",
      "epoch =  47  step =  100  of total steps  106  loss =  0.027423912659287453\n",
      "epoch =  48  step =  0  of total steps  106  loss =  0.018608083948493004\n",
      "epoch =  48  step =  20  of total steps  106  loss =  0.01645147055387497\n",
      "epoch =  48  step =  40  of total steps  106  loss =  0.02142864651978016\n",
      "epoch =  48  step =  60  of total steps  106  loss =  0.01712159626185894\n",
      "epoch =  48  step =  80  of total steps  106  loss =  0.024445513263344765\n",
      "epoch =  48  step =  100  of total steps  106  loss =  0.012680049054324627\n",
      "epoch =  49  step =  0  of total steps  106  loss =  0.017539912834763527\n",
      "epoch =  49  step =  20  of total steps  106  loss =  0.02332804910838604\n",
      "epoch =  49  step =  40  of total steps  106  loss =  0.030464978888630867\n",
      "epoch =  49  step =  60  of total steps  106  loss =  0.030035335570573807\n",
      "epoch =  49  step =  80  of total steps  106  loss =  0.024628929793834686\n",
      "epoch =  49  step =  100  of total steps  106  loss =  0.031182194128632545\n",
      "epoch =  50  step =  0  of total steps  106  loss =  0.020506711676716805\n",
      "epoch =  50  step =  20  of total steps  106  loss =  0.02133842557668686\n",
      "epoch =  50  step =  40  of total steps  106  loss =  0.014833305031061172\n",
      "epoch =  50  step =  60  of total steps  106  loss =  0.020168866962194443\n",
      "epoch =  50  step =  80  of total steps  106  loss =  0.024356571957468987\n",
      "epoch =  50  step =  100  of total steps  106  loss =  0.014986060559749603\n",
      "epoch =  51  step =  0  of total steps  106  loss =  0.01798764243721962\n",
      "epoch =  51  step =  20  of total steps  106  loss =  0.020612424239516258\n",
      "epoch =  51  step =  40  of total steps  106  loss =  0.023180637508630753\n",
      "epoch =  51  step =  60  of total steps  106  loss =  0.01607576012611389\n",
      "epoch =  51  step =  80  of total steps  106  loss =  0.02578313834965229\n",
      "epoch =  51  step =  100  of total steps  106  loss =  0.022717751562595367\n",
      "epoch =  52  step =  0  of total steps  106  loss =  0.011696000583469868\n",
      "epoch =  52  step =  20  of total steps  106  loss =  0.018275029957294464\n",
      "epoch =  52  step =  40  of total steps  106  loss =  0.027216888964176178\n",
      "epoch =  52  step =  60  of total steps  106  loss =  0.02472827583551407\n",
      "epoch =  52  step =  80  of total steps  106  loss =  0.02306089550256729\n",
      "epoch =  52  step =  100  of total steps  106  loss =  0.01786952279508114\n",
      "epoch =  53  step =  0  of total steps  106  loss =  0.01390848122537136\n",
      "epoch =  53  step =  20  of total steps  106  loss =  0.019542688503861427\n",
      "epoch =  53  step =  40  of total steps  106  loss =  0.03034786507487297\n",
      "epoch =  53  step =  60  of total steps  106  loss =  0.023475198075175285\n",
      "epoch =  53  step =  80  of total steps  106  loss =  0.01979672536253929\n",
      "epoch =  53  step =  100  of total steps  106  loss =  0.019426750019192696\n",
      "epoch =  54  step =  0  of total steps  106  loss =  0.01779368333518505\n",
      "epoch =  54  step =  20  of total steps  106  loss =  0.01009321864694357\n",
      "epoch =  54  step =  40  of total steps  106  loss =  0.022882482036948204\n",
      "epoch =  54  step =  60  of total steps  106  loss =  0.023927194997668266\n",
      "epoch =  54  step =  80  of total steps  106  loss =  0.02612285502254963\n",
      "epoch =  54  step =  100  of total steps  106  loss =  0.020438626408576965\n",
      "epoch =  55  step =  0  of total steps  106  loss =  0.011670387350022793\n",
      "epoch =  55  step =  20  of total steps  106  loss =  0.025691553950309753\n",
      "epoch =  55  step =  40  of total steps  106  loss =  0.016124878078699112\n",
      "epoch =  55  step =  60  of total steps  106  loss =  0.015399094671010971\n",
      "epoch =  55  step =  80  of total steps  106  loss =  0.023009730502963066\n",
      "epoch =  55  step =  100  of total steps  106  loss =  0.032007813453674316\n",
      "epoch =  56  step =  0  of total steps  106  loss =  0.02796756848692894\n",
      "epoch =  56  step =  20  of total steps  106  loss =  0.014723428525030613\n",
      "epoch =  56  step =  40  of total steps  106  loss =  0.016008514910936356\n",
      "epoch =  56  step =  60  of total steps  106  loss =  0.021847611293196678\n",
      "epoch =  56  step =  80  of total steps  106  loss =  0.018461672589182854\n",
      "epoch =  56  step =  100  of total steps  106  loss =  0.015153704211115837\n",
      "epoch =  57  step =  0  of total steps  106  loss =  0.023956138640642166\n",
      "epoch =  57  step =  20  of total steps  106  loss =  0.013644266873598099\n",
      "epoch =  57  step =  40  of total steps  106  loss =  0.010980179533362389\n",
      "epoch =  57  step =  60  of total steps  106  loss =  0.021640349179506302\n",
      "epoch =  57  step =  80  of total steps  106  loss =  0.01893661543726921\n",
      "epoch =  57  step =  100  of total steps  106  loss =  0.01733217015862465\n",
      "epoch =  58  step =  0  of total steps  106  loss =  0.015317566692829132\n",
      "epoch =  58  step =  20  of total steps  106  loss =  0.014866545796394348\n",
      "epoch =  58  step =  40  of total steps  106  loss =  0.019673919305205345\n",
      "epoch =  58  step =  60  of total steps  106  loss =  0.01766526699066162\n",
      "epoch =  58  step =  80  of total steps  106  loss =  0.02166728489100933\n",
      "epoch =  58  step =  100  of total steps  106  loss =  0.013052727095782757\n",
      "Saving model 0.019801368234011362\n",
      "epoch =  59  step =  0  of total steps  106  loss =  0.01705758087337017\n",
      "epoch =  59  step =  20  of total steps  106  loss =  0.022716717794537544\n",
      "epoch =  59  step =  40  of total steps  106  loss =  0.016839077696204185\n",
      "epoch =  59  step =  60  of total steps  106  loss =  0.011773213744163513\n",
      "epoch =  59  step =  80  of total steps  106  loss =  0.013795281760394573\n",
      "epoch =  59  step =  100  of total steps  106  loss =  0.022886015474796295\n",
      "epoch =  60  step =  0  of total steps  106  loss =  0.022627267986536026\n",
      "epoch =  60  step =  20  of total steps  106  loss =  0.014871489256620407\n",
      "epoch =  60  step =  40  of total steps  106  loss =  0.0293367151170969\n",
      "epoch =  60  step =  60  of total steps  106  loss =  0.016433343291282654\n",
      "epoch =  60  step =  80  of total steps  106  loss =  0.02283559739589691\n",
      "epoch =  60  step =  100  of total steps  106  loss =  0.017842013388872147\n",
      "Saving model 0.0197131243086297\n",
      "epoch =  61  step =  0  of total steps  106  loss =  0.013184464536607265\n",
      "epoch =  61  step =  20  of total steps  106  loss =  0.010118546895682812\n",
      "epoch =  61  step =  40  of total steps  106  loss =  0.021652651950716972\n",
      "epoch =  61  step =  60  of total steps  106  loss =  0.022688332945108414\n",
      "epoch =  61  step =  80  of total steps  106  loss =  0.01795087195932865\n",
      "epoch =  61  step =  100  of total steps  106  loss =  0.010154057294130325\n",
      "epoch =  62  step =  0  of total steps  106  loss =  0.02172756753861904\n",
      "epoch =  62  step =  20  of total steps  106  loss =  0.017031801864504814\n",
      "epoch =  62  step =  40  of total steps  106  loss =  0.01517261192202568\n",
      "epoch =  62  step =  60  of total steps  106  loss =  0.016886744648218155\n",
      "epoch =  62  step =  80  of total steps  106  loss =  0.013972263783216476\n",
      "epoch =  62  step =  100  of total steps  106  loss =  0.017582036554813385\n",
      "epoch =  63  step =  0  of total steps  106  loss =  0.0200334582477808\n",
      "epoch =  63  step =  20  of total steps  106  loss =  0.014994089491665363\n",
      "epoch =  63  step =  40  of total steps  106  loss =  0.02381993643939495\n",
      "epoch =  63  step =  60  of total steps  106  loss =  0.025139177218079567\n",
      "epoch =  63  step =  80  of total steps  106  loss =  0.009139010682702065\n",
      "epoch =  63  step =  100  of total steps  106  loss =  0.01576882041990757\n",
      "epoch =  64  step =  0  of total steps  106  loss =  0.02025381289422512\n",
      "epoch =  64  step =  20  of total steps  106  loss =  0.02129632607102394\n",
      "epoch =  64  step =  40  of total steps  106  loss =  0.01258130557835102\n",
      "epoch =  64  step =  60  of total steps  106  loss =  0.020524777472019196\n",
      "epoch =  64  step =  80  of total steps  106  loss =  0.019266804680228233\n",
      "epoch =  64  step =  100  of total steps  106  loss =  0.02768584154546261\n",
      "epoch =  65  step =  0  of total steps  106  loss =  0.018211521208286285\n",
      "epoch =  65  step =  20  of total steps  106  loss =  0.021202433854341507\n",
      "epoch =  65  step =  40  of total steps  106  loss =  0.015540159307420254\n",
      "epoch =  65  step =  60  of total steps  106  loss =  0.023247767239809036\n",
      "epoch =  65  step =  80  of total steps  106  loss =  0.01675724983215332\n",
      "epoch =  65  step =  100  of total steps  106  loss =  0.017046287655830383\n",
      "epoch =  66  step =  0  of total steps  106  loss =  0.030430447310209274\n",
      "epoch =  66  step =  20  of total steps  106  loss =  0.020714623853564262\n",
      "epoch =  66  step =  40  of total steps  106  loss =  0.013369981199502945\n",
      "epoch =  66  step =  60  of total steps  106  loss =  0.014373619109392166\n",
      "epoch =  66  step =  80  of total steps  106  loss =  0.028046678751707077\n",
      "epoch =  66  step =  100  of total steps  106  loss =  0.02484084479510784\n",
      "epoch =  67  step =  0  of total steps  106  loss =  0.02936534956097603\n",
      "epoch =  67  step =  20  of total steps  106  loss =  0.012775593437254429\n",
      "epoch =  67  step =  40  of total steps  106  loss =  0.02498060092329979\n",
      "epoch =  67  step =  60  of total steps  106  loss =  0.018559573218226433\n",
      "epoch =  67  step =  80  of total steps  106  loss =  0.010558659210801125\n",
      "epoch =  67  step =  100  of total steps  106  loss =  0.019370533525943756\n",
      "epoch =  68  step =  0  of total steps  106  loss =  0.01866738311946392\n",
      "epoch =  68  step =  20  of total steps  106  loss =  0.012451214715838432\n",
      "epoch =  68  step =  40  of total steps  106  loss =  0.016506610438227654\n",
      "epoch =  68  step =  60  of total steps  106  loss =  0.025527631863951683\n",
      "epoch =  68  step =  80  of total steps  106  loss =  0.014708264730870724\n",
      "epoch =  68  step =  100  of total steps  106  loss =  0.027950001880526543\n",
      "epoch =  69  step =  0  of total steps  106  loss =  0.016006523743271828\n",
      "epoch =  69  step =  20  of total steps  106  loss =  0.02413579262793064\n",
      "epoch =  69  step =  40  of total steps  106  loss =  0.03071836195886135\n",
      "epoch =  69  step =  60  of total steps  106  loss =  0.025473428890109062\n",
      "epoch =  69  step =  80  of total steps  106  loss =  0.019491270184516907\n",
      "epoch =  69  step =  100  of total steps  106  loss =  0.010787395760416985\n",
      "epoch =  70  step =  0  of total steps  106  loss =  0.014864846132695675\n",
      "epoch =  70  step =  20  of total steps  106  loss =  0.018123039975762367\n",
      "epoch =  70  step =  40  of total steps  106  loss =  0.03104519471526146\n",
      "epoch =  70  step =  60  of total steps  106  loss =  0.011830626055598259\n",
      "epoch =  70  step =  80  of total steps  106  loss =  0.012676162645220757\n",
      "epoch =  70  step =  100  of total steps  106  loss =  0.02414119802415371\n",
      "epoch =  71  step =  0  of total steps  106  loss =  0.023457160219550133\n",
      "epoch =  71  step =  20  of total steps  106  loss =  0.015012186951935291\n",
      "epoch =  71  step =  40  of total steps  106  loss =  0.014130497351288795\n",
      "epoch =  71  step =  60  of total steps  106  loss =  0.01977580599486828\n",
      "epoch =  71  step =  80  of total steps  106  loss =  0.018256546929478645\n",
      "epoch =  71  step =  100  of total steps  106  loss =  0.021601440384984016\n",
      "epoch =  72  step =  0  of total steps  106  loss =  0.013425817713141441\n",
      "epoch =  72  step =  20  of total steps  106  loss =  0.013717884197831154\n",
      "epoch =  72  step =  40  of total steps  106  loss =  0.02113460935652256\n",
      "epoch =  72  step =  60  of total steps  106  loss =  0.017651360481977463\n",
      "epoch =  72  step =  80  of total steps  106  loss =  0.0238120686262846\n",
      "epoch =  72  step =  100  of total steps  106  loss =  0.017263449728488922\n",
      "epoch =  73  step =  0  of total steps  106  loss =  0.024306414648890495\n",
      "epoch =  73  step =  20  of total steps  106  loss =  0.018856391310691833\n",
      "epoch =  73  step =  40  of total steps  106  loss =  0.015012804418802261\n",
      "epoch =  73  step =  60  of total steps  106  loss =  0.02806098572909832\n",
      "epoch =  73  step =  80  of total steps  106  loss =  0.014459014870226383\n",
      "epoch =  73  step =  100  of total steps  106  loss =  0.022943174466490746\n",
      "epoch =  74  step =  0  of total steps  106  loss =  0.008775531314313412\n",
      "epoch =  74  step =  20  of total steps  106  loss =  0.021591031923890114\n",
      "epoch =  74  step =  40  of total steps  106  loss =  0.031936660408973694\n",
      "epoch =  74  step =  60  of total steps  106  loss =  0.013057232834398746\n",
      "epoch =  74  step =  80  of total steps  106  loss =  0.02101867087185383\n",
      "epoch =  74  step =  100  of total steps  106  loss =  0.026726078242063522\n",
      "epoch =  75  step =  0  of total steps  106  loss =  0.027488984167575836\n",
      "epoch =  75  step =  20  of total steps  106  loss =  0.02156166359782219\n",
      "epoch =  75  step =  40  of total steps  106  loss =  0.024730633944272995\n",
      "epoch =  75  step =  60  of total steps  106  loss =  0.023576943203806877\n",
      "epoch =  75  step =  80  of total steps  106  loss =  0.024699833244085312\n",
      "epoch =  75  step =  100  of total steps  106  loss =  0.032500237226486206\n",
      "epoch =  76  step =  0  of total steps  106  loss =  0.02607533521950245\n",
      "epoch =  76  step =  20  of total steps  106  loss =  0.0182176623493433\n",
      "epoch =  76  step =  40  of total steps  106  loss =  0.022680334746837616\n",
      "epoch =  76  step =  60  of total steps  106  loss =  0.024685107171535492\n",
      "epoch =  76  step =  80  of total steps  106  loss =  0.026491804048419\n",
      "epoch =  76  step =  100  of total steps  106  loss =  0.02035856433212757\n",
      "epoch =  77  step =  0  of total steps  106  loss =  0.009944944642484188\n",
      "epoch =  77  step =  20  of total steps  106  loss =  0.02437032014131546\n",
      "epoch =  77  step =  40  of total steps  106  loss =  0.023332759737968445\n",
      "epoch =  77  step =  60  of total steps  106  loss =  0.017894763499498367\n",
      "epoch =  77  step =  80  of total steps  106  loss =  0.027026232331991196\n",
      "epoch =  77  step =  100  of total steps  106  loss =  0.017467550933361053\n",
      "epoch =  78  step =  0  of total steps  106  loss =  0.013853924348950386\n",
      "epoch =  78  step =  20  of total steps  106  loss =  0.017670433968305588\n",
      "epoch =  78  step =  40  of total steps  106  loss =  0.02105836197733879\n",
      "epoch =  78  step =  60  of total steps  106  loss =  0.013713828288018703\n",
      "epoch =  78  step =  80  of total steps  106  loss =  0.030768606811761856\n",
      "epoch =  78  step =  100  of total steps  106  loss =  0.026125090196728706\n",
      "epoch =  79  step =  0  of total steps  106  loss =  0.023986313492059708\n",
      "epoch =  79  step =  20  of total steps  106  loss =  0.014204172417521477\n",
      "epoch =  79  step =  40  of total steps  106  loss =  0.01931183598935604\n",
      "epoch =  79  step =  60  of total steps  106  loss =  0.018822580575942993\n",
      "epoch =  79  step =  80  of total steps  106  loss =  0.023303696885704994\n",
      "epoch =  79  step =  100  of total steps  106  loss =  0.015733787789940834\n",
      "epoch =  80  step =  0  of total steps  106  loss =  0.02594577893614769\n",
      "epoch =  80  step =  20  of total steps  106  loss =  0.02677179127931595\n",
      "epoch =  80  step =  40  of total steps  106  loss =  0.015992900356650352\n",
      "epoch =  80  step =  60  of total steps  106  loss =  0.014228861778974533\n",
      "epoch =  80  step =  80  of total steps  106  loss =  0.015342856757342815\n",
      "epoch =  80  step =  100  of total steps  106  loss =  0.01776268519461155\n",
      "epoch =  81  step =  0  of total steps  106  loss =  0.031822577118873596\n",
      "epoch =  81  step =  20  of total steps  106  loss =  0.01829277165234089\n",
      "epoch =  81  step =  40  of total steps  106  loss =  0.013646160252392292\n",
      "epoch =  81  step =  60  of total steps  106  loss =  0.013647658750414848\n",
      "epoch =  81  step =  80  of total steps  106  loss =  0.011171175166964531\n",
      "epoch =  81  step =  100  of total steps  106  loss =  0.023225897923111916\n",
      "epoch =  82  step =  0  of total steps  106  loss =  0.02503674477338791\n",
      "epoch =  82  step =  20  of total steps  106  loss =  0.02158542536199093\n",
      "epoch =  82  step =  40  of total steps  106  loss =  0.026369504630565643\n",
      "epoch =  82  step =  60  of total steps  106  loss =  0.02091204933822155\n",
      "epoch =  82  step =  80  of total steps  106  loss =  0.022128460928797722\n",
      "epoch =  82  step =  100  of total steps  106  loss =  0.028209883719682693\n",
      "epoch =  83  step =  0  of total steps  106  loss =  0.023326260969042778\n",
      "epoch =  83  step =  20  of total steps  106  loss =  0.014396811835467815\n",
      "epoch =  83  step =  40  of total steps  106  loss =  0.014788963831961155\n",
      "epoch =  83  step =  60  of total steps  106  loss =  0.02138003706932068\n",
      "epoch =  83  step =  80  of total steps  106  loss =  0.019438719376921654\n",
      "epoch =  83  step =  100  of total steps  106  loss =  0.02654588781297207\n",
      "epoch =  84  step =  0  of total steps  106  loss =  0.025478219613432884\n",
      "epoch =  84  step =  20  of total steps  106  loss =  0.019151579588651657\n",
      "epoch =  84  step =  40  of total steps  106  loss =  0.02166574075818062\n",
      "epoch =  84  step =  60  of total steps  106  loss =  0.018872255459427834\n",
      "epoch =  84  step =  80  of total steps  106  loss =  0.016949661076068878\n",
      "epoch =  84  step =  100  of total steps  106  loss =  0.021163800731301308\n",
      "epoch =  85  step =  0  of total steps  106  loss =  0.013282104395329952\n",
      "epoch =  85  step =  20  of total steps  106  loss =  0.016668813303112984\n",
      "epoch =  85  step =  40  of total steps  106  loss =  0.028894413262605667\n",
      "epoch =  85  step =  60  of total steps  106  loss =  0.021616654470562935\n",
      "epoch =  85  step =  80  of total steps  106  loss =  0.022788329049944878\n",
      "epoch =  85  step =  100  of total steps  106  loss =  0.014343639835715294\n",
      "epoch =  86  step =  0  of total steps  106  loss =  0.023624194785952568\n",
      "epoch =  86  step =  20  of total steps  106  loss =  0.019269252195954323\n",
      "epoch =  86  step =  40  of total steps  106  loss =  0.019757600501179695\n",
      "epoch =  86  step =  60  of total steps  106  loss =  0.012685592286288738\n",
      "epoch =  86  step =  80  of total steps  106  loss =  0.02243044786155224\n",
      "epoch =  86  step =  100  of total steps  106  loss =  0.01817726343870163\n",
      "epoch =  87  step =  0  of total steps  106  loss =  0.022281497716903687\n",
      "epoch =  87  step =  20  of total steps  106  loss =  0.016618061810731888\n",
      "epoch =  87  step =  40  of total steps  106  loss =  0.020002219825983047\n",
      "epoch =  87  step =  60  of total steps  106  loss =  0.02392803132534027\n",
      "epoch =  87  step =  80  of total steps  106  loss =  0.021404581144452095\n",
      "epoch =  87  step =  100  of total steps  106  loss =  0.01592348888516426\n",
      "epoch =  88  step =  0  of total steps  106  loss =  0.025424029678106308\n",
      "epoch =  88  step =  20  of total steps  106  loss =  0.03006855398416519\n",
      "epoch =  88  step =  40  of total steps  106  loss =  0.021697737276554108\n",
      "epoch =  88  step =  60  of total steps  106  loss =  0.0145577946677804\n",
      "epoch =  88  step =  80  of total steps  106  loss =  0.02006317302584648\n",
      "epoch =  88  step =  100  of total steps  106  loss =  0.01934901252388954\n",
      "epoch =  89  step =  0  of total steps  106  loss =  0.028093954548239708\n",
      "epoch =  89  step =  20  of total steps  106  loss =  0.022171836346387863\n",
      "epoch =  89  step =  40  of total steps  106  loss =  0.03081667423248291\n",
      "epoch =  89  step =  60  of total steps  106  loss =  0.020766638219356537\n",
      "epoch =  89  step =  80  of total steps  106  loss =  0.011562561616301537\n",
      "epoch =  89  step =  100  of total steps  106  loss =  0.016673434525728226\n",
      "Saving model 0.019711032628415608\n",
      "epoch =  90  step =  0  of total steps  106  loss =  0.01638377271592617\n",
      "epoch =  90  step =  20  of total steps  106  loss =  0.017308080568909645\n",
      "epoch =  90  step =  40  of total steps  106  loss =  0.012890367768704891\n",
      "epoch =  90  step =  60  of total steps  106  loss =  0.012848829850554466\n",
      "epoch =  90  step =  80  of total steps  106  loss =  0.026695070788264275\n",
      "epoch =  90  step =  100  of total steps  106  loss =  0.014368348754942417\n",
      "epoch =  91  step =  0  of total steps  106  loss =  0.01298434566706419\n",
      "epoch =  91  step =  20  of total steps  106  loss =  0.023380953818559647\n",
      "epoch =  91  step =  40  of total steps  106  loss =  0.02332356385886669\n",
      "epoch =  91  step =  60  of total steps  106  loss =  0.014423912391066551\n",
      "epoch =  91  step =  80  of total steps  106  loss =  0.02111327461898327\n",
      "epoch =  91  step =  100  of total steps  106  loss =  0.015686143189668655\n",
      "epoch =  92  step =  0  of total steps  106  loss =  0.011752652004361153\n",
      "epoch =  92  step =  20  of total steps  106  loss =  0.025039007887244225\n",
      "epoch =  92  step =  40  of total steps  106  loss =  0.01969638280570507\n",
      "epoch =  92  step =  60  of total steps  106  loss =  0.01992912031710148\n",
      "epoch =  92  step =  80  of total steps  106  loss =  0.023636965081095695\n",
      "epoch =  92  step =  100  of total steps  106  loss =  0.021186040714383125\n",
      "epoch =  93  step =  0  of total steps  106  loss =  0.020882965996861458\n",
      "epoch =  93  step =  20  of total steps  106  loss =  0.017575379461050034\n",
      "epoch =  93  step =  40  of total steps  106  loss =  0.0207019355148077\n",
      "epoch =  93  step =  60  of total steps  106  loss =  0.01690441183745861\n",
      "epoch =  93  step =  80  of total steps  106  loss =  0.016355672851204872\n",
      "epoch =  93  step =  100  of total steps  106  loss =  0.03060770593583584\n",
      "epoch =  94  step =  0  of total steps  106  loss =  0.014775184914469719\n",
      "epoch =  94  step =  20  of total steps  106  loss =  0.02515886165201664\n",
      "epoch =  94  step =  40  of total steps  106  loss =  0.010631754994392395\n",
      "epoch =  94  step =  60  of total steps  106  loss =  0.015208438038825989\n",
      "epoch =  94  step =  80  of total steps  106  loss =  0.02275734394788742\n",
      "epoch =  94  step =  100  of total steps  106  loss =  0.016080217435956\n",
      "epoch =  95  step =  0  of total steps  106  loss =  0.013854616321623325\n",
      "epoch =  95  step =  20  of total steps  106  loss =  0.016660982742905617\n",
      "epoch =  95  step =  40  of total steps  106  loss =  0.014915745705366135\n",
      "epoch =  95  step =  60  of total steps  106  loss =  0.016658132895827293\n",
      "epoch =  95  step =  80  of total steps  106  loss =  0.01918763294816017\n",
      "epoch =  95  step =  100  of total steps  106  loss =  0.018634416162967682\n",
      "epoch =  96  step =  0  of total steps  106  loss =  0.025987762957811356\n",
      "epoch =  96  step =  20  of total steps  106  loss =  0.011337672360241413\n",
      "epoch =  96  step =  40  of total steps  106  loss =  0.018137168139219284\n",
      "epoch =  96  step =  60  of total steps  106  loss =  0.019021131098270416\n",
      "epoch =  96  step =  80  of total steps  106  loss =  0.017754511907696724\n",
      "epoch =  96  step =  100  of total steps  106  loss =  0.015409463085234165\n",
      "epoch =  97  step =  0  of total steps  106  loss =  0.01540431473404169\n",
      "epoch =  97  step =  20  of total steps  106  loss =  0.011093897745013237\n",
      "epoch =  97  step =  40  of total steps  106  loss =  0.01787157543003559\n",
      "epoch =  97  step =  60  of total steps  106  loss =  0.02291824482381344\n",
      "epoch =  97  step =  80  of total steps  106  loss =  0.02296849712729454\n",
      "epoch =  97  step =  100  of total steps  106  loss =  0.01790863648056984\n",
      "epoch =  98  step =  0  of total steps  106  loss =  0.01933206245303154\n",
      "epoch =  98  step =  20  of total steps  106  loss =  0.024454636499285698\n",
      "epoch =  98  step =  40  of total steps  106  loss =  0.021592553704977036\n",
      "epoch =  98  step =  60  of total steps  106  loss =  0.017921695485711098\n",
      "epoch =  98  step =  80  of total steps  106  loss =  0.03133661672472954\n",
      "epoch =  98  step =  100  of total steps  106  loss =  0.013610798865556717\n",
      "epoch =  99  step =  0  of total steps  106  loss =  0.02196384221315384\n",
      "epoch =  99  step =  20  of total steps  106  loss =  0.014573242515325546\n",
      "epoch =  99  step =  40  of total steps  106  loss =  0.014633136801421642\n",
      "epoch =  99  step =  60  of total steps  106  loss =  0.017686938866972923\n",
      "epoch =  99  step =  80  of total steps  106  loss =  0.014415210112929344\n",
      "epoch =  99  step =  100  of total steps  106  loss =  0.02192007750272751\n",
      "epoch =  100  step =  0  of total steps  106  loss =  0.019000476226210594\n",
      "epoch =  100  step =  20  of total steps  106  loss =  0.016136409714818\n",
      "epoch =  100  step =  40  of total steps  106  loss =  0.020580368116497993\n",
      "epoch =  100  step =  60  of total steps  106  loss =  0.015921203419566154\n",
      "epoch =  100  step =  80  of total steps  106  loss =  0.01741684041917324\n",
      "epoch =  100  step =  100  of total steps  106  loss =  0.023238791152834892\n",
      "epoch =  101  step =  0  of total steps  106  loss =  0.024691298604011536\n",
      "epoch =  101  step =  20  of total steps  106  loss =  0.02017209306359291\n",
      "epoch =  101  step =  40  of total steps  106  loss =  0.01871669292449951\n",
      "epoch =  101  step =  60  of total steps  106  loss =  0.021326478570699692\n",
      "epoch =  101  step =  80  of total steps  106  loss =  0.0209367498755455\n",
      "epoch =  101  step =  100  of total steps  106  loss =  0.013596633449196815\n",
      "epoch =  102  step =  0  of total steps  106  loss =  0.011328662745654583\n",
      "epoch =  102  step =  20  of total steps  106  loss =  0.019629089161753654\n",
      "epoch =  102  step =  40  of total steps  106  loss =  0.032131168991327286\n",
      "epoch =  102  step =  60  of total steps  106  loss =  0.0220749843865633\n",
      "epoch =  102  step =  80  of total steps  106  loss =  0.0301973819732666\n",
      "epoch =  102  step =  100  of total steps  106  loss =  0.01940040849149227\n",
      "epoch =  103  step =  0  of total steps  106  loss =  0.01909097470343113\n",
      "epoch =  103  step =  20  of total steps  106  loss =  0.012281189672648907\n",
      "epoch =  103  step =  40  of total steps  106  loss =  0.014971827156841755\n",
      "epoch =  103  step =  60  of total steps  106  loss =  0.02304863929748535\n",
      "epoch =  103  step =  80  of total steps  106  loss =  0.01260917354375124\n",
      "epoch =  103  step =  100  of total steps  106  loss =  0.02550910972058773\n",
      "epoch =  104  step =  0  of total steps  106  loss =  0.01381129864603281\n",
      "epoch =  104  step =  20  of total steps  106  loss =  0.017035111784934998\n",
      "epoch =  104  step =  40  of total steps  106  loss =  0.02197420224547386\n",
      "epoch =  104  step =  60  of total steps  106  loss =  0.02107507735490799\n",
      "epoch =  104  step =  80  of total steps  106  loss =  0.016329431906342506\n",
      "epoch =  104  step =  100  of total steps  106  loss =  0.028216533362865448\n",
      "epoch =  105  step =  0  of total steps  106  loss =  0.00897272489964962\n",
      "epoch =  105  step =  20  of total steps  106  loss =  0.023446856066584587\n",
      "epoch =  105  step =  40  of total steps  106  loss =  0.016171958297491074\n",
      "epoch =  105  step =  60  of total steps  106  loss =  0.024991119280457497\n",
      "epoch =  105  step =  80  of total steps  106  loss =  0.01780526340007782\n",
      "epoch =  105  step =  100  of total steps  106  loss =  0.010857295244932175\n",
      "epoch =  106  step =  0  of total steps  106  loss =  0.017239194363355637\n",
      "epoch =  106  step =  20  of total steps  106  loss =  0.024664297699928284\n",
      "epoch =  106  step =  40  of total steps  106  loss =  0.025278817862272263\n",
      "epoch =  106  step =  60  of total steps  106  loss =  0.018673010170459747\n",
      "epoch =  106  step =  80  of total steps  106  loss =  0.022714298218488693\n",
      "epoch =  106  step =  100  of total steps  106  loss =  0.02125389128923416\n",
      "epoch =  107  step =  0  of total steps  106  loss =  0.01545173954218626\n",
      "epoch =  107  step =  20  of total steps  106  loss =  0.02571265771985054\n",
      "epoch =  107  step =  40  of total steps  106  loss =  0.010222414508461952\n",
      "epoch =  107  step =  60  of total steps  106  loss =  0.017841974273324013\n",
      "epoch =  107  step =  80  of total steps  106  loss =  0.016450388357043266\n",
      "epoch =  107  step =  100  of total steps  106  loss =  0.0340973325073719\n",
      "epoch =  108  step =  0  of total steps  106  loss =  0.013258841820061207\n",
      "epoch =  108  step =  20  of total steps  106  loss =  0.016585739329457283\n",
      "epoch =  108  step =  40  of total steps  106  loss =  0.020882973447442055\n",
      "epoch =  108  step =  60  of total steps  106  loss =  0.01562574692070484\n",
      "epoch =  108  step =  80  of total steps  106  loss =  0.018950195983052254\n",
      "epoch =  108  step =  100  of total steps  106  loss =  0.026468917727470398\n",
      "epoch =  109  step =  0  of total steps  106  loss =  0.00946643203496933\n",
      "epoch =  109  step =  20  of total steps  106  loss =  0.03279518708586693\n",
      "epoch =  109  step =  40  of total steps  106  loss =  0.03020600974559784\n",
      "epoch =  109  step =  60  of total steps  106  loss =  0.0219112578779459\n",
      "epoch =  109  step =  80  of total steps  106  loss =  0.014000498689711094\n",
      "epoch =  109  step =  100  of total steps  106  loss =  0.021293818950653076\n",
      "epoch =  110  step =  0  of total steps  106  loss =  0.017847703769803047\n",
      "epoch =  110  step =  20  of total steps  106  loss =  0.021373774856328964\n",
      "epoch =  110  step =  40  of total steps  106  loss =  0.009801964275538921\n",
      "epoch =  110  step =  60  of total steps  106  loss =  0.019365891814231873\n",
      "epoch =  110  step =  80  of total steps  106  loss =  0.027043692767620087\n",
      "epoch =  110  step =  100  of total steps  106  loss =  0.009179970249533653\n",
      "epoch =  111  step =  0  of total steps  106  loss =  0.01302407868206501\n",
      "epoch =  111  step =  20  of total steps  106  loss =  0.023203682154417038\n",
      "epoch =  111  step =  40  of total steps  106  loss =  0.013032866641879082\n",
      "epoch =  111  step =  60  of total steps  106  loss =  0.023015758022665977\n",
      "epoch =  111  step =  80  of total steps  106  loss =  0.014226527884602547\n",
      "epoch =  111  step =  100  of total steps  106  loss =  0.02164520137012005\n",
      "epoch =  112  step =  0  of total steps  106  loss =  0.015591458417475224\n",
      "epoch =  112  step =  20  of total steps  106  loss =  0.022473204880952835\n",
      "epoch =  112  step =  40  of total steps  106  loss =  0.01609513722360134\n",
      "epoch =  112  step =  60  of total steps  106  loss =  0.020120827481150627\n",
      "epoch =  112  step =  80  of total steps  106  loss =  0.009246080182492733\n",
      "epoch =  112  step =  100  of total steps  106  loss =  0.02156987600028515\n",
      "epoch =  113  step =  0  of total steps  106  loss =  0.014546842314302921\n",
      "epoch =  113  step =  20  of total steps  106  loss =  0.02200189419090748\n",
      "epoch =  113  step =  40  of total steps  106  loss =  0.023489531129598618\n",
      "epoch =  113  step =  60  of total steps  106  loss =  0.010952122509479523\n",
      "epoch =  113  step =  80  of total steps  106  loss =  0.01641976088285446\n",
      "epoch =  113  step =  100  of total steps  106  loss =  0.019664619117975235\n",
      "epoch =  114  step =  0  of total steps  106  loss =  0.014237682335078716\n",
      "epoch =  114  step =  20  of total steps  106  loss =  0.015670031309127808\n",
      "epoch =  114  step =  40  of total steps  106  loss =  0.01830461621284485\n",
      "epoch =  114  step =  60  of total steps  106  loss =  0.022246113047003746\n",
      "epoch =  114  step =  80  of total steps  106  loss =  0.030600931495428085\n",
      "epoch =  114  step =  100  of total steps  106  loss =  0.0256466306746006\n",
      "epoch =  115  step =  0  of total steps  106  loss =  0.02337893657386303\n",
      "epoch =  115  step =  20  of total steps  106  loss =  0.01817089319229126\n",
      "epoch =  115  step =  40  of total steps  106  loss =  0.019146226346492767\n",
      "epoch =  115  step =  60  of total steps  106  loss =  0.015395849011838436\n",
      "epoch =  115  step =  80  of total steps  106  loss =  0.021846240386366844\n",
      "epoch =  115  step =  100  of total steps  106  loss =  0.03016084060072899\n",
      "epoch =  116  step =  0  of total steps  106  loss =  0.011851293966174126\n",
      "epoch =  116  step =  20  of total steps  106  loss =  0.02539362572133541\n",
      "epoch =  116  step =  40  of total steps  106  loss =  0.029713142663240433\n",
      "epoch =  116  step =  60  of total steps  106  loss =  0.024913186207413673\n",
      "epoch =  116  step =  80  of total steps  106  loss =  0.022955061867833138\n",
      "epoch =  116  step =  100  of total steps  106  loss =  0.02392442338168621\n",
      "Saving model 0.019676418685055565\n",
      "epoch =  117  step =  0  of total steps  106  loss =  0.0193504448980093\n",
      "epoch =  117  step =  20  of total steps  106  loss =  0.023157307878136635\n",
      "epoch =  117  step =  40  of total steps  106  loss =  0.01775980554521084\n",
      "epoch =  117  step =  60  of total steps  106  loss =  0.01598944328725338\n",
      "epoch =  117  step =  80  of total steps  106  loss =  0.030738065019249916\n",
      "epoch =  117  step =  100  of total steps  106  loss =  0.011398897506296635\n",
      "epoch =  118  step =  0  of total steps  106  loss =  0.013304249383509159\n",
      "epoch =  118  step =  20  of total steps  106  loss =  0.022822676226496696\n",
      "epoch =  118  step =  40  of total steps  106  loss =  0.01156526617705822\n",
      "epoch =  118  step =  60  of total steps  106  loss =  0.02291458658874035\n",
      "epoch =  118  step =  80  of total steps  106  loss =  0.02131502702832222\n",
      "epoch =  118  step =  100  of total steps  106  loss =  0.022861137986183167\n",
      "epoch =  119  step =  0  of total steps  106  loss =  0.015082227997481823\n",
      "epoch =  119  step =  20  of total steps  106  loss =  0.026463082060217857\n",
      "epoch =  119  step =  40  of total steps  106  loss =  0.019016476348042488\n",
      "epoch =  119  step =  60  of total steps  106  loss =  0.01450255699455738\n",
      "epoch =  119  step =  80  of total steps  106  loss =  0.021550599485635757\n",
      "epoch =  119  step =  100  of total steps  106  loss =  0.0196685791015625\n",
      "epoch =  120  step =  0  of total steps  106  loss =  0.025013554841279984\n",
      "epoch =  120  step =  20  of total steps  106  loss =  0.011680086143314838\n",
      "epoch =  120  step =  40  of total steps  106  loss =  0.018845699727535248\n",
      "epoch =  120  step =  60  of total steps  106  loss =  0.016051338985562325\n",
      "epoch =  120  step =  80  of total steps  106  loss =  0.023671528324484825\n",
      "epoch =  120  step =  100  of total steps  106  loss =  0.01660745218396187\n",
      "epoch =  121  step =  0  of total steps  106  loss =  0.024059657007455826\n",
      "epoch =  121  step =  20  of total steps  106  loss =  0.03273339942097664\n",
      "epoch =  121  step =  40  of total steps  106  loss =  0.014331500045955181\n",
      "epoch =  121  step =  60  of total steps  106  loss =  0.02002359926700592\n",
      "epoch =  121  step =  80  of total steps  106  loss =  0.017687803134322166\n",
      "epoch =  121  step =  100  of total steps  106  loss =  0.02140156552195549\n",
      "epoch =  122  step =  0  of total steps  106  loss =  0.022996513172984123\n",
      "epoch =  122  step =  20  of total steps  106  loss =  0.01511403825134039\n",
      "epoch =  122  step =  40  of total steps  106  loss =  0.01563565619289875\n",
      "epoch =  122  step =  60  of total steps  106  loss =  0.01600276678800583\n",
      "epoch =  122  step =  80  of total steps  106  loss =  0.018950093537569046\n",
      "epoch =  122  step =  100  of total steps  106  loss =  0.018292129039764404\n",
      "epoch =  123  step =  0  of total steps  106  loss =  0.019520225003361702\n",
      "epoch =  123  step =  20  of total steps  106  loss =  0.011574460193514824\n",
      "epoch =  123  step =  40  of total steps  106  loss =  0.019754210487008095\n",
      "epoch =  123  step =  60  of total steps  106  loss =  0.016389761120080948\n",
      "epoch =  123  step =  80  of total steps  106  loss =  0.024430127814412117\n",
      "epoch =  123  step =  100  of total steps  106  loss =  0.03048345074057579\n",
      "epoch =  124  step =  0  of total steps  106  loss =  0.01769595965743065\n",
      "epoch =  124  step =  20  of total steps  106  loss =  0.02020682953298092\n",
      "epoch =  124  step =  40  of total steps  106  loss =  0.019726337864995003\n",
      "epoch =  124  step =  60  of total steps  106  loss =  0.02430802583694458\n",
      "epoch =  124  step =  80  of total steps  106  loss =  0.025351643562316895\n",
      "epoch =  124  step =  100  of total steps  106  loss =  0.023246614262461662\n",
      "epoch =  125  step =  0  of total steps  106  loss =  0.01919843815267086\n",
      "epoch =  125  step =  20  of total steps  106  loss =  0.022715307772159576\n",
      "epoch =  125  step =  40  of total steps  106  loss =  0.017576148733496666\n",
      "epoch =  125  step =  60  of total steps  106  loss =  0.014168791472911835\n",
      "epoch =  125  step =  80  of total steps  106  loss =  0.01921268366277218\n",
      "epoch =  125  step =  100  of total steps  106  loss =  0.01518946047872305\n",
      "epoch =  126  step =  0  of total steps  106  loss =  0.02204390987753868\n",
      "epoch =  126  step =  20  of total steps  106  loss =  0.017304066568613052\n",
      "epoch =  126  step =  40  of total steps  106  loss =  0.01811438798904419\n",
      "epoch =  126  step =  60  of total steps  106  loss =  0.028030747547745705\n",
      "epoch =  126  step =  80  of total steps  106  loss =  0.017629273235797882\n",
      "epoch =  126  step =  100  of total steps  106  loss =  0.021106291562318802\n",
      "epoch =  127  step =  0  of total steps  106  loss =  0.02759227715432644\n",
      "epoch =  127  step =  20  of total steps  106  loss =  0.024266475811600685\n",
      "epoch =  127  step =  40  of total steps  106  loss =  0.014531461521983147\n",
      "epoch =  127  step =  60  of total steps  106  loss =  0.01955494098365307\n",
      "epoch =  127  step =  80  of total steps  106  loss =  0.024183323606848717\n",
      "epoch =  127  step =  100  of total steps  106  loss =  0.018479209393262863\n",
      "epoch =  128  step =  0  of total steps  106  loss =  0.014421709813177586\n",
      "epoch =  128  step =  20  of total steps  106  loss =  0.01507334690541029\n",
      "epoch =  128  step =  40  of total steps  106  loss =  0.020491037517786026\n",
      "epoch =  128  step =  60  of total steps  106  loss =  0.01774732768535614\n",
      "epoch =  128  step =  80  of total steps  106  loss =  0.02062743343412876\n",
      "epoch =  128  step =  100  of total steps  106  loss =  0.01597258634865284\n",
      "epoch =  129  step =  0  of total steps  106  loss =  0.012265883386135101\n",
      "epoch =  129  step =  20  of total steps  106  loss =  0.0184039194136858\n",
      "epoch =  129  step =  40  of total steps  106  loss =  0.022668011486530304\n",
      "epoch =  129  step =  60  of total steps  106  loss =  0.027459483593702316\n",
      "epoch =  129  step =  80  of total steps  106  loss =  0.018045617267489433\n",
      "epoch =  129  step =  100  of total steps  106  loss =  0.022555867210030556\n",
      "epoch =  130  step =  0  of total steps  106  loss =  0.02594909630715847\n",
      "epoch =  130  step =  20  of total steps  106  loss =  0.037095099687576294\n",
      "epoch =  130  step =  40  of total steps  106  loss =  0.014121117070317268\n",
      "epoch =  130  step =  60  of total steps  106  loss =  0.01804887130856514\n",
      "epoch =  130  step =  80  of total steps  106  loss =  0.021458545699715614\n",
      "epoch =  130  step =  100  of total steps  106  loss =  0.010127505287528038\n",
      "epoch =  131  step =  0  of total steps  106  loss =  0.027337200939655304\n",
      "epoch =  131  step =  20  of total steps  106  loss =  0.022319994866847992\n",
      "epoch =  131  step =  40  of total steps  106  loss =  0.016772853210568428\n",
      "epoch =  131  step =  60  of total steps  106  loss =  0.017792604863643646\n",
      "epoch =  131  step =  80  of total steps  106  loss =  0.026156648993492126\n",
      "epoch =  131  step =  100  of total steps  106  loss =  0.025795720517635345\n",
      "epoch =  132  step =  0  of total steps  106  loss =  0.029193682596087456\n",
      "epoch =  132  step =  20  of total steps  106  loss =  0.020658306777477264\n",
      "epoch =  132  step =  40  of total steps  106  loss =  0.016744138672947884\n",
      "epoch =  132  step =  60  of total steps  106  loss =  0.018458671867847443\n",
      "epoch =  132  step =  80  of total steps  106  loss =  0.024848012253642082\n",
      "epoch =  132  step =  100  of total steps  106  loss =  0.01635533757507801\n",
      "epoch =  133  step =  0  of total steps  106  loss =  0.024688053876161575\n",
      "epoch =  133  step =  20  of total steps  106  loss =  0.01553548127412796\n",
      "epoch =  133  step =  40  of total steps  106  loss =  0.018627064302563667\n",
      "epoch =  133  step =  60  of total steps  106  loss =  0.01854419894516468\n",
      "epoch =  133  step =  80  of total steps  106  loss =  0.012132964096963406\n",
      "epoch =  133  step =  100  of total steps  106  loss =  0.013518260791897774\n",
      "epoch =  134  step =  0  of total steps  106  loss =  0.03114941529929638\n",
      "epoch =  134  step =  20  of total steps  106  loss =  0.020522702485322952\n",
      "epoch =  134  step =  40  of total steps  106  loss =  0.022445056587457657\n",
      "epoch =  134  step =  60  of total steps  106  loss =  0.02091336064040661\n",
      "epoch =  134  step =  80  of total steps  106  loss =  0.016131127253174782\n",
      "epoch =  134  step =  100  of total steps  106  loss =  0.03480205684900284\n",
      "epoch =  135  step =  0  of total steps  106  loss =  0.023263929411768913\n",
      "epoch =  135  step =  20  of total steps  106  loss =  0.03222307190299034\n",
      "epoch =  135  step =  40  of total steps  106  loss =  0.024693019688129425\n",
      "epoch =  135  step =  60  of total steps  106  loss =  0.009860496036708355\n",
      "epoch =  135  step =  80  of total steps  106  loss =  0.02405586838722229\n",
      "epoch =  135  step =  100  of total steps  106  loss =  0.02118813619017601\n",
      "epoch =  136  step =  0  of total steps  106  loss =  0.01912013813853264\n",
      "epoch =  136  step =  20  of total steps  106  loss =  0.028180288150906563\n",
      "epoch =  136  step =  40  of total steps  106  loss =  0.01536619383841753\n",
      "epoch =  136  step =  60  of total steps  106  loss =  0.024931110441684723\n",
      "epoch =  136  step =  80  of total steps  106  loss =  0.014422598294913769\n",
      "epoch =  136  step =  100  of total steps  106  loss =  0.016617564484477043\n",
      "Saving model 0.01964391706476234\n",
      "epoch =  137  step =  0  of total steps  106  loss =  0.015214200131595135\n",
      "epoch =  137  step =  20  of total steps  106  loss =  0.03137829527258873\n",
      "epoch =  137  step =  40  of total steps  106  loss =  0.025468097999691963\n",
      "epoch =  137  step =  60  of total steps  106  loss =  0.02376953698694706\n",
      "epoch =  137  step =  80  of total steps  106  loss =  0.019921081140637398\n",
      "epoch =  137  step =  100  of total steps  106  loss =  0.02051776833832264\n",
      "epoch =  138  step =  0  of total steps  106  loss =  0.018514079973101616\n",
      "epoch =  138  step =  20  of total steps  106  loss =  0.020150076597929\n",
      "epoch =  138  step =  40  of total steps  106  loss =  0.024804670363664627\n",
      "epoch =  138  step =  60  of total steps  106  loss =  0.022359509021043777\n",
      "epoch =  138  step =  80  of total steps  106  loss =  0.017490429803729057\n",
      "epoch =  138  step =  100  of total steps  106  loss =  0.02293507754802704\n",
      "epoch =  139  step =  0  of total steps  106  loss =  0.012392126955091953\n",
      "epoch =  139  step =  20  of total steps  106  loss =  0.023154711350798607\n",
      "epoch =  139  step =  40  of total steps  106  loss =  0.020675795152783394\n",
      "epoch =  139  step =  60  of total steps  106  loss =  0.015497105196118355\n",
      "epoch =  139  step =  80  of total steps  106  loss =  0.01580638624727726\n",
      "epoch =  139  step =  100  of total steps  106  loss =  0.0188410896807909\n",
      "epoch =  140  step =  0  of total steps  106  loss =  0.01963312178850174\n",
      "epoch =  140  step =  20  of total steps  106  loss =  0.015681209042668343\n",
      "epoch =  140  step =  40  of total steps  106  loss =  0.01515364833176136\n",
      "epoch =  140  step =  60  of total steps  106  loss =  0.017563341185450554\n",
      "epoch =  140  step =  80  of total steps  106  loss =  0.028541376814246178\n",
      "epoch =  140  step =  100  of total steps  106  loss =  0.022873511537909508\n",
      "epoch =  141  step =  0  of total steps  106  loss =  0.015798453241586685\n",
      "epoch =  141  step =  20  of total steps  106  loss =  0.025503627955913544\n",
      "epoch =  141  step =  40  of total steps  106  loss =  0.019631240516901016\n",
      "epoch =  141  step =  60  of total steps  106  loss =  0.018089765682816505\n",
      "epoch =  141  step =  80  of total steps  106  loss =  0.01742277666926384\n",
      "epoch =  141  step =  100  of total steps  106  loss =  0.03243713825941086\n",
      "epoch =  142  step =  0  of total steps  106  loss =  0.024056434631347656\n",
      "epoch =  142  step =  20  of total steps  106  loss =  0.028155289590358734\n",
      "epoch =  142  step =  40  of total steps  106  loss =  0.011759264394640923\n",
      "epoch =  142  step =  60  of total steps  106  loss =  0.010619185864925385\n",
      "epoch =  142  step =  80  of total steps  106  loss =  0.01927017979323864\n",
      "epoch =  142  step =  100  of total steps  106  loss =  0.012860936112701893\n",
      "epoch =  143  step =  0  of total steps  106  loss =  0.02003614790737629\n",
      "epoch =  143  step =  20  of total steps  106  loss =  0.01806422509253025\n",
      "epoch =  143  step =  40  of total steps  106  loss =  0.015536726452410221\n",
      "epoch =  143  step =  60  of total steps  106  loss =  0.023846106603741646\n",
      "epoch =  143  step =  80  of total steps  106  loss =  0.017224807292222977\n",
      "epoch =  143  step =  100  of total steps  106  loss =  0.01275400910526514\n",
      "epoch =  144  step =  0  of total steps  106  loss =  0.018930405378341675\n",
      "epoch =  144  step =  20  of total steps  106  loss =  0.018684105947613716\n",
      "epoch =  144  step =  40  of total steps  106  loss =  0.015106655657291412\n",
      "epoch =  144  step =  60  of total steps  106  loss =  0.016666334122419357\n",
      "epoch =  144  step =  80  of total steps  106  loss =  0.01797562651336193\n",
      "epoch =  144  step =  100  of total steps  106  loss =  0.022626392543315887\n",
      "epoch =  145  step =  0  of total steps  106  loss =  0.012223943136632442\n",
      "epoch =  145  step =  20  of total steps  106  loss =  0.010897122323513031\n",
      "epoch =  145  step =  40  of total steps  106  loss =  0.018964843824505806\n",
      "epoch =  145  step =  60  of total steps  106  loss =  0.022771721705794334\n",
      "epoch =  145  step =  80  of total steps  106  loss =  0.02149338088929653\n",
      "epoch =  145  step =  100  of total steps  106  loss =  0.019869137555360794\n",
      "epoch =  146  step =  0  of total steps  106  loss =  0.019302139058709145\n",
      "epoch =  146  step =  20  of total steps  106  loss =  0.02480655163526535\n",
      "epoch =  146  step =  40  of total steps  106  loss =  0.01234034076333046\n",
      "epoch =  146  step =  60  of total steps  106  loss =  0.015506936237215996\n",
      "epoch =  146  step =  80  of total steps  106  loss =  0.020516054704785347\n",
      "epoch =  146  step =  100  of total steps  106  loss =  0.011451365426182747\n",
      "epoch =  147  step =  0  of total steps  106  loss =  0.024315664544701576\n",
      "epoch =  147  step =  20  of total steps  106  loss =  0.01152039784938097\n",
      "epoch =  147  step =  40  of total steps  106  loss =  0.02438642829656601\n",
      "epoch =  147  step =  60  of total steps  106  loss =  0.015277538448572159\n",
      "epoch =  147  step =  80  of total steps  106  loss =  0.022910811007022858\n",
      "epoch =  147  step =  100  of total steps  106  loss =  0.01548510417342186\n",
      "epoch =  148  step =  0  of total steps  106  loss =  0.00955274049192667\n",
      "epoch =  148  step =  20  of total steps  106  loss =  0.02189931459724903\n",
      "epoch =  148  step =  40  of total steps  106  loss =  0.019658375531435013\n",
      "epoch =  148  step =  60  of total steps  106  loss =  0.01680207997560501\n",
      "epoch =  148  step =  80  of total steps  106  loss =  0.024439340457320213\n",
      "epoch =  148  step =  100  of total steps  106  loss =  0.02261623926460743\n",
      "epoch =  149  step =  0  of total steps  106  loss =  0.012585959397256374\n",
      "epoch =  149  step =  20  of total steps  106  loss =  0.021914949640631676\n",
      "epoch =  149  step =  40  of total steps  106  loss =  0.01854560896754265\n",
      "epoch =  149  step =  60  of total steps  106  loss =  0.02914329059422016\n",
      "epoch =  149  step =  80  of total steps  106  loss =  0.013694565743207932\n",
      "epoch =  149  step =  100  of total steps  106  loss =  0.01926756463944912\n",
      "epoch =  150  step =  0  of total steps  106  loss =  0.02142053097486496\n",
      "epoch =  150  step =  20  of total steps  106  loss =  0.017850296571850777\n",
      "epoch =  150  step =  40  of total steps  106  loss =  0.025219494476914406\n",
      "epoch =  150  step =  60  of total steps  106  loss =  0.027634428814053535\n",
      "epoch =  150  step =  80  of total steps  106  loss =  0.029823562130331993\n",
      "epoch =  150  step =  100  of total steps  106  loss =  0.02087463065981865\n",
      "epoch =  151  step =  0  of total steps  106  loss =  0.016683300957083702\n",
      "epoch =  151  step =  20  of total steps  106  loss =  0.019104355946183205\n",
      "epoch =  151  step =  40  of total steps  106  loss =  0.009425746276974678\n",
      "epoch =  151  step =  60  of total steps  106  loss =  0.01908441260457039\n",
      "epoch =  151  step =  80  of total steps  106  loss =  0.016124559566378593\n",
      "epoch =  151  step =  100  of total steps  106  loss =  0.014663313515484333\n",
      "epoch =  152  step =  0  of total steps  106  loss =  0.022694116458296776\n",
      "epoch =  152  step =  20  of total steps  106  loss =  0.013008588925004005\n",
      "epoch =  152  step =  40  of total steps  106  loss =  0.026240820065140724\n",
      "epoch =  152  step =  60  of total steps  106  loss =  0.027998322620987892\n",
      "epoch =  152  step =  80  of total steps  106  loss =  0.020042408257722855\n",
      "epoch =  152  step =  100  of total steps  106  loss =  0.023086562752723694\n",
      "epoch =  153  step =  0  of total steps  106  loss =  0.018615644425153732\n",
      "epoch =  153  step =  20  of total steps  106  loss =  0.021943101659417152\n",
      "epoch =  153  step =  40  of total steps  106  loss =  0.02334950491786003\n",
      "epoch =  153  step =  60  of total steps  106  loss =  0.021163329482078552\n",
      "epoch =  153  step =  80  of total steps  106  loss =  0.020310569554567337\n",
      "epoch =  153  step =  100  of total steps  106  loss =  0.02188514545559883\n",
      "epoch =  154  step =  0  of total steps  106  loss =  0.015668906271457672\n",
      "epoch =  154  step =  20  of total steps  106  loss =  0.01607935130596161\n",
      "epoch =  154  step =  40  of total steps  106  loss =  0.01329602301120758\n",
      "epoch =  154  step =  60  of total steps  106  loss =  0.018451912328600883\n",
      "epoch =  154  step =  80  of total steps  106  loss =  0.01715521328151226\n",
      "epoch =  154  step =  100  of total steps  106  loss =  0.01887158676981926\n",
      "epoch =  155  step =  0  of total steps  106  loss =  0.00861517246812582\n",
      "epoch =  155  step =  20  of total steps  106  loss =  0.026522014290094376\n",
      "epoch =  155  step =  40  of total steps  106  loss =  0.021657584235072136\n",
      "epoch =  155  step =  60  of total steps  106  loss =  0.021480781957507133\n",
      "epoch =  155  step =  80  of total steps  106  loss =  0.01276059728115797\n",
      "epoch =  155  step =  100  of total steps  106  loss =  0.020368631929159164\n",
      "epoch =  156  step =  0  of total steps  106  loss =  0.025738168507814407\n",
      "epoch =  156  step =  20  of total steps  106  loss =  0.02353081852197647\n",
      "epoch =  156  step =  40  of total steps  106  loss =  0.0198566485196352\n",
      "epoch =  156  step =  60  of total steps  106  loss =  0.023706071078777313\n",
      "epoch =  156  step =  80  of total steps  106  loss =  0.020430246368050575\n",
      "epoch =  156  step =  100  of total steps  106  loss =  0.020709605887532234\n",
      "epoch =  157  step =  0  of total steps  106  loss =  0.01472469698637724\n",
      "epoch =  157  step =  20  of total steps  106  loss =  0.013395888730883598\n",
      "epoch =  157  step =  40  of total steps  106  loss =  0.020620061084628105\n",
      "epoch =  157  step =  60  of total steps  106  loss =  0.02120686136186123\n",
      "epoch =  157  step =  80  of total steps  106  loss =  0.012935077771544456\n",
      "epoch =  157  step =  100  of total steps  106  loss =  0.02298675663769245\n",
      "epoch =  158  step =  0  of total steps  106  loss =  0.01546003483235836\n",
      "epoch =  158  step =  20  of total steps  106  loss =  0.020932352170348167\n",
      "epoch =  158  step =  40  of total steps  106  loss =  0.016646305099129677\n",
      "epoch =  158  step =  60  of total steps  106  loss =  0.02378973737359047\n",
      "epoch =  158  step =  80  of total steps  106  loss =  0.020128903910517693\n",
      "epoch =  158  step =  100  of total steps  106  loss =  0.018795954063534737\n",
      "epoch =  159  step =  0  of total steps  106  loss =  0.024769702926278114\n",
      "epoch =  159  step =  20  of total steps  106  loss =  0.02110220305621624\n",
      "epoch =  159  step =  40  of total steps  106  loss =  0.01781156100332737\n",
      "epoch =  159  step =  60  of total steps  106  loss =  0.01777285523712635\n",
      "epoch =  159  step =  80  of total steps  106  loss =  0.012200869619846344\n",
      "epoch =  159  step =  100  of total steps  106  loss =  0.009201481007039547\n",
      "epoch =  160  step =  0  of total steps  106  loss =  0.03106745146214962\n",
      "epoch =  160  step =  20  of total steps  106  loss =  0.020921245217323303\n",
      "epoch =  160  step =  40  of total steps  106  loss =  0.02035306766629219\n",
      "epoch =  160  step =  60  of total steps  106  loss =  0.018836362287402153\n",
      "epoch =  160  step =  80  of total steps  106  loss =  0.017552098259329796\n",
      "epoch =  160  step =  100  of total steps  106  loss =  0.01897914707660675\n",
      "epoch =  161  step =  0  of total steps  106  loss =  0.017043324187397957\n",
      "epoch =  161  step =  20  of total steps  106  loss =  0.022109495475888252\n",
      "epoch =  161  step =  40  of total steps  106  loss =  0.019387532025575638\n",
      "epoch =  161  step =  60  of total steps  106  loss =  0.020380109548568726\n",
      "epoch =  161  step =  80  of total steps  106  loss =  0.01907636970281601\n",
      "epoch =  161  step =  100  of total steps  106  loss =  0.018229495733976364\n",
      "epoch =  162  step =  0  of total steps  106  loss =  0.01117499265819788\n",
      "epoch =  162  step =  20  of total steps  106  loss =  0.02376071736216545\n",
      "epoch =  162  step =  40  of total steps  106  loss =  0.009811531752347946\n",
      "epoch =  162  step =  60  of total steps  106  loss =  0.01391969621181488\n",
      "epoch =  162  step =  80  of total steps  106  loss =  0.02036254107952118\n",
      "epoch =  162  step =  100  of total steps  106  loss =  0.014849000610411167\n",
      "epoch =  163  step =  0  of total steps  106  loss =  0.022101769223809242\n",
      "epoch =  163  step =  20  of total steps  106  loss =  0.022905485704541206\n",
      "epoch =  163  step =  40  of total steps  106  loss =  0.008172517642378807\n",
      "epoch =  163  step =  60  of total steps  106  loss =  0.019736098125576973\n",
      "epoch =  163  step =  80  of total steps  106  loss =  0.028723981231451035\n",
      "epoch =  163  step =  100  of total steps  106  loss =  0.01982826553285122\n",
      "epoch =  164  step =  0  of total steps  106  loss =  0.01878564991056919\n",
      "epoch =  164  step =  20  of total steps  106  loss =  0.024590706452727318\n",
      "epoch =  164  step =  40  of total steps  106  loss =  0.022653434425592422\n",
      "epoch =  164  step =  60  of total steps  106  loss =  0.017067423090338707\n",
      "epoch =  164  step =  80  of total steps  106  loss =  0.02025012858211994\n",
      "epoch =  164  step =  100  of total steps  106  loss =  0.022550836205482483\n",
      "epoch =  165  step =  0  of total steps  106  loss =  0.015571788884699345\n",
      "epoch =  165  step =  20  of total steps  106  loss =  0.011230976320803165\n",
      "epoch =  165  step =  40  of total steps  106  loss =  0.01939091831445694\n",
      "epoch =  165  step =  60  of total steps  106  loss =  0.01948726736009121\n",
      "epoch =  165  step =  80  of total steps  106  loss =  0.015830600634217262\n",
      "epoch =  165  step =  100  of total steps  106  loss =  0.010665316134691238\n",
      "epoch =  166  step =  0  of total steps  106  loss =  0.021756714209914207\n",
      "epoch =  166  step =  20  of total steps  106  loss =  0.03288748115301132\n",
      "epoch =  166  step =  40  of total steps  106  loss =  0.019369512796401978\n",
      "epoch =  166  step =  60  of total steps  106  loss =  0.018014244735240936\n",
      "epoch =  166  step =  80  of total steps  106  loss =  0.0215328149497509\n",
      "epoch =  166  step =  100  of total steps  106  loss =  0.026763906702399254\n",
      "epoch =  167  step =  0  of total steps  106  loss =  0.028439510613679886\n",
      "epoch =  167  step =  20  of total steps  106  loss =  0.02491958998143673\n",
      "epoch =  167  step =  40  of total steps  106  loss =  0.025732774287462234\n",
      "epoch =  167  step =  60  of total steps  106  loss =  0.021310700103640556\n",
      "epoch =  167  step =  80  of total steps  106  loss =  0.011000889353454113\n",
      "epoch =  167  step =  100  of total steps  106  loss =  0.01706179976463318\n",
      "epoch =  168  step =  0  of total steps  106  loss =  0.01728326454758644\n",
      "epoch =  168  step =  20  of total steps  106  loss =  0.013422940857708454\n",
      "epoch =  168  step =  40  of total steps  106  loss =  0.01989327371120453\n",
      "epoch =  168  step =  60  of total steps  106  loss =  0.01615874655544758\n",
      "epoch =  168  step =  80  of total steps  106  loss =  0.028866039589047432\n",
      "epoch =  168  step =  100  of total steps  106  loss =  0.020819004625082016\n",
      "epoch =  169  step =  0  of total steps  106  loss =  0.017463384196162224\n",
      "epoch =  169  step =  20  of total steps  106  loss =  0.021195359528064728\n",
      "epoch =  169  step =  40  of total steps  106  loss =  0.020599273964762688\n",
      "epoch =  169  step =  60  of total steps  106  loss =  0.02728663757443428\n",
      "epoch =  169  step =  80  of total steps  106  loss =  0.01832105591893196\n",
      "epoch =  169  step =  100  of total steps  106  loss =  0.017694691196084023\n",
      "epoch =  170  step =  0  of total steps  106  loss =  0.021823957562446594\n",
      "epoch =  170  step =  20  of total steps  106  loss =  0.017997166141867638\n",
      "epoch =  170  step =  40  of total steps  106  loss =  0.011295553296804428\n",
      "epoch =  170  step =  60  of total steps  106  loss =  0.019334523007273674\n",
      "epoch =  170  step =  80  of total steps  106  loss =  0.01091706845909357\n",
      "epoch =  170  step =  100  of total steps  106  loss =  0.023475835099816322\n",
      "epoch =  171  step =  0  of total steps  106  loss =  0.03050679713487625\n",
      "epoch =  171  step =  20  of total steps  106  loss =  0.022409232333302498\n",
      "epoch =  171  step =  40  of total steps  106  loss =  0.013766875490546227\n",
      "epoch =  171  step =  60  of total steps  106  loss =  0.019526183605194092\n",
      "epoch =  171  step =  80  of total steps  106  loss =  0.028920674696564674\n",
      "epoch =  171  step =  100  of total steps  106  loss =  0.013472032733261585\n",
      "epoch =  172  step =  0  of total steps  106  loss =  0.02589406445622444\n",
      "epoch =  172  step =  20  of total steps  106  loss =  0.02778874896466732\n",
      "epoch =  172  step =  40  of total steps  106  loss =  0.018910041078925133\n",
      "epoch =  172  step =  60  of total steps  106  loss =  0.023853981867432594\n",
      "epoch =  172  step =  80  of total steps  106  loss =  0.020178623497486115\n",
      "epoch =  172  step =  100  of total steps  106  loss =  0.022243112325668335\n",
      "epoch =  173  step =  0  of total steps  106  loss =  0.028346607461571693\n",
      "epoch =  173  step =  20  of total steps  106  loss =  0.025943508371710777\n",
      "epoch =  173  step =  40  of total steps  106  loss =  0.01996123231947422\n",
      "epoch =  173  step =  60  of total steps  106  loss =  0.0290093831717968\n",
      "epoch =  173  step =  80  of total steps  106  loss =  0.016617275774478912\n",
      "epoch =  173  step =  100  of total steps  106  loss =  0.01128380186855793\n",
      "Saving model 0.019631704495657445\n",
      "epoch =  174  step =  0  of total steps  106  loss =  0.020762527361512184\n",
      "epoch =  174  step =  20  of total steps  106  loss =  0.009527022950351238\n",
      "epoch =  174  step =  40  of total steps  106  loss =  0.015444902703166008\n",
      "epoch =  174  step =  60  of total steps  106  loss =  0.012263280339539051\n",
      "epoch =  174  step =  80  of total steps  106  loss =  0.018008142709732056\n",
      "epoch =  174  step =  100  of total steps  106  loss =  0.024322014302015305\n",
      "epoch =  175  step =  0  of total steps  106  loss =  0.02093879133462906\n",
      "epoch =  175  step =  20  of total steps  106  loss =  0.020168792456388474\n",
      "epoch =  175  step =  40  of total steps  106  loss =  0.028602294623851776\n",
      "epoch =  175  step =  60  of total steps  106  loss =  0.023056669160723686\n",
      "epoch =  175  step =  80  of total steps  106  loss =  0.024953581392765045\n",
      "epoch =  175  step =  100  of total steps  106  loss =  0.0326923206448555\n",
      "epoch =  176  step =  0  of total steps  106  loss =  0.018102450296282768\n",
      "epoch =  176  step =  20  of total steps  106  loss =  0.016432760283350945\n",
      "epoch =  176  step =  40  of total steps  106  loss =  0.016918888315558434\n",
      "epoch =  176  step =  60  of total steps  106  loss =  0.016216997057199478\n",
      "epoch =  176  step =  80  of total steps  106  loss =  0.011739363893866539\n",
      "epoch =  176  step =  100  of total steps  106  loss =  0.014945944771170616\n",
      "epoch =  177  step =  0  of total steps  106  loss =  0.023330604657530785\n",
      "epoch =  177  step =  20  of total steps  106  loss =  0.02567511424422264\n",
      "epoch =  177  step =  40  of total steps  106  loss =  0.011187291704118252\n",
      "epoch =  177  step =  60  of total steps  106  loss =  0.015448043122887611\n",
      "epoch =  177  step =  80  of total steps  106  loss =  0.019150305539369583\n",
      "epoch =  177  step =  100  of total steps  106  loss =  0.018847880885004997\n",
      "epoch =  178  step =  0  of total steps  106  loss =  0.02168971113860607\n",
      "epoch =  178  step =  20  of total steps  106  loss =  0.011914467439055443\n",
      "epoch =  178  step =  40  of total steps  106  loss =  0.017297139391303062\n",
      "epoch =  178  step =  60  of total steps  106  loss =  0.024372199550271034\n",
      "epoch =  178  step =  80  of total steps  106  loss =  0.016936372965574265\n",
      "epoch =  178  step =  100  of total steps  106  loss =  0.016164803877472878\n",
      "epoch =  179  step =  0  of total steps  106  loss =  0.0260385163128376\n",
      "epoch =  179  step =  20  of total steps  106  loss =  0.02053952030837536\n",
      "epoch =  179  step =  40  of total steps  106  loss =  0.024532420560717583\n",
      "epoch =  179  step =  60  of total steps  106  loss =  0.025906087830662727\n",
      "epoch =  179  step =  80  of total steps  106  loss =  0.01905103214085102\n",
      "epoch =  179  step =  100  of total steps  106  loss =  0.02778342366218567\n",
      "epoch =  180  step =  0  of total steps  106  loss =  0.027546051889657974\n",
      "epoch =  180  step =  20  of total steps  106  loss =  0.017804589122533798\n",
      "epoch =  180  step =  40  of total steps  106  loss =  0.01821383647620678\n",
      "epoch =  180  step =  60  of total steps  106  loss =  0.013197190128266811\n",
      "epoch =  180  step =  80  of total steps  106  loss =  0.017512518912553787\n",
      "epoch =  180  step =  100  of total steps  106  loss =  0.016952425241470337\n",
      "epoch =  181  step =  0  of total steps  106  loss =  0.03166716545820236\n",
      "epoch =  181  step =  20  of total steps  106  loss =  0.019244691357016563\n",
      "epoch =  181  step =  40  of total steps  106  loss =  0.02302512340247631\n",
      "epoch =  181  step =  60  of total steps  106  loss =  0.021543430164456367\n",
      "epoch =  181  step =  80  of total steps  106  loss =  0.017612146213650703\n",
      "epoch =  181  step =  100  of total steps  106  loss =  0.020670413970947266\n",
      "epoch =  182  step =  0  of total steps  106  loss =  0.015546189621090889\n",
      "epoch =  182  step =  20  of total steps  106  loss =  0.009195039980113506\n",
      "epoch =  182  step =  40  of total steps  106  loss =  0.0214782003313303\n",
      "epoch =  182  step =  60  of total steps  106  loss =  0.01820181868970394\n",
      "epoch =  182  step =  80  of total steps  106  loss =  0.027358373627066612\n",
      "epoch =  182  step =  100  of total steps  106  loss =  0.027284914627671242\n",
      "epoch =  183  step =  0  of total steps  106  loss =  0.01860572211444378\n",
      "epoch =  183  step =  20  of total steps  106  loss =  0.01761629246175289\n",
      "epoch =  183  step =  40  of total steps  106  loss =  0.010552601888775826\n",
      "epoch =  183  step =  60  of total steps  106  loss =  0.016694972291588783\n",
      "epoch =  183  step =  80  of total steps  106  loss =  0.023631567135453224\n",
      "epoch =  183  step =  100  of total steps  106  loss =  0.016428278759121895\n",
      "epoch =  184  step =  0  of total steps  106  loss =  0.011319889687001705\n",
      "epoch =  184  step =  20  of total steps  106  loss =  0.015953633934259415\n",
      "epoch =  184  step =  40  of total steps  106  loss =  0.018643826246261597\n",
      "epoch =  184  step =  60  of total steps  106  loss =  0.0168024692684412\n",
      "epoch =  184  step =  80  of total steps  106  loss =  0.021194899454712868\n",
      "epoch =  184  step =  100  of total steps  106  loss =  0.01752396672964096\n",
      "epoch =  185  step =  0  of total steps  106  loss =  0.017233945429325104\n",
      "epoch =  185  step =  20  of total steps  106  loss =  0.01617049053311348\n",
      "epoch =  185  step =  40  of total steps  106  loss =  0.02095082961022854\n",
      "epoch =  185  step =  60  of total steps  106  loss =  0.01268705353140831\n",
      "epoch =  185  step =  80  of total steps  106  loss =  0.029500778764486313\n",
      "epoch =  185  step =  100  of total steps  106  loss =  0.02335425652563572\n",
      "epoch =  186  step =  0  of total steps  106  loss =  0.026075951755046844\n",
      "epoch =  186  step =  20  of total steps  106  loss =  0.017659932374954224\n",
      "epoch =  186  step =  40  of total steps  106  loss =  0.020733267068862915\n",
      "epoch =  186  step =  60  of total steps  106  loss =  0.01661141961812973\n",
      "epoch =  186  step =  80  of total steps  106  loss =  0.017726609483361244\n",
      "epoch =  186  step =  100  of total steps  106  loss =  0.013492850586771965\n",
      "epoch =  187  step =  0  of total steps  106  loss =  0.03020901419222355\n",
      "epoch =  187  step =  20  of total steps  106  loss =  0.009336496703326702\n",
      "epoch =  187  step =  40  of total steps  106  loss =  0.021996982395648956\n",
      "epoch =  187  step =  60  of total steps  106  loss =  0.01990070566534996\n",
      "epoch =  187  step =  80  of total steps  106  loss =  0.021548418328166008\n",
      "epoch =  187  step =  100  of total steps  106  loss =  0.01946132443845272\n",
      "epoch =  188  step =  0  of total steps  106  loss =  0.013477596454322338\n",
      "epoch =  188  step =  20  of total steps  106  loss =  0.013475963845849037\n",
      "epoch =  188  step =  40  of total steps  106  loss =  0.015267765149474144\n",
      "epoch =  188  step =  60  of total steps  106  loss =  0.018663033843040466\n",
      "epoch =  188  step =  80  of total steps  106  loss =  0.031683944165706635\n",
      "epoch =  188  step =  100  of total steps  106  loss =  0.021083535626530647\n",
      "epoch =  189  step =  0  of total steps  106  loss =  0.02402133122086525\n",
      "epoch =  189  step =  20  of total steps  106  loss =  0.018931297585368156\n",
      "epoch =  189  step =  40  of total steps  106  loss =  0.01898364908993244\n",
      "epoch =  189  step =  60  of total steps  106  loss =  0.02263750322163105\n",
      "epoch =  189  step =  80  of total steps  106  loss =  0.016319045796990395\n",
      "epoch =  189  step =  100  of total steps  106  loss =  0.019405536353588104\n",
      "epoch =  190  step =  0  of total steps  106  loss =  0.019517017528414726\n",
      "epoch =  190  step =  20  of total steps  106  loss =  0.021757807582616806\n",
      "epoch =  190  step =  40  of total steps  106  loss =  0.01592441461980343\n",
      "epoch =  190  step =  60  of total steps  106  loss =  0.022783620283007622\n",
      "epoch =  190  step =  80  of total steps  106  loss =  0.021351125091314316\n",
      "epoch =  190  step =  100  of total steps  106  loss =  0.02763887122273445\n",
      "epoch =  191  step =  0  of total steps  106  loss =  0.02298012375831604\n",
      "epoch =  191  step =  20  of total steps  106  loss =  0.028734562918543816\n",
      "epoch =  191  step =  40  of total steps  106  loss =  0.013412166386842728\n",
      "epoch =  191  step =  60  of total steps  106  loss =  0.012766137719154358\n",
      "epoch =  191  step =  80  of total steps  106  loss =  0.018925603479146957\n",
      "epoch =  191  step =  100  of total steps  106  loss =  0.020057791844010353\n",
      "epoch =  192  step =  0  of total steps  106  loss =  0.0255915317684412\n",
      "epoch =  192  step =  20  of total steps  106  loss =  0.02010163851082325\n",
      "epoch =  192  step =  40  of total steps  106  loss =  0.019515201449394226\n",
      "epoch =  192  step =  60  of total steps  106  loss =  0.021710596978664398\n",
      "epoch =  192  step =  80  of total steps  106  loss =  0.011438525281846523\n",
      "epoch =  192  step =  100  of total steps  106  loss =  0.016625188291072845\n",
      "epoch =  193  step =  0  of total steps  106  loss =  0.012767289765179157\n",
      "epoch =  193  step =  20  of total steps  106  loss =  0.02316931076347828\n",
      "epoch =  193  step =  40  of total steps  106  loss =  0.01978534646332264\n",
      "epoch =  193  step =  60  of total steps  106  loss =  0.022805416956543922\n",
      "epoch =  193  step =  80  of total steps  106  loss =  0.017800167202949524\n",
      "epoch =  193  step =  100  of total steps  106  loss =  0.029251649975776672\n",
      "epoch =  194  step =  0  of total steps  106  loss =  0.01386266015470028\n",
      "epoch =  194  step =  20  of total steps  106  loss =  0.017436621710658073\n",
      "epoch =  194  step =  40  of total steps  106  loss =  0.02352570742368698\n",
      "epoch =  194  step =  60  of total steps  106  loss =  0.01133517175912857\n",
      "epoch =  194  step =  80  of total steps  106  loss =  0.01120840385556221\n",
      "epoch =  194  step =  100  of total steps  106  loss =  0.027374353259801865\n",
      "epoch =  195  step =  0  of total steps  106  loss =  0.022171657532453537\n",
      "epoch =  195  step =  20  of total steps  106  loss =  0.02290632203221321\n",
      "epoch =  195  step =  40  of total steps  106  loss =  0.0371355265378952\n",
      "epoch =  195  step =  60  of total steps  106  loss =  0.021422557532787323\n",
      "epoch =  195  step =  80  of total steps  106  loss =  0.020577406510710716\n",
      "epoch =  195  step =  100  of total steps  106  loss =  0.01115246582776308\n",
      "epoch =  196  step =  0  of total steps  106  loss =  0.028249071910977364\n",
      "epoch =  196  step =  20  of total steps  106  loss =  0.02062143199145794\n",
      "epoch =  196  step =  40  of total steps  106  loss =  0.024664869531989098\n",
      "epoch =  196  step =  60  of total steps  106  loss =  0.024370668455958366\n",
      "epoch =  196  step =  80  of total steps  106  loss =  0.018620988354086876\n",
      "epoch =  196  step =  100  of total steps  106  loss =  0.016916323453187943\n",
      "epoch =  197  step =  0  of total steps  106  loss =  0.02353299967944622\n",
      "epoch =  197  step =  20  of total steps  106  loss =  0.02846534550189972\n",
      "epoch =  197  step =  40  of total steps  106  loss =  0.010304213501513004\n",
      "epoch =  197  step =  60  of total steps  106  loss =  0.030562274158000946\n",
      "epoch =  197  step =  80  of total steps  106  loss =  0.011604119092226028\n",
      "epoch =  197  step =  100  of total steps  106  loss =  0.01365220919251442\n",
      "epoch =  198  step =  0  of total steps  106  loss =  0.018332665786147118\n",
      "epoch =  198  step =  20  of total steps  106  loss =  0.017537135630846024\n",
      "epoch =  198  step =  40  of total steps  106  loss =  0.017305785790085793\n",
      "epoch =  198  step =  60  of total steps  106  loss =  0.01652865670621395\n",
      "epoch =  198  step =  80  of total steps  106  loss =  0.019143594428896904\n",
      "epoch =  198  step =  100  of total steps  106  loss =  0.025139523670077324\n",
      "epoch =  199  step =  0  of total steps  106  loss =  0.013049421831965446\n",
      "epoch =  199  step =  20  of total steps  106  loss =  0.019507382065057755\n",
      "epoch =  199  step =  40  of total steps  106  loss =  0.021348996087908745\n",
      "epoch =  199  step =  60  of total steps  106  loss =  0.019891861826181412\n",
      "epoch =  199  step =  80  of total steps  106  loss =  0.013300249353051186\n",
      "epoch =  199  step =  100  of total steps  106  loss =  0.023297585546970367\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "total_step = len(dataset) // (batch_size * 150)\n",
    "train_loss_list = list()\n",
    "min_loss = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, signals in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            signals = Variable(signals).cuda().float()\n",
    "        else : \n",
    "            signals = Variable(signals).float()\n",
    "        \n",
    "        reconstr = Net.forward(signals)\n",
    "        signal_ = signals.view(-1, 3, 150).float()\n",
    "        loss = criterion(reconstr, signal_)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    if train_loss < min_loss : \n",
    "        min_loss = train_loss\n",
    "        torch.save(Net.state_dict() , '../../saved_models/autoencoder3.pt')\n",
    "        print('Saving model', min_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb8efdb64a8>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAew0lEQVR4nO3de5BdVZ328e+TbpIQDESSDpfOFRORgHJJE3QUSgmBQKlBgZfgLaVMBRx4a6amrDKU71DAeANLGS+MyggKGTSMKNrOBIMjMFoOxHQgMYkh0ImBNB1C5yrkfvm9f6zdnXPr9OnQ6W7Yz6fqVO+z9zr7rL3OPvs5a60+3YoIzMwsfwb0dQXMzKxvOADMzHLKAWBmllMOADOznHIAmJnlVG1fV6A7RowYEePGjevrapiZvaEsXrx4Y0TUla6vKgAkTQe+CdQAP4iIr5ZsHwTcD0wGNgFXR8RaSeOAlcCqrOhTEXF99pjJwI+Ao4H5wN9HF7+TOm7cOJqamqqpspmZZSS9UGl9l0NAkmqAu4BLgUnANZImlRS7FtgSEROAO4HbC7atjoizstv1Beu/C8wGJma36dUejJmZvX7VzAFMAZojYk1E7AHmATNKyswA7suWHwKmSlJnO5R0EnBsRDyZfeq/H7i827U3M7PDVk0A1APrCu63ZOsqlomIfcA2YHi2bbykZyT9j6TzC8q3dLFPMzM7gqqZA6j0Sb50rL6zMuuBMRGxKRvz/4Wk06vcZ9qxNJs0VMSYMWOqqK6ZmVWjmh5ACzC64P4ooLWzMpJqgeOAzRGxOyI2AUTEYmA18Pas/Kgu9kn2uLsjoiEiGurqyiaxzczsMFUTAIuAiZLGSxoIzAQaS8o0ArOy5SuBxyIiJNVlk8hIOoU02bsmItYDr0p6dzZX8Cnglz1wPGZmVqUuh4AiYp+kG4EFpF8DvTciVki6DWiKiEbgHmCupGZgMykkAC4AbpO0D9gPXB8Rm7Ntn+Xgr4E+kt3MzKyX6I3056AbGhrisL4H8O1vw8iRcPXVPV8pM7N+TtLiiGgoXZ+PPwXxve/BQw/1dS3MzPqVfATAgAFw4EBf18LMrF9xAJiZ5VR+AmD//r6uhZlZv5KPAKipcQ/AzKxEPgLAQ0BmZmUcAGZmOZWfAPAcgJlZkXwEgOcAzMzK5CMAPARkZlYmPwHgISAzsyL5CQD3AMzMiuQjADwHYGZWJh8B4B6AmVmZ/ASA5wDMzIrkIwA8BGRmViYfAeAhIDOzMg4AM7Ocyk8AeA7AzKxIPgLAcwBmZmXyEQAeAjIzK+MAMDPLqfwEgOcAzMyK5CMAPAdgZlYmHwHgISAzszJVBYCk6ZJWSWqWNKfC9kGSHsy2L5Q0rmT7GEmvSfpcwbq1kpZJWiKp6fUeyCE5AMzMynQZAJJqgLuAS4FJwDWSJpUUuxbYEhETgDuB20u23wk8UmH3H4iIsyKiods17w7PAZiZlammBzAFaI6INRGxB5gHzCgpMwO4L1t+CJgqSQCSLgfWACt6psqHwXMAZmZlqgmAemBdwf2WbF3FMhGxD9gGDJd0DPB54NYK+w3gUUmLJc3u7MklzZbUJKmpra2tiupW4CEgM7My1QSAKqyLKsvcCtwZEa9V2P7eiDiHNLR0g6QLKj15RNwdEQ0R0VBXV1dFdStwAJiZlamtokwLMLrg/iigtZMyLZJqgeOAzcB5wJWS7gCGAQck7YqI70REK0BEvCLpYdJQ0+9e19F0xnMAZmZlqukBLAImShovaSAwE2gsKdMIzMqWrwQei+T8iBgXEeOAfwG+HBHfkXSMpKEA2TDRxcDyHjieyjwHYGZWpsseQETsk3QjsACoAe6NiBWSbgOaIqIRuAeYK6mZ9Ml/Zhe7PQF4OJsnrgV+HBG/fh3HcWgeAjIzK1PNEBARMR+YX7Lu5oLlXcBVXezjloLlNcCZ3ano6+IAMDMrk59vAnsOwMysSD4CwHMAZmZl8hEAHgIyMyuTnwDwEJCZWZH8BABAlH5/zcwsv/IRADU16aeHgczMOuQjANp7AA4AM7MO+QoAzwOYmXXIVwC4B2Bm1iEfAeA5ADOzMvkIAPcAzMzK5CsAPAdgZtYhHwHgISAzszL5CAAPAZmZlXEAmJnlVL4CwHMAZmYd8hEAngMwMyuTjwDwEJCZWRkHgJlZTuUrADwHYGbWIR8B4DkAM7My+QgADwGZmZVxAJiZ5VS+AsBzAGZmHaoKAEnTJa2S1CxpToXtgyQ9mG1fKGlcyfYxkl6T9Llq99mjPAdgZlamywCQVAPcBVwKTAKukTSppNi1wJaImADcCdxesv1O4JFu7rPneAjIzKxMNT2AKUBzRKyJiD3APGBGSZkZwH3Z8kPAVEkCkHQ5sAZY0c199hwHgJlZmWoCoB5YV3C/JVtXsUxE7AO2AcMlHQN8Hrj1MPYJgKTZkpokNbW1tVVR3Qo8B2BmVqaaAFCFdVFlmVuBOyPitcPYZ1oZcXdENEREQ11dXZeVrchzAGZmZWqrKNMCjC64Pwpo7aRMi6Ra4DhgM3AecKWkO4BhwAFJu4DFVeyz53gIyMysTDUBsAiYKGk88BIwE/hYSZlGYBbwJHAl8FhEBHB+ewFJtwCvRcR3spDoap89x0NAZmZlugyAiNgn6UZgAVAD3BsRKyTdBjRFRCNwDzBXUjPpk//Mw9nn6zyWzrkHYGZWppoeABExH5hfsu7mguVdwFVd7OOWrvZ5xHgOwMysTL6+CewAMDPrkK8A8ByAmVmHfAWAewBmZh3yEQCeAzAzK5OPAHAPwMysTL4CwHMAZmYd8hEAHgIyMyuTjwDwEJCZWRkHgJlZTuUrADwHYGbWIR8B4DkAM7My+QgADwGZmZVxAJiZ5VS+AsBzAGZmHfIRAJ4DMDMrk48A8BCQmVkZB4CZWU7lKwA8B2Bm1iEfAeA5ADOzMvkIAA8BmZmVcQCYmeVUvgLAcwBmZh3yEQCeAzAzK5OPAPAQkJlZmXwFgIeAzMw6VBUAkqZLWiWpWdKcCtsHSXow275Q0rhs/RRJS7LbUkkfKXjMWknLsm1NPXVAFbkHYGZWprarApJqgLuAaUALsEhSY0T8uaDYtcCWiJggaSZwO3A1sBxoiIh9kk4Clkr6VUTsyx73gYjY2JMHVJHnAMzMylTTA5gCNEfEmojYA8wDZpSUmQHcly0/BEyVpIjYUXCxHwxET1S629wDMDMrU00A1APrCu63ZOsqlsku+NuA4QCSzpO0AlgGXF8QCAE8KmmxpNmdPbmk2ZKaJDW1tbVVc0yVdpJ+eg7AzKxDNQGgCutKP8l3WiYiFkbE6cC5wE2SBmfb3xsR5wCXAjdIuqDSk0fE3RHREBENdXV1VVS3EwMGuAdgZlagmgBoAUYX3B8FtHZWRlItcBywubBARKwEtgNnZPdbs5+vAA+ThpqOnJoaB4CZWYFqAmARMFHSeEkDgZlAY0mZRmBWtnwl8FhERPaYWgBJY4FTgbWSjpE0NFt/DHAxacL4yHEPwMysSJe/BZT9Bs+NwAKgBrg3IlZIug1oiohG4B5grqRm0if/mdnD3wfMkbQXOAD8XURslHQK8LDS2Hwt8OOI+HVPH1yRAQM8B2BmVqDLAACIiPnA/JJ1Nxcs7wKuqvC4ucDcCuvXAGd2t7Kvi3sAZmZF8vFNYPAcgJlZifwEgHsAZmZF8hUAngMwM+uQnwDwEJCZWZH8BICHgMzMijgAzMxyKl8B4DkAM7MO+QkAzwGYmRXJTwB4CMjMrIgDwMwsp/IVAJ4DMDPrkJ8A8ByAmVmR/ASAh4DMzIo4AMzMcipfAeA5ADOzDvkJAM8BmJkVyU8AeAjIzKxIvgLAQ0BmZh3yFQDuAZiZdchPAHgOwMysSH4CwD0AM7Mi+QoAzwGYmXXIVwC4B2Bm1iE/AeA5ADOzIlUFgKTpklZJapY0p8L2QZIezLYvlDQuWz9F0pLstlTSR6rdZ49zD8DMrEiXASCpBrgLuBSYBFwjaVJJsWuBLRExAbgTuD1bvxxoiIizgOnA9yXVVrnPnuU5ADOzItX0AKYAzRGxJiL2APOAGSVlZgD3ZcsPAVMlKSJ2RMS+bP1gILqxz57lHoCZWZFqAqAeWFdwvyVbV7FMdsHfBgwHkHSepBXAMuD6bHs1+yR7/GxJTZKa2traqqhuJzwHYGZWpJoAUIV1UW2ZiFgYEacD5wI3SRpc5T7JHn93RDRERENdXV0V1e2EewBmZkWqCYAWYHTB/VFAa2dlJNUCxwGbCwtExEpgO3BGlfvsWZ4DMDMrUk0ALAImShovaSAwE2gsKdMIzMqWrwQei4jIHlMLIGkscCqwtsp99iz3AMzMitR2VSAi9km6EVgA1AD3RsQKSbcBTRHRCNwDzJXUTPrkPzN7+PuAOZL2AgeAv4uIjQCV9tnDx1bMcwBmZkW6DACAiJgPzC9Zd3PB8i7gqgqPmwvMrXafR5R7AGZmRfLzTWDPAZiZFclPAHgIyMysSH4CwENAZmZFHABmZjmVrwDwHICZWYf8BIDnAMzMiuQnADwEZGZWxAFgZpZT+QoAzwGYmXXITwB4DsDMrEh+AsBDQGZmRRwAZmY5la8A8ByAmVmH/ASA5wDMzIrkJwA8BGRmViRfAeAhIDOzDvkKAPcAzMw65CcAamogIt3MzCxHATAgO1QHgJkZkMcA8DyAmRmQxwDwPICZGZCnAKipST8dAGZmQJ4CwD0AM7Mi+QsAzwGYmQF5DAD3AMzMgCoDQNJ0SaskNUuaU2H7IEkPZtsXShqXrZ8mabGkZdnPCwse80S2zyXZbWRPHVRFngMwMytS21UBSTXAXcA0oAVYJKkxIv5cUOxaYEtETJA0E7gduBrYCHwoIlolnQEsAOoLHvfxiGjqoWM5NPcAzMyKVNMDmAI0R8SaiNgDzANmlJSZAdyXLT8ETJWkiHgmIlqz9SuAwZIG9UTFu81zAGZmRaoJgHpgXcH9Foo/xReViYh9wDZgeEmZK4BnImJ3wbofZsM//yRJlZ5c0mxJTZKa2traqqhuJzwEZGZWpJoAqHRhLv17CocsI+l00rDQdQXbPx4R7wTOz26frPTkEXF3RDRERENdXV0V1e2Eh4DMzIpUEwAtwOiC+6OA1s7KSKoFjgM2Z/dHAQ8Dn4qI1e0PiIiXsp+vAj8mDTUdOQ4AM7Mi1QTAImCipPGSBgIzgcaSMo3ArGz5SuCxiAhJw4D/Am6KiD+0F5ZUK2lEtnwU8EFg+es7lC54DsDMrEiXAZCN6d9I+g2elcB/RMQKSbdJ+nBW7B5guKRm4B+B9l8VvRGYAPxTya97DgIWSPoTsAR4Cfi3njywMp4DMDMr0uWvgQJExHxgfsm6mwuWdwFXVXjcF4EvdrLbydVXswd4CMjMrIi/CWxmllP5CwDPAZiZAXkKAM8BmJkVyU8AeAjIzKyIA8DMLKfyFwCeAzAzA/IUAG95S/r56qt9Ww8zs34iPwEwYkT6uWlT39bDzKyfyE8ADM/+OOnGjX1bDzOzfsIBYGaWU/kJgKOPhmOO8RCQmVkmPwEAqRfgHoCZGZC3ABgxwj0AM7NMvgLAPQAzsw75CoARIxwAZmaZ/AWAh4DMzIC8BcDw4bB1K+zb19c1MTPrc/kKgPZvA2/e3Lf1MDPrB/IVAP4ymJlZh3wFQHsPwAFgZpbTAPBEsJlZzgLAQ0BmZh3yGQDuAZiZ5SwAhgxJN/cAzMyqCwBJ0yWtktQsaU6F7YMkPZhtXyhpXLZ+mqTFkpZlPy8seMzkbH2zpG9JUk8d1CH5z0GYmQFQ21UBSTXAXcA0oAVYJKkxIv5cUOxaYEtETJA0E7gduBrYCHwoIlolnQEsAOqzx3wXmA08BcwHpgOP9MxhHcKIEfCrX8EVV8Db3pZu9fXwl7/AK6+k/x08YkS6DR4MH/gADBsGzz+fvkQ2dCiMGQPLlkFzM0yffnBoyczsDaTLAACmAM0RsQZA0jxgBlAYADOAW7Llh4DvSFJEPFNQZgUwWNIg4Hjg2Ih4Mtvn/cDl9EYAfP7zcP/9sGIF/Od/wp49B7dJEFFc/q1vhTPPhCeeqLy/o46C8ePT/xsYPBje+U6YNg3WrElhMmUKTJ6clpcsgRdegL17034feSQFz8SJKWTq6+FjH4Njj4U//xl+8APYuTNt//Sn0/rWVjjxxPRt5pdfhlGjYP16+M1v4MABGDgwhdRll6X6vPIKHH881NamuY9Bgw7+f+RDiYCXXoJt29I+Bw6EkSPT4x99NB3PtGmpzczsDamaAKgH1hXcbwHO66xMROyTtA0YTuoBtLsCeCYidkuqz/ZTuM96KpA0m9RTYMyYMVVUtwtXX51ukC6YL70ELS0wdiycdFK68LW1pW8Lt7XBV74Czz4LX/5yurhv3Zou2qecknoPP/85vPhiulBv3w7z5qULd/FBpNuBA8XrhwyBU0+FJ59M/6w+Aj73ubS+rS1dbIcOTUNWt9ySLuJbtkBNTdpXRAqgvXvLj/Pss+Gss+CHP4S6Ojj5ZFi6NG0bOjTdb7+NHJnq8Kc/wd/8TdrvkiXlk+W1talsa2u6P3UqfPCDcPrp8J73pHrV1KSwaLdrF6xdC7t3p/YbMAD270/ht3dvCsfRo9PxrF+felNHH50e2x7GpSGzdWtq6/r6FHDPPw+nnQbLl8PKlem1nDAh/aytTcf17LPwoQ+ltm23d296ztGj03Ns355ezwMH4OMfT48ttGtXel3a2lL5M89MP3ftOljnUqtWpWOeOBGeey59ABg5Mt12707bhwyBE05Ix/7ii6le556bjn/TpvR6DR5cvu8DB+C112DHjhTyhe3e7sUXU7uccUbqubbbuTM9tq4ONmxI7TZ+fKrTzp0HX6t2+/fD73+f1p14IowbV/x8zzyTyjQ0pA8ma9emY6ipqdwuW7emDzkNDZXrDamdn34a3vWu9KFl2bLUNkOHpvffsGHlj9m+Pb1vamvTh6SamoPnz/79afuxx6Z9//GPqV3Gji1v18Jj37UrvQfr66v/wBNRXdn28/7ll2HSpPLzqLk5vSbHH5/OkQE9O21bTQBUOoroThlJp5OGhS7uxj7Tyoi7gbsBGhoaKpY5bAMGpDf/6NEH10mpoU84IV1ULrjg0Pt497uL7+/cmU7UiRPTCbdoUbrt35/eEG97W7pob9iQLiCFn8abmlJ4RMA73gGf/GQailq2DL7+9VTfhoZ0AR44MAXW6tWpN/HhD6c3xt696U0ze3a68N1wQzp5N2yAL30pvTFaW1PwtbbCH/6QTsDTToNPfAKeeirt+yMfSfWrq0v73LMnnYzPPpuGzzZvhn/+Z/jtb4uP/9hj4W//Np2wf/wjLFiQTmBIF73TTkvP3dx88DF1delN9uqr6X5hwNXWpn2232prU5Dt35/evKtWVQ7AdoUBeeKJ8N73pvZoa0ttt3t3eo1PPTWFd3sd7rgjXeTaL/htbeniUeiEE9JFpv0iffLJ6fXasSNdhPbsSa8FpNd99epDn0uFxo+Hv/71YAhPmwaf+hQ88EB6DbZuTb2zwh7rySen51m5MoXJJz6RjqP9mKZPhwsvTMfZ3oYnnpjOjdKeb319uiANGwbXXQff/jb88pcHt9fWpt7t2LEp2BYvTus/+lH47/9OdT/hhNQO27al8/zyy+HKK+Hf/x1+8pPUTsOGwUUXpXr//vfp3Ni//2APt11nvfNTTknBtnFjqseGDel98pa3pDocdVR6joj04Wn//nQebtqUlgHOPx++//3ULr/4RRodGDAgvf7ve18aKWhrS23a0JDOldraVNfnn0+v686d6VjHjUvH+/LL6cPUqaemoH388VS3IUPSfyasr0/vhSeeSB9AIZ1D73pXel+2n0crVhw83tdeS4/tQYrSRi0tIL0HuCUiLsnu3wQQEV8pKLMgK/OkpFrgZaAuIkLSKOAx4NMR8Yes/EnA4xHxjuz+NcD7I+K6Q9WloaEhmpqaDvNQc2bDhnQivv3tR+45ItIb7+mn08W+/eL805+mC/jYsTBjxsFPs48+mj4B19bCZz+bgnfx4vT4wYPTBX3LlnTiDxiQbnv2pDdy+23nzvQmHDoUfv1rOOcceP/700VvwoTUo1i3LgXMunXpoj1xYrpIfO1r6U07YkQKnfHjU1B961vpInnVVfCZz6Q3+5e/nI6xri7d2h/Tfnv11fT8Rx99MChaW9OFZciQVO+dO9NF78CBNEQ3dWrqKbW1pZ5LTU0K+t270+vV/ilzxw548MF0oTr77FT2X/81XfTr69O81Fvfmi5sw4alOrS1pYvRmjXporNwYfqEfd558MUvpg8hd9yR9jFlClx8cXrsM8+k9jnvvNReRx+dLoyNjel4Vq8+2OP56ldTe7/0UmrvJ55I2046KbXdunXwjW+k+s2aldqn/QL88svws5+lfQ8ZkoY6L7wwfUB44onUUzn33FT3o45KbTN2bFq3ZElqy8mT0wVw8+bUC1+zJv184YX0+kycmIJk16507h9/fFreujW9lsOHp/PmuedSOF10UTr3br01XVwhvUYNDWl56dJUtwsvhEsuSR+omppSmxw4kI57woR0Gzo0vW5/+UtaHjECfve79OGqpiYFyYQJqcz27Wkfy5enD5CXXJLKL1iQXsP6+nQe7duXPoiNHJneF9ddd9hDrpIWR0RDhfdwHPJG6iWsAcYDA4GlwOklZW4AvpctzwT+I1selpW/osJ+FwHvJvUGHgEu66oukydPDnsD2LIlYseOvq5F9Xbv7v/13bgx4je/SXWtxt69EY8/HrFr18F1W7ZENDd373m3b4/45jcjfvWr6spv2BBx4EDlbc8+G/HAAxFbt5Zvq/a4joTnnou4/vqI//3fvqvDEQY0RYVrapc9gCw9LgP+BagB7o2IL0m6Ldtpo6TBwFzgbGAzMDMi1kj6f8BNwPMFu7s4Il6R1AD8CDg6C4D/G11Uxj0AM7Pu66wHUFUA9BcOADOz7ussAPL1TWAzM+vgADAzyykHgJlZTjkAzMxyygFgZpZTDgAzs5xyAJiZ5dQb6nsAktqAFw7z4SMo/uN0/YXr1X39tW6uV/f013pB/63b4dZrbETUla58QwXA6yGpqdIXIfqa69V9/bVurlf39Nd6Qf+tW0/Xy0NAZmY55QAwM8upPAXA3X1dgU64Xt3XX+vmenVPf60X9N+69Wi9cjMHYGZmxfLUAzAzswIOADOznHrTB4Ck6ZJWSWqWNKeP6zJa0uOSVkpaIenvs/W3SHpJ0pLsdlkf1G2tpGXZ8zdl646X9BtJz2c/39rLdTq1oE2WSPqrpH/oq/aSdK+kVyQtL1hXsY2UfCs77/4k6ZxertfXJD2bPffDkoZl68dJ2lnQdt/r5Xp1+tpJuilrr1WSLunlej1YUKe1kpZk63uzvTq7Phy5c6zSvwl7s9xI/8FsNXAKB/+d5aQ+rM9JwDnZ8lDgOWAScAvwuT5uq7XAiJJ1dwBzsuU5wO19/Fq+DIztq/YCLgDOAZZ31UbAZaT/dCfSvz5d2Mv1uhiozZZvL6jXuMJyfdBeFV+77H2wFBhE+vezq4Ga3qpXyfavAzf3QXt1dn04YufYm70HMAVojog1EbEHmAfM6KvKRMT6iHg6W34VWAnU91V9qjADuC9bvg+4vA/rMhVYHRGH+03w1y0ifkf6l6eFOmujGcD9kTwFDJN0Um/VKyIejYh92d2ngFFH4rm7W69DmAHMi4jdEfEXoJn0/u3VekkS8H+AnxyJ5z6UQ1wfjtg59mYPgHpgXcH9FvrJBVfSONL/UF6Yrbox68bd29tDLZkAHpW0WNLsbN0JEbEe0skJjOyDerWbSfGbsq/bq11nbdSfzr3PkD4pthsv6RlJ/yPp/D6oT6XXrr+01/nAhogo/D/mvd5eJdeHI3aOvdkDQBXW9fnvvUp6C/Az4B8i4q/Ad4G3AWcB60ld0N723og4B7gUuEHSBX1Qh4okDQQ+DPw0W9Uf2qsr/eLck/QFYB/wQLZqPTAmIs4G/hH4saRje7FKnb12/aK9gGso/qDR6+1V4frQadEK67rVZm/2AGgBRhfcHwW09lFdAJB0FOnFfSAifg4QERsiYn9EHAD+jSPU9T2UiGjNfr4CPJzVYUN7lzL7+Upv1ytzKfB0RGzI6tjn7VWgszbq83NP0izgg8DHIxs0zoZYNmXLi0lj7W/vrTod4rXrD+1VC3wUeLB9XW+3V6XrA0fwHHuzB8AiYKKk8dmnyJlAY19VJhtfvAdYGRHfKFhfOG73EWB56WOPcL2OkTS0fZk0gbic1FazsmKzgF/2Zr0KFH0q6+v2KtFZGzUCn8p+U+PdwLb2bnxvkDQd+Dzw4YjYUbC+TlJNtnwKMBFY04v16uy1awRmShokaXxWrz/2Vr0yFwHPRkRL+4rebK/Org8cyXOsN2a3+/JGmil/jpTcX+jjuryP1EX7E7Aku10GzAWWZesbgZN6uV6nkH4DYymwor2dgOHAb4Hns5/H90GbDQE2AccVrOuT9iKF0HpgL+nT17WdtRGpe35Xdt4tAxp6uV7NpPHh9vPse1nZK7LXeCnwNPChXq5Xp68d8IWsvVYBl/ZmvbL1PwKuLynbm+3V2fXhiJ1j/lMQZmY59WYfAjIzs044AMzMcsoBYGaWUw4AM7OccgCYmeWUA8DMLKccAGZmOfX/AXBV18o/LFOIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = range(200)\n",
    "plt.plot(j, train_loss_list, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying that AutoEncoder has not learnt the identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[ 0.0244,  0.2461,  0.1165],\n",
      "         [-0.0238, -0.1481,  0.0442],\n",
      "         [ 0.2591,  0.3036, -0.0556]],\n",
      "\n",
      "        [[ 0.1020, -0.0845, -0.2556],\n",
      "         [-0.2310, -0.2961,  0.0433],\n",
      "         [-0.3245,  0.3056, -0.0766]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0823, -0.2130, -0.3083],\n",
      "         [ 0.0938, -0.2220, -0.3162]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[-0.2851,  0.0742, -0.3553],\n",
      "         [ 0.2057, -0.0163, -0.1433]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[ 0.0604,  0.0789, -0.2604],\n",
      "         [ 0.2309, -0.0648, -0.0305],\n",
      "         [ 0.2234,  0.0873,  0.2953]],\n",
      "\n",
      "        [[-0.9901, -0.8478, -0.9920],\n",
      "         [-1.0286, -0.7672, -0.9757],\n",
      "         [-0.8276, -0.9567, -0.8743]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(Net.encoder[0].weight)\n",
    "print(Net.encoder[2].weight)\n",
    "print(Net.decoder[0].weight)\n",
    "print(Net.decoder[2].weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking reconstruction quality visually\n",
    "This part is not properly working, since there is some problem during reshaping that changes the representation of the data.\n",
    "Need to fix this (MEDIUM-PRIORITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../../saved_models/autoencoder3.pt'))\n",
    "Net = Net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 150, 3)\n",
      "(1, 150, 3)\n",
      "tensor(0.0098, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = next(iter(trainloader2))\n",
    "# plt.plot(x.detach().numpy()[0])\n",
    "y = Net.forward(x.float())\n",
    "loss = criterion(x.float(), torch.transpose(y, 1, 2))\n",
    "\n",
    "x = x.detach().numpy()\n",
    "y = torch.transpose(y, 1, 2)\n",
    "y = y.detach().numpy()\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x[0], 'r')\n",
    "ax.plot(y[0], 'b')\n",
    "criterion = nn.MSELoss()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120150, 8)\n",
      "(19950, 8)\n",
      "(20100, 8)\n"
     ]
    }
   ],
   "source": [
    "reqd_len = 150\n",
    "channels = 3\n",
    "class IMUDataset(Dataset):\n",
    "    def __init__(self, mode = 'test', transform = None):\n",
    "        if mode == 'train' :\n",
    "            self.df = pd.read_csv('../data/train.csv', header = None)\n",
    "        elif mode == 'test' :\n",
    "            self.df = pd.read_csv('../data/test.csv', header = None)\n",
    "        elif mode == 'val' :\n",
    "            self.df = pd.read_csv('../data/val.csv', header = None)\n",
    "        self.transform = transform\n",
    "        print(self.df.shape)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        y = self.df.iloc[idx : idx + reqd_len, 3 : ].values\n",
    "        ind = np.argmax(np.sum(y, axis = 0))\n",
    "        label = np.zeros_like(self.df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        x = self.df.iloc[idx : idx + reqd_len, : channels].values\n",
    "        x = x.astype('float')\n",
    "        x = x.reshape(reqd_len, channels)\n",
    "        assert(x.shape == (reqd_len, channels))\n",
    "        assert(label.shape == (5, ))\n",
    "        return x, label\n",
    "        \n",
    "trainset = IMUDataset(mode = 'train')\n",
    "valset = IMUDataset(mode = 'val')\n",
    "testset = IMUDataset(mode = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 8\n",
    "batch_size = 8\n",
    "train_indices = [(i * reqd_len) for i in range(len(trainset) // reqd_len)]\n",
    "val_indices = [(i * reqd_len) for i in range(len(valset) // reqd_len)]\n",
    "test_indices = [(i * reqd_len) for i in range(len(testset) // reqd_len)]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size = train_batch_size, sampler = SubsetRandomSampler(train_indices), drop_last = True)\n",
    "valloader = DataLoader(valset, batch_size = batch_size, sampler = SubsetRandomSampler(val_indices), drop_last = True)\n",
    "testloader = DataLoader(testset, batch_size = batch_size, sampler = SubsetRandomSampler(test_indices), drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading autoencoder saved model\n",
    "Net = AutoEncoder()\n",
    "Net.load_state_dict(torch.load('../saved_models/autoencoder2.pt'), strict = False)\n",
    "# # freezing encoder and decoder layers\n",
    "Net.encoder[0].requires_grad = False\n",
    "Net.encoder[2].requires_grad = False\n",
    "Net.decoder[0].requires_grad = False\n",
    "Net.decoder[2].requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Net.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  0  step =  0  of total steps  100  loss =  1.603764533996582\n",
      "epoch =  0  step =  20  of total steps  100  loss =  1.6434917449951172\n",
      "epoch =  0  step =  40  of total steps  100  loss =  1.6929755210876465\n",
      "epoch =  0  step =  60  of total steps  100  loss =  1.5619838237762451\n",
      "epoch =  0  step =  80  of total steps  100  loss =  1.4808571338653564\n",
      "epoch :  0  /  30  | TL :  1.539853526353836  | VL :  1.4440586566925049\n",
      "saving model\n",
      "epoch =  1  step =  0  of total steps  100  loss =  1.6428272724151611\n",
      "epoch =  1  step =  20  of total steps  100  loss =  1.2799149751663208\n",
      "epoch =  1  step =  40  of total steps  100  loss =  1.3775889873504639\n",
      "epoch =  1  step =  60  of total steps  100  loss =  1.4892210960388184\n",
      "epoch =  1  step =  80  of total steps  100  loss =  1.460293173789978\n",
      "epoch :  1  /  30  | TL :  1.5201008546352386  | VL :  1.4443871974945068\n",
      "epoch =  2  step =  0  of total steps  100  loss =  1.3750784397125244\n",
      "epoch =  2  step =  20  of total steps  100  loss =  1.56180739402771\n",
      "epoch =  2  step =  40  of total steps  100  loss =  1.4915727376937866\n",
      "epoch =  2  step =  60  of total steps  100  loss =  1.4721105098724365\n",
      "epoch =  2  step =  80  of total steps  100  loss =  1.283617615699768\n",
      "epoch :  2  /  30  | TL :  1.5206562757492066  | VL :  1.4319918155670166\n",
      "saving model\n",
      "epoch =  3  step =  0  of total steps  100  loss =  1.411718726158142\n",
      "epoch =  3  step =  20  of total steps  100  loss =  1.3124791383743286\n",
      "epoch =  3  step =  40  of total steps  100  loss =  1.7939589023590088\n",
      "epoch =  3  step =  60  of total steps  100  loss =  1.5770286321640015\n",
      "epoch =  3  step =  80  of total steps  100  loss =  1.6869001388549805\n",
      "epoch :  3  /  30  | TL :  1.520629367828369  | VL :  1.4521781206130981\n",
      "epoch =  4  step =  0  of total steps  100  loss =  1.6595453023910522\n",
      "epoch =  4  step =  20  of total steps  100  loss =  1.3727600574493408\n",
      "epoch =  4  step =  40  of total steps  100  loss =  1.5114166736602783\n",
      "epoch =  4  step =  60  of total steps  100  loss =  1.6600677967071533\n",
      "epoch =  4  step =  80  of total steps  100  loss =  1.5330820083618164\n",
      "epoch :  4  /  30  | TL :  1.5203277790546417  | VL :  1.4450033903121948\n",
      "epoch =  5  step =  0  of total steps  100  loss =  1.2106257677078247\n",
      "epoch =  5  step =  20  of total steps  100  loss =  1.3849338293075562\n",
      "epoch =  5  step =  40  of total steps  100  loss =  1.5657110214233398\n",
      "epoch =  5  step =  60  of total steps  100  loss =  1.7990883588790894\n",
      "epoch =  5  step =  80  of total steps  100  loss =  1.676414132118225\n",
      "epoch :  5  /  30  | TL :  1.5202074182033538  | VL :  1.4374722242355347\n",
      "epoch =  6  step =  0  of total steps  100  loss =  1.4960112571716309\n",
      "epoch =  6  step =  20  of total steps  100  loss =  1.6000771522521973\n",
      "epoch =  6  step =  40  of total steps  100  loss =  1.4893662929534912\n",
      "epoch =  6  step =  60  of total steps  100  loss =  1.5385619401931763\n",
      "epoch =  6  step =  80  of total steps  100  loss =  1.486343264579773\n",
      "epoch :  6  /  30  | TL :  1.5185821437835694  | VL :  1.4355295896530151\n",
      "epoch =  7  step =  0  of total steps  100  loss =  1.4495959281921387\n",
      "epoch =  7  step =  20  of total steps  100  loss =  1.4067614078521729\n",
      "epoch =  7  step =  40  of total steps  100  loss =  1.4182645082473755\n",
      "epoch =  7  step =  60  of total steps  100  loss =  1.6312516927719116\n",
      "epoch =  7  step =  80  of total steps  100  loss =  1.5409319400787354\n",
      "epoch :  7  /  30  | TL :  1.5212412524223327  | VL :  1.4322706460952759\n",
      "epoch =  8  step =  0  of total steps  100  loss =  1.4187558889389038\n",
      "epoch =  8  step =  20  of total steps  100  loss =  1.6381789445877075\n",
      "epoch =  8  step =  40  of total steps  100  loss =  1.3897569179534912\n",
      "epoch =  8  step =  60  of total steps  100  loss =  1.3923466205596924\n",
      "epoch =  8  step =  80  of total steps  100  loss =  1.5467721223831177\n",
      "epoch :  8  /  30  | TL :  1.5195820951461791  | VL :  1.4313175678253174\n",
      "saving model\n",
      "epoch =  9  step =  0  of total steps  100  loss =  1.620729923248291\n",
      "epoch =  9  step =  20  of total steps  100  loss =  1.7410355806350708\n",
      "epoch =  9  step =  40  of total steps  100  loss =  1.4942688941955566\n",
      "epoch =  9  step =  60  of total steps  100  loss =  1.134628415107727\n",
      "epoch =  9  step =  80  of total steps  100  loss =  1.594810128211975\n",
      "epoch :  9  /  30  | TL :  1.5199006402492523  | VL :  1.4501099586486816\n",
      "epoch =  10  step =  0  of total steps  100  loss =  1.5949844121932983\n",
      "epoch =  10  step =  20  of total steps  100  loss =  1.6156816482543945\n",
      "epoch =  10  step =  40  of total steps  100  loss =  1.1913293600082397\n",
      "epoch =  10  step =  60  of total steps  100  loss =  1.5329241752624512\n",
      "epoch =  10  step =  80  of total steps  100  loss =  1.812302827835083\n",
      "epoch :  10  /  30  | TL :  1.5224783718585968  | VL :  1.450900912284851\n",
      "epoch =  11  step =  0  of total steps  100  loss =  1.407579779624939\n",
      "epoch =  11  step =  20  of total steps  100  loss =  1.6235151290893555\n",
      "epoch =  11  step =  40  of total steps  100  loss =  1.3787604570388794\n",
      "epoch =  11  step =  60  of total steps  100  loss =  1.5616307258605957\n",
      "epoch =  11  step =  80  of total steps  100  loss =  1.754401445388794\n",
      "epoch :  11  /  30  | TL :  1.5197052681446075  | VL :  1.4382681846618652\n",
      "epoch =  12  step =  0  of total steps  100  loss =  1.6473432779312134\n",
      "epoch =  12  step =  20  of total steps  100  loss =  1.1926398277282715\n",
      "epoch =  12  step =  40  of total steps  100  loss =  1.7258530855178833\n",
      "epoch =  12  step =  60  of total steps  100  loss =  1.5661284923553467\n",
      "epoch =  12  step =  80  of total steps  100  loss =  1.463202714920044\n",
      "epoch :  12  /  30  | TL :  1.5206703221797944  | VL :  1.4375255107879639\n",
      "epoch =  13  step =  0  of total steps  100  loss =  1.4677025079727173\n",
      "epoch =  13  step =  20  of total steps  100  loss =  1.128951072692871\n",
      "epoch =  13  step =  40  of total steps  100  loss =  1.6565015316009521\n",
      "epoch =  13  step =  60  of total steps  100  loss =  1.2686868906021118\n",
      "epoch =  13  step =  80  of total steps  100  loss =  1.561907410621643\n",
      "epoch :  13  /  30  | TL :  1.5195549941062927  | VL :  1.4549633264541626\n",
      "epoch =  14  step =  0  of total steps  100  loss =  1.538743019104004\n",
      "epoch =  14  step =  20  of total steps  100  loss =  1.5845896005630493\n",
      "epoch =  14  step =  40  of total steps  100  loss =  1.4945670366287231\n",
      "epoch =  14  step =  60  of total steps  100  loss =  1.3896679878234863\n",
      "epoch =  14  step =  80  of total steps  100  loss =  1.434648036956787\n",
      "epoch :  14  /  30  | TL :  1.5186157464981078  | VL :  1.4242693185806274\n",
      "saving model\n",
      "epoch =  15  step =  0  of total steps  100  loss =  1.6102614402770996\n",
      "epoch =  15  step =  20  of total steps  100  loss =  1.1099605560302734\n",
      "epoch =  15  step =  40  of total steps  100  loss =  1.8501733541488647\n",
      "epoch =  15  step =  60  of total steps  100  loss =  1.4297291040420532\n",
      "epoch =  15  step =  80  of total steps  100  loss =  1.5541871786117554\n",
      "epoch :  15  /  30  | TL :  1.5187674212455748  | VL :  1.4450924396514893\n",
      "epoch =  16  step =  0  of total steps  100  loss =  1.6458706855773926\n",
      "epoch =  16  step =  20  of total steps  100  loss =  1.5271031856536865\n",
      "epoch =  16  step =  40  of total steps  100  loss =  1.2611726522445679\n",
      "epoch =  16  step =  60  of total steps  100  loss =  1.4682618379592896\n",
      "epoch =  16  step =  80  of total steps  100  loss =  1.5603209733963013\n",
      "epoch :  16  /  30  | TL :  1.5211355996131897  | VL :  1.4467949867248535\n",
      "epoch =  17  step =  0  of total steps  100  loss =  1.613018274307251\n",
      "epoch =  17  step =  20  of total steps  100  loss =  1.453971028327942\n",
      "epoch =  17  step =  40  of total steps  100  loss =  1.5403435230255127\n",
      "epoch =  17  step =  60  of total steps  100  loss =  1.520210862159729\n",
      "epoch =  17  step =  80  of total steps  100  loss =  1.6959989070892334\n",
      "epoch :  17  /  30  | TL :  1.5200053286552428  | VL :  1.4524167776107788\n",
      "epoch =  18  step =  0  of total steps  100  loss =  1.7277864217758179\n",
      "epoch =  18  step =  20  of total steps  100  loss =  1.3623011112213135\n",
      "epoch =  18  step =  40  of total steps  100  loss =  1.678553581237793\n",
      "epoch =  18  step =  60  of total steps  100  loss =  1.5287871360778809\n",
      "epoch =  18  step =  80  of total steps  100  loss =  1.2266571521759033\n",
      "epoch :  18  /  30  | TL :  1.5207753276824951  | VL :  1.4372799396514893\n",
      "epoch =  19  step =  0  of total steps  100  loss =  1.5611252784729004\n",
      "epoch =  19  step =  20  of total steps  100  loss =  1.408008337020874\n",
      "epoch =  19  step =  40  of total steps  100  loss =  1.7542239427566528\n",
      "epoch =  19  step =  60  of total steps  100  loss =  1.5434743165969849\n",
      "epoch =  19  step =  80  of total steps  100  loss =  1.4929931163787842\n",
      "epoch :  19  /  30  | TL :  1.5195785164833069  | VL :  1.4520981311798096\n",
      "epoch =  20  step =  0  of total steps  100  loss =  1.211176872253418\n",
      "epoch =  20  step =  20  of total steps  100  loss =  1.4765042066574097\n",
      "epoch =  20  step =  40  of total steps  100  loss =  1.643604040145874\n",
      "epoch =  20  step =  60  of total steps  100  loss =  1.5866198539733887\n",
      "epoch =  20  step =  80  of total steps  100  loss =  1.4692939519882202\n",
      "epoch :  20  /  30  | TL :  1.5212155759334565  | VL :  1.4532629251480103\n",
      "epoch =  21  step =  0  of total steps  100  loss =  1.4550361633300781\n",
      "epoch =  21  step =  20  of total steps  100  loss =  1.5284357070922852\n",
      "epoch =  21  step =  40  of total steps  100  loss =  1.381962776184082\n",
      "epoch =  21  step =  60  of total steps  100  loss =  1.491179347038269\n",
      "epoch =  21  step =  80  of total steps  100  loss =  1.4450626373291016\n",
      "epoch :  21  /  30  | TL :  1.5205009841918946  | VL :  1.4336810111999512\n",
      "epoch =  22  step =  0  of total steps  100  loss =  1.533837914466858\n",
      "epoch =  22  step =  20  of total steps  100  loss =  1.4295780658721924\n",
      "epoch =  22  step =  40  of total steps  100  loss =  1.423389196395874\n",
      "epoch =  22  step =  60  of total steps  100  loss =  1.7886070013046265\n",
      "epoch =  22  step =  80  of total steps  100  loss =  1.5896148681640625\n",
      "epoch :  22  /  30  | TL :  1.5194894504547118  | VL :  1.4546679258346558\n",
      "epoch =  23  step =  0  of total steps  100  loss =  1.4414513111114502\n",
      "epoch =  23  step =  20  of total steps  100  loss =  1.408372402191162\n",
      "epoch =  23  step =  40  of total steps  100  loss =  1.3865852355957031\n",
      "epoch =  23  step =  60  of total steps  100  loss =  1.6561682224273682\n",
      "epoch =  23  step =  80  of total steps  100  loss =  1.59818434715271\n",
      "epoch :  23  /  30  | TL :  1.5192582285404206  | VL :  1.4529545307159424\n",
      "epoch =  24  step =  0  of total steps  100  loss =  1.3663408756256104\n",
      "epoch =  24  step =  20  of total steps  100  loss =  1.4597346782684326\n",
      "epoch =  24  step =  40  of total steps  100  loss =  1.515913486480713\n",
      "epoch =  24  step =  60  of total steps  100  loss =  1.6555931568145752\n",
      "epoch =  24  step =  80  of total steps  100  loss =  1.3876521587371826\n",
      "epoch :  24  /  30  | TL :  1.5207168555259705  | VL :  1.4394984245300293\n",
      "epoch =  25  step =  0  of total steps  100  loss =  1.3850321769714355\n",
      "epoch =  25  step =  20  of total steps  100  loss =  1.521095871925354\n",
      "epoch =  25  step =  40  of total steps  100  loss =  1.399839997291565\n",
      "epoch =  25  step =  60  of total steps  100  loss =  1.6020997762680054\n",
      "epoch =  25  step =  80  of total steps  100  loss =  1.347461223602295\n",
      "epoch :  25  /  30  | TL :  1.5174619960784912  | VL :  1.4417532682418823\n",
      "epoch =  26  step =  0  of total steps  100  loss =  1.5074195861816406\n",
      "epoch =  26  step =  20  of total steps  100  loss =  1.3820929527282715\n",
      "epoch =  26  step =  40  of total steps  100  loss =  1.445395588874817\n",
      "epoch =  26  step =  60  of total steps  100  loss =  1.6327600479125977\n",
      "epoch =  26  step =  80  of total steps  100  loss =  1.4618850946426392\n",
      "epoch :  26  /  30  | TL :  1.519276648759842  | VL :  1.4439672231674194\n",
      "epoch =  27  step =  0  of total steps  100  loss =  1.3475069999694824\n",
      "epoch =  27  step =  20  of total steps  100  loss =  1.45066237449646\n",
      "epoch =  27  step =  40  of total steps  100  loss =  1.050883412361145\n",
      "epoch =  27  step =  60  of total steps  100  loss =  1.7520695924758911\n",
      "epoch =  27  step =  80  of total steps  100  loss =  1.5559051036834717\n",
      "epoch :  27  /  30  | TL :  1.5181639671325684  | VL :  1.4633153676986694\n",
      "epoch =  28  step =  0  of total steps  100  loss =  1.5180740356445312\n",
      "epoch =  28  step =  20  of total steps  100  loss =  1.5254337787628174\n",
      "epoch =  28  step =  40  of total steps  100  loss =  1.8007771968841553\n",
      "epoch =  28  step =  60  of total steps  100  loss =  1.4996777772903442\n",
      "epoch =  28  step =  80  of total steps  100  loss =  1.2831164598464966\n",
      "epoch :  28  /  30  | TL :  1.5206521344184876  | VL :  1.445867657661438\n",
      "epoch =  29  step =  0  of total steps  100  loss =  1.518463373184204\n",
      "epoch =  29  step =  20  of total steps  100  loss =  1.3726383447647095\n",
      "epoch =  29  step =  40  of total steps  100  loss =  1.3653535842895508\n",
      "epoch =  29  step =  60  of total steps  100  loss =  1.597317099571228\n",
      "epoch =  29  step =  80  of total steps  100  loss =  1.71254563331604\n",
      "epoch :  29  /  30  | TL :  1.5181376373767852  | VL :  1.4502646923065186\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "total_step = len(trainset) // (train_batch_size * 150)\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "min_val = 100\n",
    "for epoch in range(num_epochs):\n",
    "    trn = []\n",
    "    Net.train()\n",
    "    for i, (images, labels) in enumerate(trainloader) :\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images).cuda().float()\n",
    "            labels = Variable(labels).cuda()\n",
    "        else : \n",
    "            images = Variable(images).float()\n",
    "            labels = Variable(labels)\n",
    "        \n",
    "        _, target = torch.max(labels, 1)\n",
    "\n",
    "        y_pred = Net.forward(images, classify = True)\n",
    "        \n",
    "        loss = criterion(y_pred, target)\n",
    "        trn.append(loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "#         torch.nn.utils.clip_grad_value_(Net.parameters(), 10)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 20 == 0 :\n",
    "            print('epoch = ', epoch, ' step = ', i, ' of total steps ', total_step, ' loss = ', loss.item())\n",
    "            \n",
    "    train_loss = (sum(trn) / len(trn))\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    Net.eval()\n",
    "    val = []\n",
    "    with torch.no_grad() :\n",
    "        for i, (images, labels) in enumerate(valloader) :\n",
    "            if torch.cuda.is_available():\n",
    "                images = Variable(images).cuda().float()\n",
    "                labels = Variable(labels).cuda()\n",
    "            else : \n",
    "                images = Variable(images).float()\n",
    "                labels = Variable(labels)\n",
    "                \n",
    "            _, target = torch.max(labels, 1)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = Net.forward(images, classify = True)\n",
    "            loss = criterion(outputs, target)\n",
    "            val.append(loss)\n",
    "\n",
    "    val_loss = (sum(val) / len(val)).item()\n",
    "    val_loss_list.append(val_loss)\n",
    "    print('epoch : ', epoch, ' / ', num_epochs, epoch' | TL : ', train_loss, ' | VL : ', val_loss)\n",
    "    \n",
    "    if val_loss < min_val :\n",
    "        print('saving model')\n",
    "        min_val = val_loss\n",
    "        torch.save(Net.state_dict(), 'autoencoder_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb3b252d908>,\n",
       " <matplotlib.lines.Line2D at 0x7fb3b252da58>]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.arange(30)\n",
    "plt.plot(j, train_loss_list, 'r', j, val_loss_list, 'g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_accuracy(dataloader, Net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    Net.eval()\n",
    "    for i, (images, labels) in enumerate(dataloader):\n",
    "        images = Variable(images).float()\n",
    "        labels = Variable(labels).float()\n",
    "\n",
    "        outputs = Net(images, classify = True)\n",
    "    \n",
    "        _, label_ind = torch.max(labels, 1)\n",
    "        _, pred_ind = torch.max(outputs, 1)\n",
    "        \n",
    "        # converting to numpy arrays\n",
    "        label_ind = label_ind.data.numpy()\n",
    "        pred_ind = pred_ind.data.numpy()\n",
    "        \n",
    "        # get difference\n",
    "        diff_ind = label_ind - pred_ind\n",
    "        # correctly classified will be 1 and will get added\n",
    "        # incorrectly classified will be 0\n",
    "        correct += np.count_nonzero(diff_ind == 0)\n",
    "        total += len(diff_ind)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    # print(len(diff_ind))\n",
    "    return accuracy\n",
    "\n",
    "Net = Net.cpu().eval()\n",
    "# _get_accuracy(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42875\n",
      "0.4296875\n",
      "0.4140625\n"
     ]
    }
   ],
   "source": [
    "print(_get_accuracy(trainloader, Net))\n",
    "print(_get_accuracy(testloader, Net))\n",
    "print(_get_accuracy(valloader, Net))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The symmetrical fully convolutional autoencoder doesn't work well. So, next we try using an asymmetrical autoencoder (asymmetrical since it will only have maxpool in encoder) (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - (MEDIUM-PRIORITY)\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        # defining layers\n",
    "        self.conv1 = nn.Conv1d(3, 10, 3)\n",
    "        self.mp = nn.MaxPool1d(2, 2)\n",
    "        \n",
    "        self.dconv1 = nn.ConvTranspose1d(10, 3, 3)\n",
    "        nn.init.xavier_uniform_(self.conv1.weight, gain = nn.init.calculate_gain('relu'))\n",
    "        \n",
    "    def forward(self, signal):\n",
    "        signal = signal.view(-1, 150 * 3)\n",
    "        out = F.relu(self.fc1(signal))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = F.log_softmax(self.fc3(out), dim = 1)\n",
    "        return out\n",
    "\n",
    "Net = AutoEncoder()\n",
    "if torch.cuda.is_available():\n",
    "    print('Model on GPU')\n",
    "    Net = Net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
