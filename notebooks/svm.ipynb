{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16200\n"
     ]
    }
   ],
   "source": [
    "traindf = pd.read_csv('../data/train.csv', header = None)\n",
    "valdf = pd.read_csv('../data/val.csv', header = None)\n",
    "testdf = pd.read_csv('../data/test.csv', header = None)\n",
    "print(len(testdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using raw data to train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_segments(df):\n",
    "    ''' Returns 2 arrays : \n",
    "        x of shape (num_examples, num_features = 150)\n",
    "        y of shape (num_examples, num_classes = 5)\n",
    "        Extracts this from given Pandas DataFrame\n",
    "    '''\n",
    "    x = np.zeros((len(df) // 150, 450))\n",
    "    y = np.zeros((len(df) // 150, 5))\n",
    "    for i in range(1, len(df) // 150) : \n",
    "        # taking 150 values of 3 channels at a time, flattening and \n",
    "        x[i - 1] = df.iloc[(i - 1) * 150 : i * 150,  : 3].values.reshape(450)\n",
    "        # finding single one_hot encoded label (which occurs maximum times in 150 values)\n",
    "        label_array = df.iloc[((i - 1) * 150) : i * 150, 3 : ].values\n",
    "        ind = np.argmax(np.sum(label_array, axis = 0))\n",
    "        label = np.zeros_like(df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        y[i - 1] = label\n",
    "        \n",
    "    num = len(df) // 150\n",
    "    # last example isn't considered in the loop\n",
    "    x[num - 1] = df.iloc[(num - 1) * 150 : , : 3].values.reshape(450)\n",
    "    # just taking the central value for the last label\n",
    "    y[num - 1] = df.iloc[((num - 1) * 150) + 75, 3 : ].values\n",
    "    return x, y\n",
    "\n",
    "# Calling loading function and load all data into NumPy arrays\n",
    "# as required by sklearn\n",
    "x_test, y_test_ = return_segments(testdf)\n",
    "x_train, y_train_ = return_segments(traindf)\n",
    "# Converting one_hot encoded labels to integers\n",
    "y_test = np.argmax(y_test_, axis = 1)\n",
    "y_train = np.argmax(y_train_, axis = 1)\n",
    "\n",
    "# a = traindf.iloc[ : 150, : 3].values.reshape(450)\n",
    "# b = traindf.iloc[150 : 300, : 3].values.reshape(450)\n",
    "# x = np.zeros((len(traindf) // 150, 450))\n",
    "# x[0] = a\n",
    "# x[1] = b\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Grid Search to find best hyperparameters for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/envs/pyt/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "svm_model = GridSearchCV(SVC(), params_grid, cv=5)\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.4016393442622951 \n",
      "\n",
      "Best C: 1 \n",
      "\n",
      "Best Kernel: rbf \n",
      "\n",
      "Best Gamma: 0.001 \n",
      "\n",
      "[[ 0  0  0 15  0]\n",
      " [ 0  0  0 19  0]\n",
      " [ 0  0  0 23  0]\n",
      " [ 0  0  0 33  0]\n",
      " [ 0  0  0 18  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.00      0.00      0.00        19\n",
      "           2       0.00      0.00      0.00        23\n",
      "           3       0.31      1.00      0.47        33\n",
      "           4       0.00      0.00      0.00        18\n",
      "\n",
      "    accuracy                           0.31       108\n",
      "   macro avg       0.06      0.20      0.09       108\n",
      "weighted avg       0.09      0.31      0.14       108\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/envs/pyt/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "y_pred = final_model.predict(x_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  0  5  1]\n",
      " [ 4  2  3  9  1]\n",
      " [ 6  2  9  5  1]\n",
      " [ 5 10 10  5  3]\n",
      " [ 4  4  3  2  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.60      0.42        15\n",
      "           1       0.11      0.11      0.11        19\n",
      "           2       0.36      0.39      0.37        23\n",
      "           3       0.19      0.15      0.17        33\n",
      "           4       0.45      0.28      0.34        18\n",
      "\n",
      "    accuracy                           0.28       108\n",
      "   macro avg       0.29      0.31      0.28       108\n",
      "weighted avg       0.28      0.28      0.27       108\n",
      "\n",
      "[[ 98   0   1   0   0]\n",
      " [  0  83   0   3   1]\n",
      " [  0   0 167   2   2]\n",
      " [  0   0   3 339   1]\n",
      " [  0   0   2   1 151]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        99\n",
      "           1       1.00      0.95      0.98        87\n",
      "           2       0.97      0.98      0.97       171\n",
      "           3       0.98      0.99      0.99       343\n",
      "           4       0.97      0.98      0.98       154\n",
      "\n",
      "    accuracy                           0.98       854\n",
      "   macro avg       0.98      0.98      0.98       854\n",
      "weighted avg       0.98      0.98      0.98       854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_lin = svm.SVC(kernel = 'linear', C = 1000)\n",
    "svm_lin.fit(x_train, y_train)\n",
    "y_pred = svm_lin.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_train)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only one channel data to train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_segments_x_acc(df):\n",
    "    ''' Returns 2 arrays : \n",
    "        x of shape (num_examples, num_features = 150)\n",
    "        y of shape (num_examples, num_classes = 5)\n",
    "        Extracts only x_acc data and labels from given Pandas DataFrame\n",
    "    '''\n",
    "    x = np.zeros((len(df) // 150, 150))\n",
    "    y = np.zeros((len(df) // 150, 5))\n",
    "    for i in range(1, len(df) // 150) : \n",
    "        # taking 150 values of 3 channels at a time, flattening and \n",
    "        x[i - 1] = df.iloc[(i - 1) * 150 : i * 150, 2].values\n",
    "        # finding single one_hot encoded label (which occurs maximum times in 150 values)\n",
    "        label_array = df.iloc[((i - 1) * 150) : i * 150, 3 : ].values\n",
    "        ind = np.argmax(np.sum(label_array, axis = 0))\n",
    "        label = np.zeros_like(df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        y[i - 1] = label\n",
    "        \n",
    "    num = len(df) // 150\n",
    "    # last example isn't considered in the loop\n",
    "    x[num - 1] = df.iloc[(num - 1) * 150 : , 0].values\n",
    "    # just taking the central value for the last label\n",
    "    y[num - 1] = df.iloc[((num - 1) * 150) + 75, 3 : ].values\n",
    "    return x, y\n",
    "\n",
    "xtrain, ytrain_ = return_segments_x_acc(traindf)\n",
    "xtest, ytest_ = return_segments_x_acc(valdf)\n",
    "ytest = np.argmax(ytest_, axis = 1)\n",
    "ytrain = np.argmax(ytrain_, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/envs/pyt/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight='balanced',\n",
       "                           coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "svm_model = GridSearchCV(SVC(class_weight = 'balanced'), params_grid, cv = 5)\n",
    "svm_model.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.28337236533957844 \n",
      "\n",
      "Best C: 100 \n",
      "\n",
      "Best Kernel: linear \n",
      "\n",
      "Best Gamma: auto_deprecated \n",
      "\n",
      "[[ 3  2  4  4  2]\n",
      " [ 3  2  3  4  1]\n",
      " [ 5  2  9  3  0]\n",
      " [ 7  4 12  5  7]\n",
      " [ 5  6  4  5  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.20      0.16        15\n",
      "           1       0.12      0.15      0.14        13\n",
      "           2       0.28      0.47      0.35        19\n",
      "           3       0.24      0.14      0.18        35\n",
      "           4       0.29      0.17      0.21        24\n",
      "\n",
      "    accuracy                           0.22       106\n",
      "   macro avg       0.21      0.23      0.21       106\n",
      "weighted avg       0.23      0.22      0.21       106\n",
      "\n",
      "[[ 76   0  14   7   2]\n",
      " [  0  72   6   8   1]\n",
      " [  7   4 134  23   3]\n",
      " [ 40  29  60 184  30]\n",
      " [ 11   6  16  10 111]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.77      0.65        99\n",
      "           1       0.65      0.83      0.73        87\n",
      "           2       0.58      0.78      0.67       171\n",
      "           3       0.79      0.54      0.64       343\n",
      "           4       0.76      0.72      0.74       154\n",
      "\n",
      "    accuracy                           0.68       854\n",
      "   macro avg       0.67      0.73      0.69       854\n",
      "weighted avg       0.70      0.68      0.67       854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "y_pred = final_model.predict(xtest)\n",
    "print(confusion_matrix(ytest, y_pred))\n",
    "print(classification_report(ytest, y_pred))\n",
    "y_pred = final_model.predict(xtrain)\n",
    "print(confusion_matrix(ytrain, y_pred))\n",
    "print(classification_report(ytrain, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 50 sampled points of signal as one example instead of 150 sampled points to increase the dataset size and train SVM using that larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_segments(df):\n",
    "    ''' Returns 2 arrays : \n",
    "        x of shape (num_examples, num_features = 50)\n",
    "        y of shape (num_examples, num_classes = 5)\n",
    "        Extracts this from given Pandas DataFrame\n",
    "    '''\n",
    "    x = np.zeros((len(df) // 50, 150))\n",
    "    y = np.zeros((len(df) // 50, 5))\n",
    "    for i in range(1, len(df) // 50) : \n",
    "        # taking 150 values of 3 channels at a time, flattening and \n",
    "        x[i - 1] = df.iloc[(i - 1) * 50 : i * 50,  : 3].values.reshape(150)\n",
    "        # finding single one_hot encoded label (which occurs maximum times in 150 values)\n",
    "        label_array = df.iloc[((i - 1) * 50) : i * 50, 3 : ].values\n",
    "        ind = np.argmax(np.sum(label_array, axis = 0))\n",
    "        label = np.zeros_like(df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        y[i - 1] = label\n",
    "        \n",
    "    num = len(df) // 50\n",
    "    # last example isn't considered in the loop\n",
    "    x[num - 1] = df.iloc[(num - 1) * 50 : , : 3].values.reshape(150)\n",
    "    # just taking the central value for the last label\n",
    "    y[num - 1] = df.iloc[((num - 1) * 50) + 25, 3 : ].values\n",
    "    return x, y\n",
    "\n",
    "# Calling loading function and load all data into NumPy arrays\n",
    "# as required by sklearn\n",
    "x_test, y_test_ = return_segments(testdf)\n",
    "x_train, y_train_ = return_segments(traindf)\n",
    "# Converting one_hot encoded labels to integers\n",
    "y_test = np.argmax(y_test_, axis = 1)\n",
    "y_train = np.argmax(y_train_, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "svm_model = GridSearchCV(SVC(), params_grid, cv = 5)\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.4016393442622951 \n",
      "\n",
      "Best C: 1 \n",
      "\n",
      "Best Kernel: rbf \n",
      "\n",
      "Best Gamma: 0.001 \n",
      "\n",
      "[[ 0  0  0 45  0]\n",
      " [ 0  0  0 57  0]\n",
      " [ 0  0  0 69  0]\n",
      " [ 0  0  0 99  0]\n",
      " [ 0  0  0 54  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        45\n",
      "           1       0.00      0.00      0.00        57\n",
      "           2       0.00      0.00      0.00        69\n",
      "           3       0.31      1.00      0.47        99\n",
      "           4       0.00      0.00      0.00        54\n",
      "\n",
      "    accuracy                           0.31       324\n",
      "   macro avg       0.06      0.20      0.09       324\n",
      "weighted avg       0.09      0.31      0.14       324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/envs/pyt/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0  297    0]\n",
      " [   0    0    0  261    0]\n",
      " [   0    0    0  513    0]\n",
      " [   0    0    0 1029    0]\n",
      " [   0    0    0  462    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       297\n",
      "           1       0.00      0.00      0.00       261\n",
      "           2       0.00      0.00      0.00       513\n",
      "           3       0.40      1.00      0.57      1029\n",
      "           4       0.00      0.00      0.00       462\n",
      "\n",
      "    accuracy                           0.40      2562\n",
      "   macro avg       0.08      0.20      0.11      2562\n",
      "weighted avg       0.16      0.40      0.23      2562\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/envs/pyt/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "y_pred = final_model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = final_model.predict(x_train)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6  5 11 18  5]\n",
      " [11 10  7 21  8]\n",
      " [14  2 26 20  7]\n",
      " [11 13 27 38 10]\n",
      " [ 5  7  7 20 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.13      0.13        45\n",
      "           1       0.27      0.18      0.21        57\n",
      "           2       0.33      0.38      0.35        69\n",
      "           3       0.32      0.38      0.35        99\n",
      "           4       0.33      0.28      0.30        54\n",
      "\n",
      "    accuracy                           0.29       324\n",
      "   macro avg       0.28      0.27      0.27       324\n",
      "weighted avg       0.29      0.29      0.29       324\n",
      "\n",
      "[[272   0  23   2   0]\n",
      " [  0 244   8   7   2]\n",
      " [  1   1 485  17   9]\n",
      " [  0   5  47 975   2]\n",
      " [  1   1  12   5 443]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       297\n",
      "           1       0.97      0.93      0.95       261\n",
      "           2       0.84      0.95      0.89       513\n",
      "           3       0.97      0.95      0.96      1029\n",
      "           4       0.97      0.96      0.97       462\n",
      "\n",
      "    accuracy                           0.94      2562\n",
      "   macro avg       0.95      0.94      0.94      2562\n",
      "weighted avg       0.95      0.94      0.94      2562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class_wt = {0 : 3, 1 : 3, 2 : 2, 3 : 1, 4 : 2}\n",
    "svm_lin = svm.SVC(class_weight = None, kernel = 'rbf', decision_function_shape = 'ovr', C = 1e3, gamma = 'scale')\n",
    "svm_lin.fit(x_train, y_train)\n",
    "y_pred = svm_lin.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_train)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimenting with SVMs trained on raw data, it is clear that even SVMs cannot generalize on raw data. So, will try to use running standard deviation, RMS, etc. before feeding to SVM.\n",
    "\n",
    "### Using running standard deviation data to train SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_std_deviation(x, window_size = 10):\n",
    "    ''' Returns running standard deviation of x calculated using a window of size window_size\n",
    "    Sliding of window starts from zero index upto where window can be placed (len(x) - window_size)\n",
    "    Remaining part of input is discarded (not very significant since it will be present in some other\n",
    "    input also due to the 50% overlap)\n",
    "    '''\n",
    "    std_dev = np.zeros(len(x) - window_size)\n",
    "    for i in range(len(x) - window_size):\n",
    "        std_dev[i] = np.std(x[i : i + window_size])\n",
    "        \n",
    "    return std_dev\n",
    "\n",
    "def return_segments(df, window_size = 20):\n",
    "    ''' Returns 2 arrays : \n",
    "        x of shape (num_examples, num_features = 150)\n",
    "        y of shape (num_examples, num_classes = 5)\n",
    "        Extracts this from given Pandas DataFrame\n",
    "    '''\n",
    "    x = np.zeros((len(df) // 150, 450 - (3 * window_size)))\n",
    "    y = np.zeros((len(df) // 150, 5))\n",
    "    for i in range(1, len(df) // 150) : \n",
    "        # taking 150 values of 3 channels at a time, flattening and \n",
    "        acc = df.iloc[(i - 1) * 150 : i * 150,  : 3].values\n",
    "        z = np.zeros(450 - (3 * window_size))\n",
    "        z[0 : 150 - window_size] = running_std_deviation(np.transpose(acc)[0], window_size = window_size)\n",
    "        z[150 - window_size : 300 - (2 * window_size)] = running_std_deviation(np.transpose(acc)[1], window_size = window_size)\n",
    "        z[300 - (2 * window_size) : ] = running_std_deviation(np.transpose(acc)[2], window_size = window_size)\n",
    "        x[i - 1] = z\n",
    "        # finding single one_hot encoded label (which occurs maximum times in 150 values)\n",
    "        label_array = df.iloc[((i - 1) * 150) : i * 150, 3 : ].values\n",
    "        ind = np.argmax(np.sum(label_array, axis = 0))\n",
    "        label = np.zeros_like(df.iloc[0, 3 : ].values)\n",
    "        label = label.astype('float')\n",
    "        label[ind] = 1\n",
    "        y[i - 1] = label\n",
    "        \n",
    "    num = len(df) // 150\n",
    "    # last example isn't considered in the loop\n",
    "    acc = df.iloc[(num - 1) * 150 : , : 3].values\n",
    "    z = np.zeros(450 - (3 * window_size))\n",
    "    z[0 : 150 - window_size] = running_std_deviation(np.transpose(acc)[0], window_size = window_size)\n",
    "    z[150 - window_size : 300 - (2 * window_size)] = running_std_deviation(np.transpose(acc)[1], window_size = window_size)\n",
    "    z[300 - (2 * window_size) : ] = running_std_deviation(np.transpose(acc)[2], window_size = window_size)\n",
    "    x[num - 1] = z\n",
    "    # just taking the central value for the last label\n",
    "    y[num - 1] = df.iloc[((num - 1) * 150) + 75, 3 : ].values\n",
    "    return x, y\n",
    "\n",
    "# Calling loading function and load all data into NumPy arrays\n",
    "# as required by sklearn\n",
    "x_test, y_test_ = return_segments(testdf)\n",
    "x_train, y_train_ = return_segments(traindf)\n",
    "# Converting one_hot encoded labels to integers\n",
    "y_test = np.argmax(y_test_, axis = 1)\n",
    "y_train = np.argmax(y_train_, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/envs/pyt/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight='balanced',\n",
       "                           coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_grid = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "svm_model = GridSearchCV(SVC(class_weight = 'balanced'), params_grid, cv = 5)\n",
    "svm_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score for training data: 0.30327868852459017 \n",
      "\n",
      "Best C: 1000 \n",
      "\n",
      "Best Kernel: rbf \n",
      "\n",
      "Best Gamma: 0.001 \n",
      "\n",
      "[[ 5  5  3  1  1]\n",
      " [ 4  7  3  4  1]\n",
      " [ 1  0 20  1  1]\n",
      " [12  4  8  5  4]\n",
      " [ 3  4  3  3  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.33      0.25        15\n",
      "           1       0.35      0.37      0.36        19\n",
      "           2       0.54      0.87      0.67        23\n",
      "           3       0.36      0.15      0.21        33\n",
      "           4       0.42      0.28      0.33        18\n",
      "\n",
      "    accuracy                           0.39       108\n",
      "   macro avg       0.37      0.40      0.36       108\n",
      "weighted avg       0.38      0.39      0.36       108\n",
      "\n",
      "[[ 41   6  37   8   7]\n",
      " [ 13  43  14   6  11]\n",
      " [ 21  11 118   8  13]\n",
      " [ 78  41  91  78  55]\n",
      " [ 21  24  23  10  76]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.41      0.30        99\n",
      "           1       0.34      0.49      0.41        87\n",
      "           2       0.42      0.69      0.52       171\n",
      "           3       0.71      0.23      0.34       343\n",
      "           4       0.47      0.49      0.48       154\n",
      "\n",
      "    accuracy                           0.42       854\n",
      "   macro avg       0.43      0.46      0.41       854\n",
      "weighted avg       0.52      0.42      0.41       854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the accuracy score\n",
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "y_pred = final_model.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = final_model.predict(x_train)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  6  3  2  1]\n",
      " [ 4  5  3  4  3]\n",
      " [ 1  1 18  2  1]\n",
      " [11  4  8  6  4]\n",
      " [ 5  4  2  3  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.20      0.15        15\n",
      "           1       0.25      0.26      0.26        19\n",
      "           2       0.53      0.78      0.63        23\n",
      "           3       0.35      0.18      0.24        33\n",
      "           4       0.31      0.22      0.26        18\n",
      "\n",
      "    accuracy                           0.33       108\n",
      "   macro avg       0.31      0.33      0.31       108\n",
      "weighted avg       0.33      0.33      0.32       108\n",
      "\n",
      "[[ 51   5  33   6   4]\n",
      " [  8  56  12   3   8]\n",
      " [ 24   5 118  10  14]\n",
      " [ 79  48  82  87  47]\n",
      " [ 22  19  16  13  84]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.52      0.36        99\n",
      "           1       0.42      0.64      0.51        87\n",
      "           2       0.45      0.69      0.55       171\n",
      "           3       0.73      0.25      0.38       343\n",
      "           4       0.54      0.55      0.54       154\n",
      "\n",
      "    accuracy                           0.46       854\n",
      "   macro avg       0.48      0.53      0.47       854\n",
      "weighted avg       0.56      0.46      0.45       854\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# class_wt = {0 : 3, 1 : 3, 2 : 2, 3 : 1, 4 : 2}\n",
    "svm_lin = svm.SVC(class_weight = 'balanced', kernel = 'linear', C = 10)\n",
    "svm_lin.fit(x_train, y_train)\n",
    "y_pred = svm_lin.predict(x_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "y_pred = svm_lin.predict(x_train)\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(.95)\n",
    "principalComponents = pca.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain = pca.transform(x_train)\n",
    "xtest = pca.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45081967213114754\n",
      "0.3888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akshay/anaconda3/envs/pyt/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/akshay/anaconda3/envs/pyt/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logisticRegr = LogisticRegression()\n",
    "logisticRegr.fit(xtrain, y_train)\n",
    "print(logisticRegr.score(xtrain, y_train))\n",
    "print(logisticRegr.score(xtest, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
